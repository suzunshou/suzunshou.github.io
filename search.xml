<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>JVM - 自动内存管理</title>
      <link href="/2020/03/15/JVM-%E8%87%AA%E5%8A%A8%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"/>
      <url>/2020/03/15/JVM-%E8%87%AA%E5%8A%A8%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<pre><code>Java基于C++实现，与C++的一大区别在于它能够进行自动内存管理。</code></pre><p>先从<code>垃圾</code>说起，所谓的垃圾就是无用的对象，主要存放在<code>堆区</code>中。对于C++来说，创建对象的时候需要<code>malloc</code>，用完对象之后需要<code>free</code>，以免无用对象占据内存空间，这一切的操作都是<code>手动</code>的。对于Java来说，通过<code>Java虚拟机</code>及<code>垃圾收集器</code>可以<code>自动化</code>的实现对象内存的<code>分配及回收</code>。</p><p><img src="/images/jvm-gc.png" alt="jvm-gc"></p><p>那么，如何标识哪些内存对象是无用的呢？</p><pre><code>判断对象是否应该存活的算法有：引用计数算法、根搜索算法。</code></pre><p><code>引用计数算法</code>，给每一个对象添加一个<code>引用计数器</code>，只要一个对象被引用了，那么计数值就加1，如果引用失效了，那么计数值就减1，直到为0，那么这个对象就可以被回收了，这种方式还是比较简单高效的。但是，如果存在<code>循环引用</code>，<code>引用计数算法</code>就无能为力了，引用会一直存在，计数值不会为0，从而造成内存无法被回收。</p><p><img src="/images/jvm-ref-d.png" alt="jvm-ref-d"></p><p><code>根搜索算法</code>，通过一系列名为<code>GC Roots</code>的对象为起始点，从这些节点<code>向下搜索</code>，如果对象是<code>可达</code>的，那么这个对象就是<code>存活</code>的，反之，就是不存活的，这个对象就是可回收的。</p><p><img src="/images/jvm-ref-r.png" alt="jvm-ref-r"></p><pre><code>决定对象是否应该存活的直接影响因素就是引用，在Java中存在有四种引用：强引用、软引用、弱引用、虚引用。</code></pre><p><strong>强引用</strong> 普遍存在，类似<code>Object obj = new Object()</code>，只要对象引用还存在，对象的内存就不会被回收。<br><strong>软引用</strong> 表示有用但非必需的对象，当内存不够的时候，软引用对象就可以被回收。<br><strong>弱引用</strong> 表示非必需对象，只要发生了GC，弱引用对象就可能被回收。<br><strong>虚引用</strong> 用于在对象被回收的时候能够收到通知。</p><pre><code>在标识对象存活的基础上，需要利用垃圾收集算法来实现内存的回收。</code></pre><p>首先是<code>标记-清除</code>算法，分为<code>标记</code>和<code>清除</code>两个阶段。标记的对象是<code>可回收对象</code>，先进行<code>标记</code>，然后再去执行<code>清除</code>。这种算法的缺点就是会产生大量的<code>内存碎片</code>，使得连续内存不足，导致GC的触发，并且标记、清除阶段效率都不高。</p><p><img src="/images/jvm-ms.png" alt="jvm-ms"></p><p>为了解决<code>标记-清除</code>算法的缺点，又产生了<code>复制</code>算法。将内存空间分为2个区域，各占<code>50%</code>，1个区域<code>正常</code>使用，1个区域<code>空闲</code>着，每次发生<code>GC</code>的时候，会将使用着的区域的<code>存活</code>对象<code>复制</code>到另一个区域，并按照<code>顺序存放</code>。通过这种方式，解决了内存碎片的问题，但同时又浪费了50%的内存空间。</p><p><img src="/images/jvm-gc-cp.png" alt="jvm-gc-cp">由于新生代的对象，98%左右都是<code>朝生夕死</code>的，将新生代分为<code>Eden区、Surviror0区、Survivor1区</code>，并且比例为<code>8:1:1</code>，使用复制算法也不至于浪费过多内存空间，并且不会产生内存碎片。</p><p>对于老年代里头的对象，一般存活率都是比较高的，如果采用<code>标记-清除</code>算法，那还不如<code>复制算法</code>呢，但如果采用<code>复制</code>算法，又因为老年代对象存活率高，频繁的移动内存中的对象，难免会造成回收效率的下降。因此，又产生了一种<code>标记-整理</code>算法，这种算法不会产生内存碎片，但效率比起复制算法来说也不高，但适用于老年代。</p><p><img src="/images/jvm-mc.png" alt="jvm-mc"></p><p>根据以上信息可以得知，<code>复制算法</code>更适用于<code>新生代</code>的内存回收，而<code>标记-清除算法</code>、<code>标记-整理算法</code>更适用于<code>老年代</code>的内存回收，因此，垃圾收集器基本都是基于<code>分代收集算法</code>，将内存区域划分为不同年代，按照每个区域合适的垃圾回收算法回收内存。</p><pre><code>实际上，垃圾收集器在分代收集算法的基础上以串行、并行、并发方式提供。</code></pre><table><thead><tr><th></th><th>新生代</th><th>老年代</th></tr></thead><tbody><tr><td>串行</td><td>Serial收集器</td><td>Serial Old收集器</td></tr><tr><td>并行</td><td>ParNew收集器、Parallel Scavenge收集器</td><td>Parallel Old收集器</td></tr><tr><td>并发</td><td></td><td>CMS收集器</td></tr><tr><td>其它</td><td>G1收集器</td><td>G1收集器</td></tr></tbody></table><p><code>新生代</code>的内存回收（YGC、Minor GC、Young GC）使用的复制算法。Serial收集器是<code>单线程</code>的，适用于Client模式，而ParNew收集器与Serial收集器相比除了采用<code>多线程</code>没有多大区别，适用于Server模式，Parallel Scavenge收集器表面上看起来和ParNew收集器没有多大区别，但实际上Parallel Scavenge收集器更关注的是<code>吞吐量</code>，通过减少<code>Stop The World</code>时间来提高吞吐量，同时可能导致<code>GC</code>次数更加<code>频繁</code>。</p><p><img src="/images/jvm-gc-new.png" alt="jvm-gc-new"></p><p><code>老年代</code>的内存回收（Major GC、FGC、Full GC同时也会回收新生代）使用的标记-整理算法、标记-清除算法。Serial Old收集器是<code>单线程</code>的，采用<code>标记-整理</code>算法，适用于Client模式。Parallel Old收集器是Parallel Scavenge收集器的老年代版本，是<code>多线程</code>的，注重<code>吞吐量</code>，采用的<code>标记-整理</code>算法。CMS收集器采用的<code>标记-清除</code>算法，注重<code>低停顿</code>，在<code>初始标记</code>、<code>重新标记</code>阶段会Stop The World，而<code>并发标记</code>、<code>并发清除</code>阶段与用户线程并行存在，由于采用的标记-清除算法，因此会产生内存碎片，导致出现<code>Concurrent Mode Failure</code>，触发Serial Old收集器来执行标记-整理。</p><p><img src="/images/jvm-gc-old.png" alt="jvm-gc-old">在CMS收集器的基础上又产生了<code>G1收集器</code>，与之不同的是G1收集器采用的<code>标记-整理</code>算法，不会产生内存碎片并且没有明显的分代概念，而是将内存划分为若干个固定大小区域，可以在保证<code>吞吐量</code>的同时完成<code>低停顿</code>的内存回收，在回收内存的时候不会全区域的去回收，而是优先回收内存垃圾比较多的区域。</p><p><img src="/images/jvm-gc-g1.png" alt="jvm-gc-g1"></p><pre><code>内存的分配也随着JDK的发展与各种技术的提升而更加智能。</code></pre><p><strong>对象优先在Eden区分配</strong><br>大部分的对象都具备朝生夕死的特点，更适合在新生代中分配，并且Minor GC速度比较快。</p><p><strong>大对象直接进入老年代</strong><br>由于新生代采用的复制算法，Minor GC会比较频繁，因此大对象最好直接进老年代，避免发生频繁的内存复制。当然，也有一些朝生夕死的大对象，如果过多这种大对象进入了老年代可能会导致Major GC的频繁发生，甚至导致Full GC的出现。可以通过配置-XX:PretenureSizeThreshold参数来定义直接进入老年代的大对象的大小门槛。</p><p><strong>长期存活对象将进入老年代</strong><br>如果对象长期存活，那么可能是有用的，最好是晋升到老年代，否则随着多次的Minor GC会不断的被复制来复制去，同时也比较占据新生代的内存空间。可以通过配置-XX:MaxTenuringThreshold参数来修改新生代中的对象晋升到老年代的历经GC次数，默认是15次。</p><p><strong>动态年龄判断</strong><br>通过动态年龄判断，只要Surviror区中相同年龄的对象大小总和超过Surviror区大小的一半，那么就允许新生代对象不必历经MaxTenuringThreshold配置的GC次数提前晋升到老年代。</p><p><strong>空间分配担保</strong><br>在发生新生代Minor GC的时候，会去判断要晋升到老年代的对象大小总和是否超过老年代剩余空间的大小，如果超过了，并且配置了HandlePromotionFailure，那么就会进行Minor GC，否则的话，会执行一次Full GC。</p><p><strong>逃逸分析、栈上分配</strong><br>逃逸分析分为线程逃逸、方法逃逸。对于线程逃逸来说，如果一个对象只在一个线程中使用，那么这个对象就逃逸了，不需要在堆中分配内存。对于方法逃逸来说，如果一个对象只在方法内部使用，并且被外部方法所引用，那么这个对象就逃逸了，不需要在堆中分配内存。</p>]]></content>
      
      
      
        <tags>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM - Java虚拟机内存模型</title>
      <link href="/2020/03/09/JVM-Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"/>
      <url>/2020/03/09/JVM-Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<pre><code>Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。</code></pre><p><img src="/images/jvm.png" alt="jvm"></p><p>这些区域包含：虚拟机栈、本地方法栈、程序计数器、堆、方法区。<br>每个区域都有各自的生命周期以及各自的作用范围及功能。<br>在线程中，虚拟机栈、本地方法栈、程序计数器是私有的，属于<code>指令</code>，堆、方法区则是共享的，属于<code>数据</code>。</p><p><code>程序计数器</code>标识的是<code>线程</code>正在执行的<code>字节码指令地址</code>，由于多线程的存在及CPU可能会来回切换线程。<br>多个线程之间的<code>程序计数器</code>是相互独立的，可以看作是各自的<code>行号指示器</code>。</p><p><code>虚拟机栈</code>，它表示的是<code>Java方法</code>在运行时候的<code>内存模型</code>，是一种先进后出的数据结构。<br><code>虚拟机栈</code>，存储了当前方法运行所需要的<code>指令</code>、<code>数据</code>、<code>返回地址</code>。</p><p><img src="/images/jvm-stack.png" alt="jvm-stack"></p><p>方法被调用的时候都会去创建<code>栈帧</code>，从方法执行的<code>开始</code>和<code>结束</code>又对应着<code>栈帧</code>在<code>虚拟机栈</code>中的<code>入栈</code>和<code>出栈</code>。<br><code>栈帧</code>被用来保存<code>局部变量表</code>、<code>操作数栈</code>、<code>动态链接</code>、<code>方法出口</code>等信息，每一个方法都对应着一个<code>栈帧</code>。<br><img src="/images/jvm-stack-1.png" alt="jvm-stack-1"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sankuai.test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSON;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String json = <span class="string">"&#123;\"id\":1,\"name\":\"1\"&#125;"</span>;</span><br><span class="line">        <span class="keyword">int</span> a = <span class="number">1</span>, b = <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">int</span> c = a + b + <span class="number">6</span>;</span><br><span class="line">        System.out.println(a + b);</span><br><span class="line">        System.out.println(c);</span><br><span class="line">        System.out.println(JSON.parseObject(json, User<span class="class">.<span class="keyword">class</span>))</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>局部变量表</code>中包含了<code>基本数据类型</code>、<code>对象引用类型</code>、<code>返回地址</code>。</p><ul><li><code>基本数据类型</code>：byte、short、int、long、float、double、boolean、char。</li><li><code>对象引用类型</code>：对象的起始地址（数组）或者对象的句柄（类）。</li><li><code>返回地址</code>：指向的是一条字节码指令的地址。</li></ul><p><code>操作数栈</code>，本质也是一个栈，入栈和出栈代表着变量的操作，比如：两个变量相加。<br><code>动态链接</code>，所调用的对象会在常量池中存储并用标号标识，而常量池会指向对象的真实地址。<br><img src="/images/jvm-cp-0.png" alt="jvm-cp-0"><img src="/images/jvm-cp.png" alt="jvm-cp"><code>方法出口</code>，当<code>栈帧</code>出栈之后，对应的这个方法应该返回到调用它的地方。</p><p>接着是<code>本地方法栈</code>，它跟<code>虚拟机栈</code>是类似的，只不过它调用的<code>不是Java方法</code>，而是<code>Native本地方法</code>。<br>另外，<code>虚拟机栈</code>、<code>本地方法栈</code>都是线程私有的，生命周期跟随着线程。<br>当线程越多、栈的深度越深，就可能造成栈溢出<code>StackOverFlowError</code>，甚至是<code>OutOfMemoryError</code>。</p><p><code>堆</code>是Java虚拟机中内存占用<code>最大</code>的一块区域，也被所有的线程所<code>共享</code>，主要是用来<code>存放对象实例</code>。所有的对象实例和数组都要在<code>堆</code>上分配内存，不过后来出现了栈上分配、标量替换、逃逸分析等技术，使得对象<code>不一定</code>需要在堆上分配内存。一个堆包含了：<code>新生代（Eden、S0、S1）</code>、<code>老年代</code>，比例通常是<code>1:2</code>。</p><p><img src="/images/jvm-heap.png" alt="jvm-heap"><code>堆</code>也是垃圾收集器GC的重点区域，目前普遍采用的是<code>分代收集算法</code>。</p><p>最后是<code>方法区</code>，也是被<code>所有</code>线程所共享的，主要存储的是：被虚拟机所加载的<code>类的信息</code>、<code>常量</code>、<code>静态变量</code>、即使编译器编译后的<code>代码</code>等信息，在<code>JDK1.8</code>之后，<code>方法区</code>被<code>元空间</code>所替代，并且被挪到了<code>堆外</code>。<br>在<code>方法区</code>中存在着一个<code>运行时常量池</code>，它用来存储<code>字面量</code>和<code>符号引用</code>。<br><img src="/images/jvm-cp-2.png" alt="jvm-cp-2"></p>]]></content>
      
      
      
        <tags>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL - 复制原理</title>
      <link href="/2020/03/07/MySQL-%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/"/>
      <url>/2020/03/07/MySQL-%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<pre><code>MySQL的复制是一种高性能高可用的解决方案，在主从之间进行复制、重放数据。</code></pre><p><img src="/images/mysql-repl.png" alt="mysql-repl"></p><p>复制（replication）首先会把<code>主</code>服务器的<code>数据更改</code>写入<code>binlog</code>二进制文件中，<code>从</code>服务器的<code>I/O线程</code>从<code>binlog</code>中<code>拉取</code>数据，<code>存入</code>本地的<code>relay log</code>中继日志中，然后由<code>SQL线程</code>读取并<code>重放</code>到从服务器中。</p><p>由于整个复制的过程是<code>异步实时</code>的，所以可能会存在在主从同步的<code>延迟</code>现象，这个延迟可能是一秒、一分、一小时，甚至一天，数据量越大，主服务器的<code>压力</code>就越大。</p><pre><code>MySQL支持的复制方式包含有：row（行）、statement（语句）、mixed（行+语句）。</code></pre><p>首先是基于<code>行</code>的复制方式，这种方式只会在<code>binlog</code>文件中记录<code>最终</code>的修改的<code>记录</code>的结果，在一些<code>复杂</code>查询下却返回<code>较少</code>数据情况下比较适用，但<code>兼容性</code>也不好，一旦修改列的话，就会出现问题，并且随着行数的增多，<code>binlog</code>文件也会<code>膨胀</code>。</p><p>接着是基于<code>语句</code>的复制方式，这种方式会在<code>binlog</code>文件中记录操作的<code>SQL语句</code>，相比基于行的方式来说，SQL语句更<code>容易理解</code>且遇到问题的时候也<code>较好定位</code>，在占用的<code>体积</code>上来说也<code>小</code>了许多。当然，基于<code>语句</code>的复制方式也存在着数据操作范围不可控的<code>风险</code>，同样，一旦修改列的话，也可能会出现问题。</p><p>最后是<code>mixed</code>这种方式，<code>结合</code>了基于<code>行</code>的复制方式和基于<code>语句</code>的复制方式，取二者的优点。</p>]]></content>
      
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL - 锁和事务</title>
      <link href="/2020/03/04/MySQL-%E9%94%81%E5%92%8C%E4%BA%8B%E5%8A%A1/"/>
      <url>/2020/03/04/MySQL-%E9%94%81%E5%92%8C%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<pre><code>MySQL本身也是在文件系统的基础上发展而来，因为锁的存在使之有所不同。</code></pre><p><code>MySQL</code>作为一种数据库软件，难免会存在对其<code>共享资源</code>的<code>并发访问</code>，为了<code>协调和管理</code>不同资源的并发访问，也就产生了<code>锁机制</code>，因为锁机制的存在为数据库提供了数据的<code>完整性</code>和<code>一致性</code>。</p><p>从<code>锁的级别</code>来分锁可分为：行级锁、表级锁、页级锁。<br>从<code>锁的类型</code>来分锁可分为：共享锁、排它锁（独占锁）。<br>为了协调<code>行锁、表锁</code>产生了：意向锁（表级锁）。</p><p><code>共享锁</code>，允许事务去<code>读取</code>数据。<br><code>排它锁</code>，允许事务去<code>修改或删除</code>数据。<br><code>意向锁</code>，获取行级锁的时候，自动添加的表级锁，包含：意向共享锁、意向排它锁。</p><p>对于<code>MyISAM</code>存储引擎，只支持<code>表锁</code>，而<code>InnoDB</code>存储引擎则支持<code>行锁、表锁</code>。</p><p><code>MyISAM</code>存储引擎修改、删除数据的时候，会产生排它锁，锁定的<code>整张表</code>，并发写入性能较差，而读取的时候产生的是共享锁，不会锁定表，读取性能就比较好。</p><p><code>InnoDB</code>存储引擎修改、删除数据的时候，会产生排它锁，锁定的<code>特定索引记录</code>，一般不会影响表中的其它行，并发写入性能较好，而读取的时候产生的是共享锁，不会锁定表和行，读取性能较好。</p><p><strong>行锁锁定的是索引记录，而不是记录行，如果没有索引，则使用隐式索引进行锁定。</strong></p><p>当一张表<code>某些行</code>已经获取了<code>排它锁</code>，在表中会产生一个<code>意向排它锁</code>，如果此时有一个事务要来锁定整张表，那么一看有<code>意向排它锁</code>的存在，该事务就会被<code>阻塞</code>，通过<code>意向锁</code>直接就可以知道能不能锁定表，不需要逐行去遍历检测是否有<code>排它锁</code>，通过意向锁高效地协调了行锁和表锁的关系。</p><p><code>行级锁</code>按照锁定范围来分，又分为三种：</p><ul><li><code>Record Lock</code> 单行记录上的锁。</li><li><code>Gap Lock</code> 间隙锁，锁定一个范围，不包含记录本身。</li><li><code>Next-Key Lock</code> 锁定一个范围，包含记录本身，用于解决幻读问题。</li></ul><p>当然，锁也是有利有弊的，也可能出现<code>死锁</code>的情况。<br>当<code>两个或两个以上</code>的事务在执行过程中，因<code>争夺资源</code>而造成一种<code>相互等待</code>的现象，称为<code>死锁</code>。</p><p>最后，也是因为锁的存在，丰富了后续事务的功能。</p><pre><code>MySQL通过设计一种机制，使得数据能够完整地从一种一致性状态切换到另一种一致性状态，这种机制称为事务。</code></pre><p>事务包含有四大特性：原子性（A）、一致性（C）、隔离性（I）、持久性（D），简称酸性。<br><code>原子性</code>：事务中的操作，要么全部成功，要么全部失败，不可切分。<br><code>一致性</code>：事务将数据库从一种一致性状态转变成另外一种一致性状态，并且保证数据的完整性。<br><code>隔离性</code>：又称并发控制，事务在提交之前对于其它事务是处于不可见的状态的。<br><code>持久性</code>：事务一旦提交，结果就是永久性的，不会因为数据库宕机而丢失数据。</p><p><code>原子性</code>、<code>持久性</code>是通过<code>redo</code>日志实现的，<code>一致性</code>是通过<code>undo</code>日志实现的，<code>隔离性</code>是通过<code>锁机制</code>实现的。</p><p>从本质上来说，<code>原子性</code>也是为了配合<code>持久性</code>而存在的，当事务的一部分写入<code>redo日志</code>后，发生了<code>崩溃、断电</code>，那么根据<code>原子性</code>来说，该次事务应当<code>恢复</code>，那么对于已经持久化到日志文件中的数据，就必须要通过<code>回溯</code>来撤销。在<code>InnoDB</code>存储引擎中，<code>redo</code>重做日志对应的就是<code>ib_logfile0</code>、<code>ib_logfile1</code>。<br><img src="/images/redo.png" alt="redo"></p><p>接着，事务要进行<code>回滚</code>，那就需要通过<code>一致性</code>来保障，而<code>undo</code>日志就是用来实现<code>一致性</code>的，在<code>undo</code>日志中保存了多个版本的事务的一些信息，通过<code>undo</code>日志，将事务<code>rollback</code>到修改之前的样子。</p><p>在此，不得不提的是MySQL的<code>MVCC</code>多版本并发控制，它也是通过<code>undo</code>日志来实现的。<br>MVCC是通过在每一数据行后头添加2个隐藏字段<code>create version</code>、<code>delete version</code>以及每次开启一个事务会初始化一个<code>事务id</code>。新增一条数据的时候，<code>create version</code>的值就等于<code>事务id</code>，删除数据的时候，<code>delete version</code>就等于<code>事务id</code>，更新数据的时候会先删后增，在<code>undo</code>日志中就会存在2条数据，一条<code>delete version</code>就等于<code>事务id</code>，一条<code>create version</code>的值等于<code>事务id</code>。</p><p>在事务执行过程中，可能会同时存在其它的事务，而<code>多个</code>事务之前需要相互<code>隔离</code>，也就是要做到<code>并发控制</code>，锁就是用来实现<code>隔离性</code>的。MySQL的事务的<code>隔离级别</code>包含：<code>Read Uncommitted</code>读未提交、<code>Read Committed</code>读已提交、<code>Read Repeatable</code>可重复读、<code>Serializable</code>串行化。其中，<code>读已提交</code>、<code>可重复读</code>是基于<code>MVCC</code>多版本并发控制来实现的。</p><p>锁，为事务的并发控制带来了好处，同时也带来了坏处，包括：脏读、不可重复读、幻读。</p><p><code>脏读</code>，指的是一个事务读到了另一个事务未提交的内容，一旦另一个事务回滚了，就出现了<code>脏数据</code>。<br><code>不可重复读</code>，指的是同一个事务使用同一句SQL进行<code>多次读取</code>，返回不同的结果。<br><code>幻读</code>，指的是一个事务在进行<code>增删</code>的时候，某些已经确定不会出现的记录突然出现。</p><p>要解决脏读，那就需要至少设置隔离级别为：<code>Read Committed</code>读已提交。<br>要解决不可重复读，那就需要至少设置隔离级别为：<code>Read Repeatable</code>可重复读。<br>要解决幻读，那就需要设置隔离级别为：<code>Serializable</code>串行化或者采用<code>Next-Key Lock</code>间隙锁。</p>]]></content>
      
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL - 索引原理</title>
      <link href="/2020/02/28/MySQL-%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86/"/>
      <url>/2020/02/28/MySQL-%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<pre><code>在MySQL数据库中，索引是一种很重要的提升查询性能的存储结构。</code></pre><p>索引，就像是书本的目录一样，通过查询索引，可以快速的定位到数据所处位置，减少磁盘I/O次数，提高性能。<br>在<code>InnoDB</code>存储引擎中，支持的索引包含：<code>B+树</code>、<code>全文索引</code>、<code>哈希索引</code>。</p><p>本文将主要聚焦在由<code>B+树</code>实现的索引结构，全文索引基于倒排索引实现，哈希索引基于链表、哈希函数实现。</p><p><img src="/images/b+.png" alt="b+"></p><p>首先，看一下<code>二分查找</code>，要从一个<code>有序数组</code>中查找一个元素，通过每次的<code>折半再折半</code>，时间复杂度为<code>O(logn)</code>，如果直接<code>顺序查找</code>元素的话，时间复杂度为<code>O(n)</code>。</p><p><img src="/images/mbs.png" alt="mbs"></p><p>接着，拓展到<code>二叉查找树</code>，如果<code>二叉查找树</code>足够平衡，那么时间复杂度还可以接近<code>二分查找</code>。</p><p><img src="/images/mbst.png" alt="mbst"></p><p>反之，<code>二叉查找树</code>呈现线性状态的话，那么时间复杂度就接近于<code>顺序查找</code>了。</p><p><img src="/images/mbst2.png" alt="mbst2"></p><p>因此，<code>B+树</code>既然能够提升查询性能的话，那必然是一棵<code>平衡查找树</code>，不能出现线性状态。<br><code>二叉查找树</code>定义：左边节点值小于根节点值，右边节点值大于根节点值，中序遍历后为从小到大排序的列表。<br><code>平衡二叉树</code>定义：在<code>二叉查找树</code>的条件下，又满足左右子树任何节点高度差不超过1。</p><p><code>B+树</code>的所有记录节点都是按照顺序排列，从小到大排列在叶子节点，并且每个叶子节点之间有<code>指针</code>进行连接。</p><p><img src="/images/b+.png" alt="b+"></p><p>在<code>B+树</code>的叶子节点中，包含了所有的节点及数据，其它非叶子节点仅仅包含指针引用。</p><p>在执行<code>范围查找</code>的时候，只需要在<code>B+树</code>上进行<code>二分查找</code>，然后找到底层叶子节点的<code>起始</code>位置，再沿着叶子节点间的双向指针<code>顺序遍历</code>即可，一般<code>B+树</code>的高度在<code>2 ~ 4</code>之间。</p><p>除了这个优点之外，由于非叶子节点<code>不存储</code>数据，经过一次<code>磁盘I/O</code>操作，就可以加载<code>大量</code>的节点，然后在<code>内存</code>中高效执行二分查找，再去找到数据所在<code>叶子节点</code>即可。</p><pre><code>由B+树来实现的索引包含：聚集索引、非聚集索引。</code></pre><p>每张表有且仅有<code>一个</code>聚集索引，通常情况下，是采用<code>主键</code>来作为聚集索引。<br>聚集索引根据每张表的<code>主键</code>来构造B+树，在<code>叶子节点</code>则存储整张表的<code>行记录数据</code>。<br>聚集索引是<code>逻辑连续</code>的，因此，在范围查找、根据主键排序的时候，效率特别高。</p><p>与聚集索引相反的是<code>非聚集索引</code>，又称为<code>辅助索引</code>，它的叶子节点并不存储<code>行记录数据</code>。<br>每张表可以拥有<code>多个</code>非聚集索引，通过非聚集索引查找数据会遍历找到叶子节点，再通过叶子节点指向的<code>聚集索引</code>的指针，再去<code>聚集索引</code>上遍历然后查找对应的<code>行记录数据</code>，也因此通过<code>非聚集索引</code>查找数据比通过<code>聚集索引</code>慢了一倍的速度。</p><p><img src="/images/msindex.png" alt="msindex"></p><pre><code>基于B+树两类索引实现的应用包含有：联合索引、覆盖索引。</code></pre><p>索引既可以使用单独的列，又可以使用<code>多个列</code>组合起来使用，这就是<code>联合索引</code>。<br>比如有这么一张表，包含有主键id及name、age组成的联合索引及一个addr普通字段。</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; desc test;</span><br><span class="line">+-------+--------------+------+-----+---------+-------+</span><br><span class="line">|<span class="string"> Field </span>|<span class="string"> Type         </span>|<span class="string"> Null </span>|<span class="string"> Key </span>|<span class="string"> Default </span>|<span class="string"> Extra </span>|</span><br><span class="line">+-------+--------------+------+-----+---------+-------+</span><br><span class="line">|<span class="string"> id    </span>|<span class="string"> int(11)      </span>|<span class="string"> NO   </span>|<span class="string"> PRI </span>|<span class="string"> 0       </span>|<span class="string">       </span>|</span><br><span class="line">|<span class="string"> name  </span>|<span class="string"> varchar(30)  </span>|<span class="string"> YES  </span>|<span class="string"> MUL </span>|<span class="string"> NULL    </span>|<span class="string">       </span>|</span><br><span class="line">|<span class="string"> age   </span>|<span class="string"> int(11)      </span>|<span class="string"> YES  </span>|<span class="string">     </span>|<span class="string"> NULL    </span>|<span class="string">       </span>|</span><br><span class="line">|<span class="string"> addr  </span>|<span class="string"> varchar(200) </span>|<span class="string"> YES  </span>|<span class="string">     </span>|<span class="string"> NULL    </span>|<span class="string">       </span>|</span><br><span class="line">+-------+--------------+------+-----+---------+-------+</span><br><span class="line"></span><br><span class="line">mysql&gt; show index from test;</span><br><span class="line">+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span><br><span class="line">|<span class="string"> Table </span>|<span class="string"> Non_unique </span>|<span class="string"> Key_name </span>|<span class="string"> Seq_in_index </span>|<span class="string"> Column_name </span>|<span class="string"> Collation </span>|<span class="string"> Cardinality </span>|<span class="string"> Sub_part </span>|<span class="string"> Packed </span>|<span class="string"> Null </span>|<span class="string"> Index_type </span>|<span class="string"> Comment </span>|<span class="string"> Index_comment </span>|</span><br><span class="line">+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span><br><span class="line">|<span class="string"> test  </span>|<span class="string">          0 </span>|<span class="string"> PRIMARY  </span>|<span class="string">            1 </span>|<span class="string"> id          </span>|<span class="string"> A         </span>|<span class="string">           0 </span>|<span class="string">     NULL </span>|<span class="string"> NULL   </span>|<span class="string">      </span>|<span class="string"> BTREE      </span>|<span class="string">         </span>|<span class="string">               </span>|</span><br><span class="line">|<span class="string"> test  </span>|<span class="string">          1 </span>|<span class="string"> union_x  </span>|<span class="string">            1 </span>|<span class="string"> name        </span>|<span class="string"> A         </span>|<span class="string">           0 </span>|<span class="string">     NULL </span>|<span class="string"> NULL   </span>|<span class="string"> YES  </span>|<span class="string"> BTREE      </span>|<span class="string">         </span>|<span class="string">               </span>|</span><br><span class="line">|<span class="string"> test  </span>|<span class="string">          1 </span>|<span class="string"> union_x  </span>|<span class="string">            2 </span>|<span class="string"> age         </span>|<span class="string"> A         </span>|<span class="string">           0 </span>|<span class="string">     NULL </span>|<span class="string"> NULL   </span>|<span class="string"> YES  </span>|<span class="string"> BTREE      </span>|<span class="string">         </span>|<span class="string">               </span>|</span><br><span class="line">+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span><br></pre></td></tr></table></figure><p>当然，由于采用的B+树实现的，<code>联合索引</code>底层叶子节点的数据也是按多列顺序排列。<br>对于联合索引，需要符合<code>最左原则</code>，才可以使用到索引。</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; explain select * from test where name = 1 and age = 1;</span><br><span class="line"><span class="code">+----+</span>-------------<span class="code">+-------+</span>------<span class="code">+---------------+</span>------<span class="code">+---------+</span>------<span class="code">+--------+</span>-------------+</span><br><span class="line">| id | select<span class="emphasis">_type | table | type | possible_</span>keys | key  | key<span class="emphasis">_len | ref  | rows   | Extra       |</span></span><br><span class="line"><span class="emphasis">+----+-------------+-------+------+---------------+------+---------+------+--------+-------------+</span></span><br><span class="line"><span class="emphasis">|  1 | SIMPLE      | test  | ALL  | union_</span>x       | NULL | NULL    | NULL | 997182 | Using where |</span><br><span class="line"><span class="code">+----+</span>-------------<span class="code">+-------+</span>------<span class="code">+---------------+</span>------<span class="code">+---------+</span>------<span class="code">+--------+</span>-------------+</span><br><span class="line"></span><br><span class="line">mysql&gt;  explain select * from test where age = 1 and name = 1;</span><br><span class="line"><span class="code">+----+</span>-------------<span class="code">+-------+</span>------<span class="code">+---------------+</span>------<span class="code">+---------+</span>------<span class="code">+--------+</span>-------------+</span><br><span class="line">| id | select<span class="emphasis">_type | table | type | possible_</span>keys | key  | key<span class="emphasis">_len | ref  | rows   | Extra       |</span></span><br><span class="line"><span class="emphasis">+----+-------------+-------+------+---------------+------+---------+------+--------+-------------+</span></span><br><span class="line"><span class="emphasis">|  1 | SIMPLE      | test  | ALL  | union_</span>x       | NULL | NULL    | NULL | 997182 | Using where |</span><br><span class="line"><span class="code">+----+</span>-------------<span class="code">+-------+</span>------<span class="code">+---------------+</span>------<span class="code">+---------+</span>------<span class="code">+--------+</span>-------------+</span><br><span class="line"></span><br><span class="line">mysql&gt;  explain select * from test where name = 1;</span><br><span class="line"><span class="code">+----+</span>-------------<span class="code">+-------+</span>------<span class="code">+---------------+</span>------<span class="code">+---------+</span>------<span class="code">+--------+</span>-------------+</span><br><span class="line">| id | select<span class="emphasis">_type | table | type | possible_</span>keys | key  | key<span class="emphasis">_len | ref  | rows   | Extra       |</span></span><br><span class="line"><span class="emphasis">+----+-------------+-------+------+---------------+------+---------+------+--------+-------------+</span></span><br><span class="line"><span class="emphasis">|  1 | SIMPLE      | test  | ALL  | union_</span>x       | NULL | NULL    | NULL | 997182 | Using where |</span><br><span class="line"><span class="code">+----+</span>-------------<span class="code">+-------+</span>------<span class="code">+---------------+</span>------<span class="code">+---------+</span>------<span class="code">+--------+</span>-------------+</span><br><span class="line"></span><br><span class="line">mysql&gt;  explain select * from test where age = 1;</span><br><span class="line"><span class="code">+----+</span>-------------<span class="code">+-------+</span>------<span class="code">+---------------+</span>------<span class="code">+---------+</span>------<span class="code">+--------+</span>-------------+</span><br><span class="line">| id | select<span class="emphasis">_type | table | type | possible_</span>keys | key  | key<span class="emphasis">_len | ref  | rows   | Extra       |</span></span><br><span class="line"><span class="emphasis">+----+-------------+-------+------+---------------+------+---------+------+--------+-------------+</span></span><br><span class="line"><span class="emphasis">|  1 | SIMPLE      | test  | ALL  | NULL          | NULL | NULL    | NULL | 997182 | Using where |</span></span><br><span class="line"><span class="emphasis">+----+-------------+-------+------+---------------+------+---------+------+--------+-------------+</span></span><br></pre></td></tr></table></figure><p>通过以上四个例子可以看到，联合索引如果按照其中一个列去查询的话，那就必须按照最左原则。<br>现在有联合索引&lt;name,age&gt;，通过<code>name</code>去查询<code>可以</code>用到索引，而通过<code>age</code>就<code>无法</code>使用索引。<br>如果<code>同时使用</code>name和age的话，在查询的where条件后面<code>可以</code>调整name和age的顺序且不影响索引的使用。</p><p>在联合索引的基础上，又产生了一种<code>覆盖索引</code>，也就是直接从非聚集索引上就可以查到数据。</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt;  explain select name,age from test where age = 1;</span><br><span class="line"><span class="code">+----+</span>-------------<span class="code">+-------+</span>-------<span class="code">+---------------+</span>---------<span class="code">+---------+</span>------<span class="code">+--------+</span>--------------------------+</span><br><span class="line">| id | select<span class="emphasis">_type | table | type  | possible_</span>keys | key     | key<span class="emphasis">_len | ref  | rows   | Extra                    |</span></span><br><span class="line"><span class="emphasis">+----+-------------+-------+-------+---------------+---------+---------+------+--------+--------------------------+</span></span><br><span class="line"><span class="emphasis">|  1 | SIMPLE      | test  | index | NULL          | union_</span>x | 38      | NULL | 997182 | Using where; Using index |</span><br><span class="line"><span class="code">+----+</span>-------------<span class="code">+-------+</span>-------<span class="code">+---------------+</span>---------<span class="code">+---------+</span>------<span class="code">+--------+</span>--------------------------+</span><br></pre></td></tr></table></figure><p>由于name、age组成了联合索引，通过非聚集索引（辅助索引）就可以找到name和age。<br>通过<code>覆盖索引</code>查询则无需再去聚集索引查询数据，可以减少磁盘I/O。</p><pre><code>上文提到B+树高度一般在2 ~ 4层，这是由InnoDB存储引擎数据组织方式决定的。</code></pre><p>在<code>磁盘</code>中，最小的存储单元<code>扇区</code>，每一个扇区大小为<code>512</code>字节。<br>在<code>文件系统</code>中，最小的存储单元是<code>块</code>，每一个块大小为<code>4</code>KB。<br>在<code>InnoDB</code>中，最小的存储单元是<code>页</code>，每一页大小为<code>16</code>KB。</p><p><img src="/images/innodb-driver.png" alt="innodb-driver"></p><p>在数据表中，数据都是存储在页上，一页<code>16KB</code>，如果一行数据<code>1KB</code>，那么一页可以存储<code>16行</code>数据。<br>假设主键大小为<code>8</code>字节，指针大小为<code>6</code>字节，则一个<code>非叶子节点页</code>可以存储<code>16*1024/(8+6)=1170</code>个单元。</p><p>如果高度为<code>2</code>，每个单元都指向一个页，那么可以存储<code>1170*16=18720</code>条记录。<br>如果高度为<code>3</code>，那么可以存储<code>1170*1170*16=21902400</code>条记录，大概<code>2000万</code>条。<br>如果高度为<code>4</code>，那么可以存储<code>1170*1170*1170*16=25625808000</code>条记录，大概<code>200亿</code>条。</p><p>一般来说，一张表数据量到了<code>2000万</code>条算多的了，不至于到<code>200亿</code>条。因此，<code>B+树高度一般在2-4层</code>，对于磁盘来说，<code>1秒</code>可以进行<code>100次</code>磁盘I/O操作，加载<code>3层B+树</code>，需要<code>3次磁盘I/O</code>，也就是<code>0.03秒</code>。</p>]]></content>
      
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux - BIO、NIO、AIO</title>
      <link href="/2020/01/30/Linux-BIO%E3%80%81NIO%E3%80%81AIO/"/>
      <url>/2020/01/30/Linux-BIO%E3%80%81NIO%E3%80%81AIO/</url>
      
        <content type="html"><![CDATA[<pre><code>在计算机通信中，I/O在数据交换中起到了至关重要的作用。    </code></pre><p>最初，只有<code>BIO</code>这种<code>同步阻塞</code>式的I/O编程通信模型。<br>随着计算机普及及流量的上涨，产生了<code>NIO</code>这种<code>同步非阻塞</code>式的I/O编程通信模型。<br>再后来，<code>NIO</code>出现了瓶颈，便产生了<code>AIO</code>这种<code>异步非阻塞</code>式的I/O编程通信模型。</p><pre><code>对于I/O类型，分为：文件I/O、网络I/O。</code></pre><p>文件I/O：基本<code>本地磁盘</code>，在内核空间与用户进程空间之间交换数据。<br>网络I/O：基本<code>网络Socket通信</code>，在不同（主机）进程之间交换数据。</p><pre><code>对于I/O方式，分为：同步、异步。</code></pre><p>同步方式：后续的操作<code>需要等待</code>前面操作完成才可以继续执行。<br>异步方式：后续的操作<code>不需要等待</code>前面操作完成，可以直接返回，通过event、callback调用。</p><pre><code>对于I/O状态，分为：阻塞、非阻塞。</code></pre><p>阻塞状态：当前执行的线程将处于<code>阻塞</code>状态，<code>无法</code>继续执行其他的任务。<br>非阻塞状态：当前执行的线程<code>不会</code>处于<code>阻塞</code>状态，<code>可以</code>继续其它任务，I/O操作由<code>后台</code>去处理。</p><pre><code>I/O通信模型围绕着上述方式和状态分为：BIO、NIO、AIO。</code></pre><p>首先，是<code>BIO</code>，同步阻塞I/O，最为原始，设计最简单，适用于并发线程少于1000的情况。<br>在服务端，绑定IP、监听端口，启动一个<code>Acceptor</code>线程，阻塞等待accept。<br>当客户端进发起连接请求时，创建一个线程进行Socket<code>连接</code>，等待与客户端之间进行<code>读写I/O流</code>操作。<br>客户端使用连接完毕之后，断开连接，销毁线程。<br>当然，由于创建线程成本过高，可以采用<code>线程池</code>进行优化线程成本。<br>但是，如果线程内部I/O阻塞，线程池资源也会带来瓶颈，也因此无法同时承受太多并发连接。</p><p><img src="/images/linux-bio.png" alt="linux-bio"></p><p><img src="/images/os-bio.png" alt="os-bio"></p><p>接着，是<code>NIO</code>，同步非阻塞I/O，底层基于<code>Reactor模型</code>来实现。<br>与<code>BIO</code>不同的是，在<code>NIO</code>中，客户端与服务端的Channel建立连接后，由<code>Selector</code>线程不断的去轮询，获取当前就绪的Channel。<br>而不是来一个请求直接启动一个线程。Selector是一个多路复用器，Channel被注册到Selector上。<br>客户端只与Channel进行交互，所有的读写不是基于流，而是基于Buffer，有I/O操作时才会创建线程。<br>通过多路复用器的轮询，而不是Acceptor的阻塞accept，实现了非阻塞I/O。<br>对于多路复用器轮询出可用Channel的操作，根据操作系统实现又包含有：select、poll、epoll、kqueue。</p><p><img src="/images/linux-nio.png" alt="linux-nio"></p><p><img src="/images/os-nio.png" alt="os-nio"></p><p><code>AIO</code>作为<code>NIO</code>的升级版，是异步非阻塞I/O，底层基于<code>Proactor模型</code>来实现，适用高并发场景。<br>整体上基于事件和回调机制，文件通道、套接字通道都是异步的，读写返回的是<code>Future</code>。<br>不需要再去注册相关感兴趣的key，只需要等待事件和I/O操作结果返回即可。</p><p><img src="/images/linux-aio.png" alt="linux-aio"></p><p>总的来说：<br>BIO，基于同步阻塞，适用连接较少且连接使用时间均匀的场景，耗费服务器资源较多。<br>NIO，基于同步非阻塞，适用连接较多且连接使用时间短的场景，充分利用服务器资源。<br>AIO，基于异步非阻塞，适用连接较多且连接使用时间长的场景，充分利用操作系统来完成并发操作。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka - 高性能原因</title>
      <link href="/2020/01/26/Kafka-%E9%AB%98%E6%80%A7%E8%83%BD%E5%8E%9F%E5%9B%A0/"/>
      <url>/2020/01/26/Kafka-%E9%AB%98%E6%80%A7%E8%83%BD%E5%8E%9F%E5%9B%A0/</url>
      
        <content type="html"><![CDATA[<pre><code>Kafka的高性能在于设计巧妙及借助操作系统特性。</code></pre><p>Kafka消息的<code>生产和消费</code>都是需要指定<code>Topic</code>的。</p><p>首先，从表面设计方面来看。</p><p>一个Topic可以拆分为多个Partition，而这些Partition可以均匀部署在<code>多个</code>Broker上，充分发挥<code>集群</code>的作用，实现<code>机器并行</code>处理。每个Partition再分为多个Segment，每次只有一个Segment可以进行日志的顺序写入，其它Segment可以根据<code>offset</code>进行读取。</p><p>对于日志的存储路径，Kafka支持多磁盘路径，通过配置<code>log.dirs</code>，按<code>逗号</code>分隔，可以实现<code>磁盘并行</code>处理。</p><p><img src="/images/kafka-hp.png" alt="kafka-hp"></p><p>接着，从底层实现方面来看。</p><p>Kafka采用了<code>顺序写</code>的方式，对于一些场景，<code>顺序写磁盘</code>比<code>随机写内存</code>来得快。</p><p>另外，由于<code>Segment</code>的存在，使得Kafka删除旧数据的时候更简单，直接删除老的Segment文件，而不需要操作一个文件去删除内容，也避免了随机写的操作。</p><p>Kafka充分利用了<code>Page Cache</code>，如果读写速率相当，只需要操作<code>Page Cache</code>即可，而不需要操作磁盘，数据会由<code>I/O调度器</code>定时组装成大块刷入磁盘中。</p><p>通过<code>Page Cache</code>的方式，Kafka不需要使用JVM的堆内存，也减少了GC的负担。</p><p>数据通过网络传输然后持久化到磁盘中，也从磁盘传输到网络中，Kafka采用了<code>NIO零拷贝机制</code>，减少了内核空间、用户空间的数据拷贝过程以及上下文切换次数。</p><p>Kafka从Producer到Broker发送的数据并没有直接发送过去，而是先<code>缓存</code>起来，积累一定条数或者等待一定时间，然后<code>合并、压缩、序列化</code>，<code>批量</code>发送到Broker，降低了网络负载，提高了传输效率。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka - 高可用设计</title>
      <link href="/2020/01/19/Kafka-%E9%AB%98%E5%8F%AF%E7%94%A8%E8%AE%BE%E8%AE%A1/"/>
      <url>/2020/01/19/Kafka-%E9%AB%98%E5%8F%AF%E7%94%A8%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<pre><code>Kafka的高可用主要围绕着：Data Replication、Leader Election 两方面来实现的。</code></pre><p><code>Data Replication</code>（数据备份），这种<code>冗余</code>数据的方式比较多见，一份数据不安全，那就来多份，再把这些数据<code>均匀分散</code>在多台主机上，即便是<code>部分主机宕机</code>，也不会影响整体。</p><p>这种方式虽好，却存在着<code>数据一致性</code>的问题。</p><p><img src="/images/kafka-ha.png" alt="kafka-ha"></p><p>副本与源头数据，由于<code>网络延迟</code>等原因导致数据不一致。</p><p>在Kafka中，源头称为<code>Leader</code>，副本称为<code>Replica</code>或者<code>Follower</code>，所有的读、写只会在<code>Leader</code>上操作，通过这种方式，可以<code>保证</code>数据的有序性，副本只从<code>Leader</code>拉取数据，可以<code>减少</code>数据同步通路数，<code>降低</code>副本设计的复杂度。当然，这种方式仍然存在<code>数据一致性</code>问题。</p><p>为了解决这个问题，Kafka定义了一个<code>ISR</code>（In-Sync Replica），所有数据同步完成或者没有落后<code>Leader</code>过多的副本都会被记入<code>ISR</code>中。当<code>Leader</code>宕机之后，新的<code>Leader</code>只会从<code>ISR</code>中选举。</p><p>当然，极端情况下，可能<code>ISR</code>中没有任何副本，这个时候就需要在<code>一致性</code>和<code>可用性</code>之间选择。</p><p>如果选择<code>一致性</code>，那么就需要等待<code>ISR</code>中的副本活过来，会<code>暂时不可用</code>。<br>如果选择<code>可用性</code>，那么就选择<code>第一个</code>活过来的副本，可能出现<code>数据丢失</code>。</p><p>为了实现更好的高可用，需要将<code>Topic</code>的<code>Partition</code>负载均衡到多个<code>Broker</code>，并且要保证<code>Partition</code>的个数<code>大于等于</code>拥有的<code>Broker</code>的个数，保证<code>单Broker</code>的<code>Partition</code>可靠性。</p><p>可以自定义<code>Partition</code>算法，默认算法是：</p><ul><li>将所有的Broker，假设<code>n</code>个和<code>Partition</code>排序。</li><li>将第<code>i</code>个Partition分配到第 <code>i mod n</code> 个Broker上。</li><li>将第<code>i</code>个Partition的第<code>j</code>个Replica分配到第 <code>（i+j）mod n</code> 个Broker上。</li></ul><p><img src="/images/kafka-repl.png" alt="kafka-repl"></p><p>对于<code>Leader Election</code>可以简单通过Zookeeper来完成，最先创建ZNode节点的就作为Leader。</p><p>但是，这种方式可能出现<code>脑裂</code>、<code>惊群</code>现象，造成多主、ZK压力过大。</p><p>还有流行的少数服从多数算法，但是这种要求至少一半存活，比较不靠谱。</p><p>Kafka在初始化的时候，启动了一个<code>KafkaController</code>，将<code>Leader Election</code>交给这个控制器来完成。</p><p>只有最先在Zookeeper上创建<code>/controller</code>节点的主机才可以作为控制器。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * This callback is invoked by the zookeeper leader elector on electing the current broker as the new controller.</span></span><br><span class="line"><span class="comment">  * It does the following things on the become-controller state change -</span></span><br><span class="line"><span class="comment">  * 1. Registers controller epoch changed listener</span></span><br><span class="line"><span class="comment">  * 2. Increments the controller epoch</span></span><br><span class="line"><span class="comment">  * 3. Initializes the controller's context object that holds cache objects for current topics, live brokers and</span></span><br><span class="line"><span class="comment">  *    leaders for all existing partitions.</span></span><br><span class="line"><span class="comment">  * 4. Starts the controller's channel manager</span></span><br><span class="line"><span class="comment">  * 5. Starts the replica state machine</span></span><br><span class="line"><span class="comment">  * 6. Starts the partition state machine</span></span><br><span class="line"><span class="comment">  * If it encounters any unexpected exception/error while becoming controller, it resigns as the current controller.</span></span><br><span class="line"><span class="comment">  * This ensures another controller election will be triggered and there will always be an actively serving controller</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">onControllerFailover</span></span>() &#123;</span><br><span class="line">   info(<span class="string">"Reading controller epoch from ZooKeeper"</span>)</span><br><span class="line">   <span class="comment">//读取zk上/controller_epoch的值</span></span><br><span class="line">   readControllerEpochFromZooKeeper()</span><br><span class="line">   info(<span class="string">"Incrementing controller epoch in ZooKeeper"</span>)</span><br><span class="line">   <span class="comment">//将/controller_epoch的值 +1</span></span><br><span class="line">   incrementControllerEpoch()</span><br><span class="line">   info(<span class="string">"Registering handlers"</span>)</span><br><span class="line">   </span><br><span class="line">   <span class="comment">//注册监听器，监听Topic、Broker、ISR等的变化</span></span><br><span class="line">   <span class="comment">// before reading source of truth from zookeeper, register the listeners to get broker/topic callbacks</span></span><br><span class="line">   <span class="keyword">val</span> childChangeHandlers = <span class="type">Seq</span>(brokerChangeHandler,topicChangeHandler, topicDeletionHandler,logDirEventNotificationHandler,isrChangeNotificationHandler)</span><br><span class="line">   childChangeHandlers.foreach(zkClient.registerZNodeChildChangeHandler)</span><br><span class="line">   <span class="keyword">val</span> nodeChangeHandlers = <span class="type">Seq</span>(preferredReplicaElectionHandler, partitionReassignmentHandler)</span><br><span class="line">   nodeChangeHandlers.foreach(zkClient.registerZNodeChangeHandlerAndCheckExistence)</span><br><span class="line">   <span class="comment">//删除监听器，isr变更或者日志目录变更会触发监听器，进行重分配</span></span><br><span class="line">   info(<span class="string">"Deleting log dir event notifications"</span>)</span><br><span class="line">   zkClient.deleteLogDirEventNotifications()</span><br><span class="line">   info(<span class="string">"Deleting isr change notifications"</span>)</span><br><span class="line">   zkClient.deleteIsrChangeNotifications()</span><br><span class="line">   info(<span class="string">"Initializing controller context"</span>)</span><br><span class="line">   <span class="comment">//初始化控制器上下文</span></span><br><span class="line">   initializeControllerContext()</span><br><span class="line">   info(<span class="string">"Fetching topic deletions in progress"</span>)</span><br><span class="line">   <span class="keyword">val</span> (topicsToBeDeleted, topicsIneligibleForDeletion) = fetchTopicDeletionsInProgress()</span><br><span class="line">   info(<span class="string">"Initializing topic deletion manager"</span>)</span><br><span class="line">   <span class="comment">//初始化Topic管理器</span></span><br><span class="line">   topicDeletionManager.init(topicsToBeDeleted, topicsIneligibleForDeletion)</span><br><span class="line"></span><br><span class="line">   <span class="comment">// We need to send UpdateMetadataRequest after the controller context is initialized and before the state machines</span></span><br><span class="line">   <span class="comment">// are started. The is because brokers need to receive the list of live brokers from UpdateMetadataRequest before</span></span><br><span class="line">   <span class="comment">// they can process the LeaderAndIsrRequests that are generated by replicaStateMachine.startup() and</span></span><br><span class="line">   <span class="comment">// partitionStateMachine.startup().</span></span><br><span class="line">   info(<span class="string">"Sending update metadata request"</span>)</span><br><span class="line">   sendUpdateMetadataRequest(controllerContext.liveOrShuttingDownBrokerIds.toSeq)</span><br><span class="line"></span><br><span class="line">   replicaStateMachine.startup()<span class="comment">//启动replica状态机</span></span><br><span class="line">   partitionStateMachine.startup()<span class="comment">//启动partition状态机</span></span><br><span class="line"></span><br><span class="line">   info(<span class="string">s"Ready to serve as the new controller with epoch <span class="subst">$epoch</span>"</span>)</span><br><span class="line">   <span class="comment">//触发重新分配</span></span><br><span class="line">   maybeTriggerPartitionReassignment(controllerContext.partitionsBeingReassigned.keySet)</span><br><span class="line">   <span class="comment">//尝试删除无效Topic</span></span><br><span class="line">   topicDeletionManager.tryTopicDeletion()</span><br><span class="line">   <span class="keyword">val</span> pendingPreferredReplicaElections = fetchPendingPreferredReplicaElections()</span><br><span class="line">   <span class="comment">//执行选举</span></span><br><span class="line">   onPreferredReplicaElection(pendingPreferredReplicaElections)</span><br><span class="line">   info(<span class="string">"Starting the controller scheduler"</span>)</span><br><span class="line">   <span class="comment">//启动kafka重分配定时任务</span></span><br><span class="line">   kafkaScheduler.startup()</span><br><span class="line">   <span class="keyword">if</span> (config.autoLeaderRebalanceEnable) &#123;</span><br><span class="line">     scheduleAutoLeaderRebalanceTask(delay = <span class="number">5</span>, unit = <span class="type">TimeUnit</span>.<span class="type">SECONDS</span>)</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">//启动token认证定时任务</span></span><br><span class="line">   <span class="keyword">if</span> (config.tokenAuthEnabled) &#123;</span><br><span class="line">     info(<span class="string">"starting the token expiry check scheduler"</span>)</span><br><span class="line">     tokenCleanScheduler.startup()</span><br><span class="line">     tokenCleanScheduler.schedule(name = <span class="string">"delete-expired-tokens"</span>,</span><br><span class="line">       fun = tokenManager.expireTokens,</span><br><span class="line">       period = config.delegationTokenExpiryCheckIntervalMs,</span><br><span class="line">       unit = <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka - 网络通信模型</title>
      <link href="/2020/01/18/Kafka-%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E6%A8%A1%E5%9E%8B/"/>
      <url>/2020/01/18/Kafka-%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<pre><code>Kafka的网络通信模型是基于Java NIO的Reactor多线程模型实现的。</code></pre><p>从Kakfa的<code>SocketServer.scala</code>中可以看到一段关于Kafka网络模型的说明。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * An NIO socket server. The threading model is</span></span><br><span class="line"><span class="comment"> *   1 Acceptor thread that handles new connections</span></span><br><span class="line"><span class="comment"> *   Acceptor has N Processor threads that each have their own selector and read requests from sockets</span></span><br><span class="line"><span class="comment"> *   M Handler threads that handle requests and produce responses back to the processor threads for writing.</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure><p>Kafka包含了<code>1个Acceptor</code>线程用来接收新<code>连接</code>、<code>N个Processor</code>线程用来处理<code>Socket</code>请求、<code>M个Handler</code>线程用来处理<code>业务</code>逻辑。</p><p>首先，对比一下几种NIO模型。</p><ul><li><p>普通NIO<br><img src="/images/common-nio.png" alt="common-nio"></p></li><li><p>高并发NIO<br><img src="/images/advance-nio.png" alt="advance-nio"></p></li><li><p>Kafka NIO<br><img src="/images/kafka-nio.png" alt="kafka-nio"></p></li></ul><p>接着，从源码层面来分析。</p><p>Broker启动的时候，会创建<code>Acceptor</code>以及<code>Processor</code>，并初始化<code>KafkaApis</code>及<code>请求处理池</code>。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Create and start the socket server acceptor threads so that the bound port is known.</span></span><br><span class="line"><span class="comment">// Delay starting processors until the end of the initialization sequence to ensure</span></span><br><span class="line"><span class="comment">// that credentials have been loaded before processing authentications.</span></span><br><span class="line"><span class="comment">//启动Acceptor，绑定端口</span></span><br><span class="line">socketServer = <span class="keyword">new</span> <span class="type">SocketServer</span>(config, metrics, time, credentialProvider)</span><br><span class="line">socketServer.startup(startupProcessors = <span class="literal">false</span>)</span><br></pre></td></tr></table></figure><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* start processing requests */</span></span><br><span class="line">apis = <span class="keyword">new</span> <span class="type">KafkaApis</span>(socketServer.requestChannel, replicaManager, adminManager, groupCoordinator, transactionCoordinator,</span><br><span class="line">  kafkaController, zkClient, config.brokerId, config, metadataCache, metrics, authorizer, quotaManagers,</span><br><span class="line">  fetchManager, brokerTopicStats, clusterId, time, tokenManager)</span><br></pre></td></tr></table></figure><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requestHandlerPool = <span class="keyword">new</span> <span class="type">KafkaRequestHandlerPool</span>(config.brokerId, socketServer.requestChannel, apis, time, config.numIoThreads)</span><br></pre></td></tr></table></figure><p>startup方法创建了连接数管理器、启动Acceptor线程及Processor线程。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>(startupProcessors: <span class="type">Boolean</span> = <span class="literal">true</span>) &#123;</span><br><span class="line">  <span class="keyword">this</span>.synchronized &#123;</span><br><span class="line">    <span class="comment">//用于维护单IP下的连接数，防止资源过载</span></span><br><span class="line">    connectionQuotas = <span class="keyword">new</span> <span class="type">ConnectionQuotas</span>(maxConnectionsPerIp, maxConnectionsPerIpOverrides)</span><br><span class="line">    createAcceptorAndProcessors(config.numNetworkThreads, config.listeners)</span><br><span class="line">    <span class="keyword">if</span> (startupProcessors) &#123;</span><br><span class="line">      startProcessors()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">createAcceptorAndProcessors</span></span>(processorsPerListener: <span class="type">Int</span>,</span><br><span class="line">                                        endpoints: <span class="type">Seq</span>[<span class="type">EndPoint</span>]): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> sendBufferSize = config.socketSendBufferBytes</span><br><span class="line">  <span class="keyword">val</span> recvBufferSize = config.socketReceiveBufferBytes</span><br><span class="line">  <span class="keyword">val</span> brokerId = config.brokerId</span><br><span class="line">  <span class="comment">//遍历server.properties配置的listeners属性，Kafka单机支持多协议、多端口</span></span><br><span class="line">  endpoints.foreach &#123; endpoint =&gt;</span><br><span class="line">    <span class="keyword">val</span> listenerName = endpoint.listenerName</span><br><span class="line">    <span class="keyword">val</span> securityProtocol = endpoint.securityProtocol</span><br><span class="line">    <span class="comment">//创建Acceptor线程，配置socket buffer，并开启nioSelector，启动端口监听客户端</span></span><br><span class="line">    <span class="keyword">val</span> acceptor = <span class="keyword">new</span> <span class="type">Acceptor</span>(endpoint, sendBufferSize, recvBufferSize, brokerId, connectionQuotas)</span><br><span class="line">    <span class="comment">//添加连接处理器Processor</span></span><br><span class="line">    addProcessors(acceptor, endpoint, processorsPerListener)</span><br><span class="line">    <span class="type">KafkaThread</span>.nonDaemon(<span class="string">s"kafka-socket-acceptor-<span class="subst">$listenerName</span>-<span class="subst">$securityProtocol</span>-<span class="subst">$&#123;endpoint.port&#125;</span>"</span>, acceptor).start()</span><br><span class="line">    acceptor.awaitStartup()</span><br><span class="line">    acceptors.put(endpoint, acceptor)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在Acceptor线程内部，不断循环，监听OP_ACCEPT事件，再将请求交给Processor去处理I/O。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Accept loop that checks for new connection attempts</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</span><br><span class="line">  serverChannel.register(nioSelector, <span class="type">SelectionKey</span>.<span class="type">OP_ACCEPT</span>)</span><br><span class="line">  startupComplete()</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> currentProcessor = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> (isRunning) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">val</span> ready = nioSelector.select(<span class="number">500</span>)</span><br><span class="line">        <span class="keyword">if</span> (ready &gt; <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">val</span> keys = nioSelector.selectedKeys()</span><br><span class="line">          <span class="keyword">val</span> iter = keys.iterator()</span><br><span class="line">          <span class="keyword">while</span> (iter.hasNext &amp;&amp; isRunning) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">              <span class="keyword">val</span> key = iter.next</span><br><span class="line">              iter.remove()</span><br><span class="line">              <span class="keyword">if</span> (key.isAcceptable) &#123;</span><br><span class="line">                <span class="keyword">val</span> processor = synchronized &#123;</span><br><span class="line">                  currentProcessor = currentProcessor % processors.size</span><br><span class="line">                  processors(currentProcessor)</span><br><span class="line">                &#125;</span><br><span class="line">                  <span class="comment">//获取连接</span></span><br><span class="line">                  accept(key, processor)</span><br><span class="line">              &#125; <span class="keyword">else</span></span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"Unrecognized key state for acceptor thread."</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 轮询到下一个Processor</span></span><br><span class="line">                currentProcessor = currentProcessor + <span class="number">1</span></span><br><span class="line">            &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">              <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Error while accepting connection"</span>, e)</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="comment">// We catch all the throwables to prevent the acceptor thread from exiting on exceptions due</span></span><br><span class="line">        <span class="comment">// to a select operation on a specific channel or a bad request. We don't want</span></span><br><span class="line">        <span class="comment">// the broker to stop responding to requests from other clients in these scenarios.</span></span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">ControlThrowable</span> =&gt; <span class="keyword">throw</span> e</span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Error occurred"</span>, e)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    debug(<span class="string">"Closing server socket and selector."</span>)</span><br><span class="line">    <span class="type">CoreUtils</span>.swallow(serverChannel.close(), <span class="keyword">this</span>, <span class="type">Level</span>.<span class="type">ERROR</span>)</span><br><span class="line">    <span class="type">CoreUtils</span>.swallow(nioSelector.close(), <span class="keyword">this</span>, <span class="type">Level</span>.<span class="type">ERROR</span>)</span><br><span class="line">    shutdownComplete()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Accept a new connection</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accept</span></span>(key: <span class="type">SelectionKey</span>, processor: <span class="type">Processor</span>) &#123;</span><br><span class="line">  <span class="keyword">val</span> serverSocketChannel = key.channel().asInstanceOf[<span class="type">ServerSocketChannel</span>]</span><br><span class="line">  <span class="comment">//监听新连接</span></span><br><span class="line">  <span class="keyword">val</span> socketChannel = serverSocketChannel.accept()</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">//增加连接数</span></span><br><span class="line">    connectionQuotas.inc(socketChannel.socket().getInetAddress)</span><br><span class="line">    socketChannel.configureBlocking(<span class="literal">false</span>)</span><br><span class="line">    socketChannel.socket().setTcpNoDelay(<span class="literal">true</span>)</span><br><span class="line">    socketChannel.socket().setKeepAlive(<span class="literal">true</span>)</span><br><span class="line">    <span class="keyword">if</span> (sendBufferSize != <span class="type">Selectable</span>.<span class="type">USE_DEFAULT_BUFFER_SIZE</span>)</span><br><span class="line">      socketChannel.socket().setSendBufferSize(sendBufferSize)</span><br><span class="line">    debug(<span class="string">"Accepted connection from %s on %s and assigned it to processor %d, sendBufferSize [actual|requested]: [%d|%d] recvBufferSize [actual|requested]: [%d|%d]"</span></span><br><span class="line">          .format(socketChannel.socket.getRemoteSocketAddress, socketChannel.socket.getLocalSocketAddress, processor.id,</span><br><span class="line">                socketChannel.socket.getSendBufferSize, sendBufferSize,</span><br><span class="line">                socketChannel.socket.getReceiveBufferSize, recvBufferSize))</span><br><span class="line">      <span class="comment">//Processor处理I/O事件</span></span><br><span class="line">      processor.accept(socketChannel)</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">TooManyConnectionsException</span> =&gt;</span><br><span class="line">      info(<span class="string">"Rejected connection from %s, address already has the configured maximum of %d connections."</span>.format(e.ip, e.count))</span><br><span class="line">      close(socketChannel)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Processor的accept将socketChannel存放在<code>ConcurrentLinkedQueue</code>中。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Queue up a new connection for reading</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accept</span></span>(socketChannel: <span class="type">SocketChannel</span>) &#123;</span><br><span class="line">  newConnections.add(socketChannel)</span><br><span class="line">  wakeup()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后由Processor线程从队列中获取连接并交给<code>RequestChannel</code>处理。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</span><br><span class="line">  startupComplete()<span class="comment">//CountDownLatch</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (isRunning) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="comment">//从队列中取出连接</span></span><br><span class="line">          configureNewConnections()</span><br><span class="line">          <span class="comment">//处理responseQueue</span></span><br><span class="line">          processNewResponses()</span><br><span class="line">          <span class="comment">//selector.poll</span></span><br><span class="line">          poll()</span><br><span class="line">          <span class="comment">//处理requestQueue</span></span><br><span class="line">          processCompletedReceives()</span><br><span class="line">          <span class="comment">//移除inflightResponses</span></span><br><span class="line">          processCompletedSends()</span><br><span class="line">          <span class="comment">//移除连接</span></span><br><span class="line">          processDisconnected()</span><br><span class="line">      &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="comment">// We catch all the throwables here to prevent the processor thread from exiting. We do this because</span></span><br><span class="line">        <span class="comment">// letting a processor exit might cause a bigger impact on the broker. This behavior might need to be</span></span><br><span class="line">        <span class="comment">// reviewed if we see an exception that needs the entire broker to stop. Usually the exceptions thrown would</span></span><br><span class="line">        <span class="comment">// be either associated with a specific socket channel or a bad request. These exceptions are caught and</span></span><br><span class="line">        <span class="comment">// processed by the individual methods above which close the failing channel and continue processing other</span></span><br><span class="line">        <span class="comment">// channels. So this catch block should only ever see ControlThrowables.</span></span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; processException(<span class="string">"Processor got uncaught exception."</span>, e)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    debug(<span class="string">"Closing selector - processor "</span> + id)</span><br><span class="line">    <span class="type">CoreUtils</span>.swallow(closeAll(), <span class="keyword">this</span>, <span class="type">Level</span>.<span class="type">ERROR</span>)</span><br><span class="line">    shutdownComplete()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后，由<code>KafkaRequestHandlerPool</code>实现的简单线程池启动的<code>KafkaRequestHandler</code>线程，不断从<code>RequestChannel</code>中的<code>requestQueue</code>获取请求，然后调用<code>KafkaApis</code>处理业务逻辑，再返回给<code>RequestChannel</code>的<code>responseQueue</code>。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KafkaRequestHandlerPool</span>(<span class="params">val brokerId: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                              val requestChannel: <span class="type">RequestChannel</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                              val apis: <span class="type">KafkaApis</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                              time: <span class="type">Time</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                              numThreads: <span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> <span class="keyword">with</span> <span class="title">KafkaMetricsGroup</span> </span>&#123;</span><br><span class="line">  <span class="comment">//线程池大小</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> threadPoolSize: <span class="type">AtomicInteger</span> = <span class="keyword">new</span> <span class="type">AtomicInteger</span>(numThreads)</span><br><span class="line">  <span class="comment">/* a meter to track the average free capacity of the request handlers */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> aggregateIdleMeter = newMeter(<span class="string">"RequestHandlerAvgIdlePercent"</span>, <span class="string">"percent"</span>, <span class="type">TimeUnit</span>.<span class="type">NANOSECONDS</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">this</span>.logIdent = <span class="string">"[Kafka Request Handler on Broker "</span> + brokerId + <span class="string">"], "</span></span><br><span class="line">  <span class="keyword">val</span> runnables = <span class="keyword">new</span> mutable.<span class="type">ArrayBuffer</span>[<span class="type">KafkaRequestHandler</span>](numThreads)</span><br><span class="line">  <span class="keyword">for</span> (i &lt;- <span class="number">0</span> until numThreads) &#123;</span><br><span class="line">    createHandler(i)</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">//启动KafkaRequestHandler线程</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">createHandler</span></span>(id: <span class="type">Int</span>): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">    runnables += <span class="keyword">new</span> <span class="type">KafkaRequestHandler</span>(id, brokerId, aggregateIdleMeter, threadPoolSize, requestChannel, apis, time)</span><br><span class="line">    <span class="type">KafkaThread</span>.daemon(<span class="string">"kafka-request-handler-"</span> + id, runnables(id)).start()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">resizeThreadPool</span></span>(newSize: <span class="type">Int</span>): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">    <span class="keyword">val</span> currentSize = threadPoolSize.get</span><br><span class="line">    info(<span class="string">s"Resizing request handler thread pool size from <span class="subst">$currentSize</span> to <span class="subst">$newSize</span>"</span>)</span><br><span class="line">    <span class="keyword">if</span> (newSize &gt; currentSize) &#123;</span><br><span class="line">      <span class="keyword">for</span> (i &lt;- currentSize until newSize) &#123;</span><br><span class="line">        createHandler(i)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (newSize &lt; currentSize) &#123;</span><br><span class="line">      <span class="keyword">for</span> (i &lt;- <span class="number">1</span> to (currentSize - newSize)) &#123;</span><br><span class="line">        runnables.remove(currentSize - i).stop()</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    threadPoolSize.set(newSize)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">shutdown</span></span>(): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">    info(<span class="string">"shutting down"</span>)</span><br><span class="line">    <span class="keyword">for</span> (handler &lt;- runnables)</span><br><span class="line">      handler.initiateShutdown()</span><br><span class="line">    <span class="keyword">for</span> (handler &lt;- runnables)</span><br><span class="line">      handler.awaitShutdown()</span><br><span class="line">    info(<span class="string">"shut down completely"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * A thread that answers kafka requests.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KafkaRequestHandler</span>(<span class="params">id: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                          brokerId: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                          val aggregateIdleMeter: <span class="type">Meter</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                          val totalHandlerThreads: <span class="type">AtomicInteger</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                          val requestChannel: <span class="type">RequestChannel</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                          apis: <span class="type">KafkaApis</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                          time: <span class="type">Time</span></span>) <span class="keyword">extends</span> <span class="title">Runnable</span> <span class="keyword">with</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.logIdent = <span class="string">"[Kafka Request Handler "</span> + id + <span class="string">" on Broker "</span> + brokerId + <span class="string">"], "</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> shutdownComplete = <span class="keyword">new</span> <span class="type">CountDownLatch</span>(<span class="number">1</span>)</span><br><span class="line">  <span class="meta">@volatile</span> <span class="keyword">private</span> <span class="keyword">var</span> stopped = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</span><br><span class="line">    <span class="keyword">while</span> (!stopped) &#123;</span><br><span class="line">      <span class="comment">// We use a single meter for aggregate idle percentage for the thread pool.</span></span><br><span class="line">      <span class="comment">// Since meter is calculated as total_recorded_value / time_window and</span></span><br><span class="line">      <span class="comment">// time_window is independent of the number of threads, each recorded idle</span></span><br><span class="line">      <span class="comment">// time should be discounted by # threads.</span></span><br><span class="line">      <span class="keyword">val</span> startSelectTime = time.nanoseconds</span><br><span class="line">      <span class="comment">//获取请求</span></span><br><span class="line">      <span class="keyword">val</span> req = requestChannel.receiveRequest(<span class="number">300</span>)</span><br><span class="line">      <span class="keyword">val</span> endTime = time.nanoseconds</span><br><span class="line">      <span class="keyword">val</span> idleTime = endTime - startSelectTime</span><br><span class="line">      aggregateIdleMeter.mark(idleTime / totalHandlerThreads.get)</span><br><span class="line">      </span><br><span class="line">      req <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">RequestChannel</span>.<span class="type">ShutdownRequest</span> =&gt;</span><br><span class="line">          debug(<span class="string">s"Kafka request handler <span class="subst">$id</span> on broker <span class="subst">$brokerId</span> received shut down command"</span>)</span><br><span class="line">          shutdownComplete.countDown()</span><br><span class="line">          <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">case</span> request: <span class="type">RequestChannel</span>.<span class="type">Request</span> =&gt;</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">            request.requestDequeueTimeNanos = endTime</span><br><span class="line">            trace(<span class="string">s"Kafka request handler <span class="subst">$id</span> on broker <span class="subst">$brokerId</span> handling request <span class="subst">$request</span>"</span>)</span><br><span class="line">            <span class="comment">//由KafkaApis来处理业务逻辑</span></span><br><span class="line">            apis.handle(request)</span><br><span class="line">          &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> e: <span class="type">FatalExitError</span> =&gt;</span><br><span class="line">              shutdownComplete.countDown()</span><br><span class="line">              <span class="type">Exit</span>.exit(e.statusCode)</span><br><span class="line">            <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Exception when handling request"</span>, e)</span><br><span class="line">          &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            request.releaseBuffer()</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">case</span> <span class="literal">null</span> =&gt; <span class="comment">// continue</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    shutdownComplete.countDown()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">stop</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    stopped = <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">initiateShutdown</span></span>(): <span class="type">Unit</span> = requestChannel.sendShutdownRequest()</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">awaitShutdown</span></span>(): <span class="type">Unit</span> = shutdownComplete.await()</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>KafkaApis</code>的<code>handle</code>方法逻辑。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Top-level method that handles all requests and multiplexes to the right api</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">handle</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>) &#123;</span><br><span class="line">   <span class="keyword">try</span> &#123;</span><br><span class="line">     trace(<span class="string">s"Handling request:<span class="subst">$&#123;request.requestDesc(true)&#125;</span> from connection <span class="subst">$&#123;request.context.connectionId&#125;</span>;"</span> +</span><br><span class="line">       <span class="string">s"securityProtocol:<span class="subst">$&#123;request.context.securityProtocol&#125;</span>,principal:<span class="subst">$&#123;request.context.principal&#125;</span>"</span>)</span><br><span class="line">     request.header.apiKey <span class="keyword">match</span> &#123;</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">PRODUCE</span> =&gt; handleProduceRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">FETCH</span> =&gt; handleFetchRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">LIST_OFFSETS</span> =&gt; handleListOffsetRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">METADATA</span> =&gt; handleTopicMetadataRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">LEADER_AND_ISR</span> =&gt; handleLeaderAndIsrRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">STOP_REPLICA</span> =&gt; handleStopReplicaRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">UPDATE_METADATA</span> =&gt; handleUpdateMetadataRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">CONTROLLED_SHUTDOWN</span> =&gt; handleControlledShutdownRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">OFFSET_COMMIT</span> =&gt; handleOffsetCommitRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">OFFSET_FETCH</span> =&gt; handleOffsetFetchRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">FIND_COORDINATOR</span> =&gt; handleFindCoordinatorRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">JOIN_GROUP</span> =&gt; handleJoinGroupRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">HEARTBEAT</span> =&gt; handleHeartbeatRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">LEAVE_GROUP</span> =&gt; handleLeaveGroupRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">SYNC_GROUP</span> =&gt; handleSyncGroupRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">DESCRIBE_GROUPS</span> =&gt; handleDescribeGroupRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">LIST_GROUPS</span> =&gt; handleListGroupsRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">SASL_HANDSHAKE</span> =&gt; handleSaslHandshakeRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">API_VERSIONS</span> =&gt; handleApiVersionsRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">CREATE_TOPICS</span> =&gt; handleCreateTopicsRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">DELETE_TOPICS</span> =&gt; handleDeleteTopicsRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">DELETE_RECORDS</span> =&gt; handleDeleteRecordsRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">INIT_PRODUCER_ID</span> =&gt; handleInitProducerIdRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">OFFSET_FOR_LEADER_EPOCH</span> =&gt; handleOffsetForLeaderEpochRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">ADD_PARTITIONS_TO_TXN</span> =&gt; handleAddPartitionToTxnRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">ADD_OFFSETS_TO_TXN</span> =&gt; handleAddOffsetsToTxnRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">END_TXN</span> =&gt; handleEndTxnRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">WRITE_TXN_MARKERS</span> =&gt; handleWriteTxnMarkersRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">TXN_OFFSET_COMMIT</span> =&gt; handleTxnOffsetCommitRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">DESCRIBE_ACLS</span> =&gt; handleDescribeAcls(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">CREATE_ACLS</span> =&gt; handleCreateAcls(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">DELETE_ACLS</span> =&gt; handleDeleteAcls(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">ALTER_CONFIGS</span> =&gt; handleAlterConfigsRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">DESCRIBE_CONFIGS</span> =&gt; handleDescribeConfigsRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">ALTER_REPLICA_LOG_DIRS</span> =&gt; handleAlterReplicaLogDirsRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">DESCRIBE_LOG_DIRS</span> =&gt; handleDescribeLogDirsRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">SASL_AUTHENTICATE</span> =&gt; handleSaslAuthenticateRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">CREATE_PARTITIONS</span> =&gt; handleCreatePartitionsRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">CREATE_DELEGATION_TOKEN</span> =&gt; handleCreateTokenRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">RENEW_DELEGATION_TOKEN</span> =&gt; handleRenewTokenRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">EXPIRE_DELEGATION_TOKEN</span> =&gt; handleExpireTokenRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">DESCRIBE_DELEGATION_TOKEN</span> =&gt; handleDescribeTokensRequest(request)</span><br><span class="line">       <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">DELETE_GROUPS</span> =&gt; handleDeleteGroupsRequest(request)</span><br><span class="line">     &#125;</span><br><span class="line">   &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">     <span class="keyword">case</span> e: <span class="type">FatalExitError</span> =&gt; <span class="keyword">throw</span> e</span><br><span class="line">     <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; handleError(request, e)</span><br><span class="line">   &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">     request.apiLocalCompleteTimeNanos = time.nanoseconds</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>每个业务处理完结果都存入<code>RequestChannel</code>中。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">sendResponse</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>, responseOpt: <span class="type">Option</span>[<span class="type">AbstractResponse</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// Update error metrics for each error code in the response including Errors.NONE</span></span><br><span class="line">  responseOpt.foreach(response =&gt; requestChannel.updateErrorMetrics(request.header.apiKey, response.errorCounts.asScala))</span><br><span class="line"></span><br><span class="line">  responseOpt <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Some</span>(response) =&gt;</span><br><span class="line">      <span class="keyword">val</span> responseSend = request.context.buildResponse(response)</span><br><span class="line">      <span class="keyword">val</span> responseString =</span><br><span class="line">        <span class="keyword">if</span> (<span class="type">RequestChannel</span>.isRequestLoggingEnabled) <span class="type">Some</span>(response.toString(request.context.apiVersion))</span><br><span class="line">        <span class="keyword">else</span> <span class="type">None</span></span><br><span class="line">      requestChannel.sendResponse(<span class="keyword">new</span> <span class="type">RequestChannel</span>.<span class="type">Response</span>(request, <span class="type">Some</span>(responseSend), <span class="type">SendAction</span>, responseString))</span><br><span class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">      requestChannel.sendResponse(<span class="keyword">new</span> <span class="type">RequestChannel</span>.<span class="type">Response</span>(request, <span class="type">None</span>, <span class="type">NoOpAction</span>, <span class="type">None</span>))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Send a response back to the socket server to be sent over the network */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sendResponse</span></span>(response: <span class="type">RequestChannel</span>.<span class="type">Response</span>) &#123;</span><br><span class="line">  <span class="keyword">if</span> (isTraceEnabled) &#123;</span><br><span class="line">    <span class="keyword">val</span> requestHeader = response.request.header</span><br><span class="line">    <span class="keyword">val</span> message = response.responseAction <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">SendAction</span> =&gt;</span><br><span class="line">        <span class="string">s"Sending <span class="subst">$&#123;requestHeader.apiKey&#125;</span> response to client <span class="subst">$&#123;requestHeader.clientId&#125;</span> of <span class="subst">$&#123;response.responseSend.get.size&#125;</span> bytes."</span></span><br><span class="line">      <span class="keyword">case</span> <span class="type">NoOpAction</span> =&gt;</span><br><span class="line">        <span class="string">s"Not sending <span class="subst">$&#123;requestHeader.apiKey&#125;</span> response to client <span class="subst">$&#123;requestHeader.clientId&#125;</span> as it's not required."</span></span><br><span class="line">      <span class="keyword">case</span> <span class="type">CloseConnectionAction</span> =&gt;</span><br><span class="line">        <span class="string">s"Closing connection for client <span class="subst">$&#123;requestHeader.clientId&#125;</span> due to error during <span class="subst">$&#123;requestHeader.apiKey&#125;</span>."</span></span><br><span class="line">    &#125;</span><br><span class="line">    trace(message)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> processor = processors.get(response.processor)</span><br><span class="line">  <span class="comment">// The processor may be null if it was shutdown. In this case, the connections</span></span><br><span class="line">  <span class="comment">// are closed, so the response is dropped.</span></span><br><span class="line">  <span class="keyword">if</span> (processor != <span class="literal">null</span>) &#123;</span><br><span class="line">    processor.enqueueResponse(response)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[network] <span class="function"><span class="keyword">def</span> <span class="title">enqueueResponse</span></span>(response: <span class="type">RequestChannel</span>.<span class="type">Response</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  responseQueue.put(response)</span><br><span class="line">  wakeup()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka - 消息到达保证机制</title>
      <link href="/2020/01/16/Kafka-%E6%B6%88%E6%81%AF%E5%88%B0%E8%BE%BE%E4%BF%9D%E8%AF%81%E6%9C%BA%E5%88%B6/"/>
      <url>/2020/01/16/Kafka-%E6%B6%88%E6%81%AF%E5%88%B0%E8%BE%BE%E4%BF%9D%E8%AF%81%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<pre><code>Kafka消费端采用pull模式，为消费端提供了更多的控制权。</code></pre><p>如果broker采用push模式，能更快的将消息推送给消费端，但无法适应消费端的消费能力，使消费端崩溃。</p><p>采用pull模式，可自主控制消费速率及消费的方式（批量、单条），并且可以表述不同的传输语义。</p><p>Kafka中包含了三种传输语义：</p><ul><li><code>At Most Once</code> 消息可能会丢，但不会重复。</li></ul><p><img src="/images/kafka-amo.png" alt="kafka-amo"></p><p>在这种模式下，先<code>Commit</code> Offset，再去<code>处理</code>消息。<br>如果Commit<code>成功</code>了，此时消费端<code>宕机</code>了，那么下次恢复的时候，消息不会再下发，也就<code>丢了</code>。</p><ul><li><code>At Least Once</code> 消息不会丢，但可能会重复（默认模式）。</li></ul><p><img src="/images/kafka-alo.png" alt="kafka-alo"></p><p>在这种模式下，先<code>处理</code>消息，再<code>Commit</code> Offset。<br>如果Commit<code>失败</code>了，那么这条消息还会继续下发，直到Offset <code>Commit成功</code>，也就<code>重了</code>。</p><ul><li><code>Exactly Once</code> 消息不会丢且不会重复。</li></ul><p><img src="/images/kafka-eo.png" alt="kafka-eo"></p><p>以<code>At Least Once</code> 为基础，让下游保证<code>幂等</code>，并且保存消息处理状态、Offset提交状态，间接实现<code>Exactly Once</code>。而要真正实现<code>Exactly Once</code>，需要引入<code>两阶段</code>事务处理，对于消息乱序、消息重复，采用类似TCP三次握手的<code>ACK</code>机制，对于单Session的，可以这么简单处理，对于多Session的，需要基于事务来实现类似分布式锁、分布式Session，记录所有事务状态、事务进度、判断是否合法，要么全部成功，要么全部失败。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka - 日志、索引、分区、分段设计</title>
      <link href="/2020/01/15/Kafka-%E6%97%A5%E5%BF%97%E3%80%81%E7%B4%A2%E5%BC%95%E3%80%81%E5%88%86%E5%8C%BA%E3%80%81%E5%88%86%E6%AE%B5%E8%AE%BE%E8%AE%A1/"/>
      <url>/2020/01/15/Kafka-%E6%97%A5%E5%BF%97%E3%80%81%E7%B4%A2%E5%BC%95%E3%80%81%E5%88%86%E5%8C%BA%E3%80%81%E5%88%86%E6%AE%B5%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<pre><code>Topic是Kafka的基本组织单位。</code></pre><p>Kafka的<code>消息</code>是以<code>Topic</code>作为<code>基本单位</code>来组织的，而多个Topic之间又是<code>相互独立</code>的。</p><p>形象的说，可以将Kafka当成一个<code>队列集合</code>，每一个Topic相当于一个<code>队列</code>。</p><p>每个Topic又分为多个Partition，也就是<code>分区</code>，分别存储了一部分的<code>消息</code>，也起到了<code>负载均衡</code>的作用。</p><p>创建Topic的时候，可以指定partition的个数，最终以文件形式存储在磁盘上。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kafka-topics.sh --create --partitions 3 --topic test_p_3 --zookeeper localhost:2181 --replication-factor 1</span><br></pre></td></tr></table></figure><p><img src="/images/kafka-tps.png" alt="kafka-tps.png"></p><p>每个partition以<code>Topic名称-Partition序号</code>来命名，底下又分为多个<code>Segment</code>，也就是<code>分段</code>。</p><p>生产消息的时候，需要指定Topic，而Topic根据Partition路由算法，路由到具体Partition。</p><p><img src="/images/kafka-p-j.png" alt="kafka-p-j"></p><p>同一个Topic，每一个partition各自处理各自的消息。</p><p><img src="/images/kafka-partition.png" alt="ukafka-partition.png"></p><p>每一个<code>segment</code>包含：日志（用来存储消息数据）和索引（用来记录offset相关映射信息）</p><p>通过<code>分段</code>，可以<code>减少</code>文件的大小以及通过<code>稀疏索引</code>进一步实现数据的<code>快速</code>查找。</p><p>可以通过配置<code>log.dirs</code>的值来修改数据存储的位置，默认是在<code>/tmp/kafka-logs</code>目录下。</p><p><img src="/images/kafka-logs.png" alt="kafka-logs"></p><pre><code>以相同基准offset命名的日志、索引文件，称为段。</code></pre><p>如果一个partition只有一个数据文件的话：</p><ul><li><p>对于写入<br>由于是顺序追加写入，时间复杂度为O(1)</p></li><li><p>对于查找<br>要查找某个offset，采用的是顺序查找，时间复杂度达到了O(n)</p></li></ul><p>通过对数据进行分段、加索引，解决了痛点。</p><p>在Kafka中，索引文件分为：</p><table><thead><tr><th align="center">name</th><th align="center">type</th><th align="center">suffix</th></tr></thead><tbody><tr><td align="center">偏移量索引</td><td align="center">OffsetIndex</td><td align="center">.index</td></tr><tr><td align="center">时间戳索引</td><td align="center">TimeIndex</td><td align="center">.timeindex</td></tr><tr><td align="center">事务索引</td><td align="center">TransactionIndex</td><td align="center">.txnindex</td></tr></tbody></table><p>日志文件分为：</p><table><thead><tr><th align="center">name</th><th align="center">suffix</th><th align="center">desc</th></tr></thead><tbody><tr><td align="center">数据文件</td><td align="center">.log</td><td align="center">用于存储消息</td></tr><tr><td align="center">交换文件</td><td align="center">.swap</td><td align="center">用于segment的恢复</td></tr><tr><td align="center">延迟待删文件</td><td align="center">.deleted</td><td align="center">用于标识要删除的文件</td></tr><tr><td align="center">快照文件</td><td align="center">.snapshot</td><td align="center">用于记录producer的事务信息</td></tr><tr><td align="center">清理临时文件</td><td align="center">.cleaned</td><td align="center">用于标识正在删除的文件</td></tr></tbody></table><p><strong>分段</strong></p><p>假设有100条消息，offset取值范围在：0 - 99，如果分为4个段，那么每一个段各存储25条消息，取值范围分别为：0 - 24、25 - 49、 50 - 74、75 - 99，而每一段的文件以<code>20位起始offset</code>来命名，不足20位，用0补齐，要查找某个offset只需要找到对应范围内的文件，然后再通过<code>二分查找</code>算法去文件查找即可。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 通过kafka.tools.DumpLogSegments可以查看log文件的内容</span><br><span class="line">./kafka-run-class.sh kafka.tools.DumpLogSegments --files /tmp/kafka-logs/test_p_3-0/00000000000000000000.log</span><br></pre></td></tr></table></figure><p><img src="/images/kafka-sg.png" alt="kafka-sg"></p><p><strong>索引</strong></p><p>通过分段可以减少数据文件大小，并且加快查询速度，但仍然存在顺序查找的最差情况。</p><p>为了进一步提高数据查找的速度，Kafka通过建立<code>稀疏索引</code>的方式，每隔一定间隔建立一条索引。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 通过kafka.tools.DumpLogSegments可以查看index文件的内容</span><br><span class="line">./kafka-run-class.sh kafka.tools.DumpLogSegments --files /tmp/kafka-logs/test_p_3-0/00000000000000000000.index</span><br></pre></td></tr></table></figure><p><img src="/images/kafka-index.png" alt="kafka-index"></p><p>偏移量索引，记录着 <code>&lt; offset , position &gt;</code> 偏移量 - 物理地址</p><p>时间戳索引，记录着 <code>&lt; timestamp , offset &gt;</code>时间戳 - 偏移量</p><p>事务索引，记录着 <code>&lt; offset , AbortedTxn &gt;</code> 偏移量 - 被中断事务</p><pre><code>消息查找：offset、timestamp</code></pre><p>在Kafka中，segment通过一个跳跃表来维护。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* the actual segments of the log */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> segments: <span class="type">ConcurrentNavigableMap</span>[java.lang.<span class="type">Long</span>, <span class="type">LogSegment</span>] = <span class="keyword">new</span> <span class="type">ConcurrentSkipListMap</span>[java.lang.<span class="type">Long</span>, <span class="type">LogSegment</span>]</span><br></pre></td></tr></table></figure><p>每一次，只有一个<code>activeSegment</code>可以进行写入消息，其它的<code>segment</code>是只读的。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The active segment that is currently taking appends</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">activeSegment</span> </span>= segments.lastEntry.getValue</span><br></pre></td></tr></table></figure><p><strong>基于偏移量查找</strong></p><p><code>OffsetIndex</code>的数据格式为：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">offset:</span> <span class="number">33</span> <span class="string">position</span> <span class="number">4158</span></span><br><span class="line"><span class="attr">offset:</span> <span class="number">66</span> <span class="string">position</span> <span class="number">8316</span></span><br><span class="line"><span class="attr">offset:</span> <span class="number">99</span> <span class="string">position</span> <span class="number">12474</span></span><br></pre></td></tr></table></figure><p>在Kafka的<code>IndexEntry.scala</code>中定义为：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The mapping between a logical log offset and the physical position</span></span><br><span class="line"><span class="comment"> * in some log file of the beginning of the message set entry with the</span></span><br><span class="line"><span class="comment"> * given offset.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">OffsetPosition</span>(<span class="params">offset: <span class="type">Long</span>, position: <span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">IndexEntry</span> </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">indexKey</span> </span>= offset</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">indexValue</span> </span>= position.toLong</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果要查找<code>offset=35</code>的消息，那么就先从<code>segments</code>跳跃表上找到对应应访问的<code>segment</code>文件。</p><p>然后通过<code>二分查找</code>在偏移量索引文件找到不大于35的offset，也就是<code>offset: 33 position 4158</code>。</p><p>解析offset对应的<code>position</code>，从position处顺序查找<code>log文件</code>，找到<code>offset=35</code>的位置。</p><p><strong>基于时间戳查找</strong></p><p><code>TimeIndex</code>的数据格式为：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">timestamp:</span> <span class="number">1579167998000</span> <span class="string">offset</span> <span class="number">33</span></span><br><span class="line"><span class="attr">timestamp:</span> <span class="number">1579168197621</span> <span class="string">offset</span> <span class="number">66</span></span><br><span class="line"><span class="attr">timestamp:</span> <span class="number">1579168397242</span> <span class="string">offset</span> <span class="number">99</span></span><br></pre></td></tr></table></figure><p>在Kafka的<code>IndexEntry.scala</code>中定义为：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The mapping between a timestamp to a message offset. The entry means that any message whose timestamp is greater</span></span><br><span class="line"><span class="comment"> * than that timestamp must be at or after that offset.</span></span><br><span class="line"><span class="comment"> * @param timestamp The max timestamp before the given offset.</span></span><br><span class="line"><span class="comment"> * @param offset The message offset.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">TimestampOffset</span>(<span class="params">timestamp: <span class="type">Long</span>, offset: <span class="type">Long</span></span>) <span class="keyword">extends</span> <span class="title">IndexEntry</span> </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">indexKey</span> </span>= timestamp</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">indexValue</span> </span>= offset</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果要查找<code>timestamp=15791679981234</code>的消息，那么就先比较每个<code>segment</code>文件的<code>largestTimestamp</code>，找到对应的<code>segment</code>文件。</p><p>然后通过<code>二分查找</code>在时间戳索引文件找到不大于<code>15791679981234</code>的<code>timestamp</code>，也就是<code>timestamp: 1579167998000 offset 33</code>。</p><p>找到offset直接去偏移量索引文件中查找position。</p><p>从position处顺序查找<code>log文件</code>，找到<code>timestamp=15791679981234</code>的位置。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka - 启动流程分析</title>
      <link href="/2020/01/09/Kafka-%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/"/>
      <url>/2020/01/09/Kafka-%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<pre><code>通常，应用程序的启动都是基于main函数的，Kafka也不例外。</code></pre><p>启动<code>Kafka</code>的时候，通过执行<code>kafka-server-start.sh</code>文件，并且指定配置文件即可。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kafka-server-start.sh ../config/server.properties</span><br></pre></td></tr></table></figure><p>而<code>kafka-server-start.sh</code>中核心的内容在于启动<code>kafka.Kafka</code>类中的<code>main</code>函数。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">...省略</span></span><br><span class="line">exec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka "$@"</span><br></pre></td></tr></table></figure><p>主要流程：解析配置文件、创建<code>KafkaServerStartable</code>实例、启动服务。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">//解析配置文件 </span></span><br><span class="line">    <span class="keyword">val</span> serverProps = getPropsFromArgs(args)</span><br><span class="line">      <span class="comment">//从配置文件创建实例 </span></span><br><span class="line">    <span class="keyword">val</span> kafkaServerStartable = <span class="type">KafkaServerStartable</span>.fromProps(serverProps)</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    <span class="comment">//优雅退出</span></span><br><span class="line">    <span class="type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="type">Thread</span>(<span class="string">"kafka-shutdown-hook"</span>) &#123;</span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = kafkaServerStartable.shutdown()</span><br><span class="line">    &#125;)</span><br><span class="line">    kafkaServerStartable.startup()<span class="comment">//启动应用</span></span><br><span class="line">    kafkaServerStartable.awaitShutdown()<span class="comment">//阻塞等待关闭 </span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</span><br><span class="line">      fatal(<span class="string">"Exiting Kafka due to fatal exception"</span>, e)</span><br><span class="line">      <span class="type">Exit</span>.exit(<span class="number">1</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="type">Exit</span>.exit(<span class="number">0</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>1. 解析配置文件</strong><br>读取指定的<code>server.properties</code>文件，进行一系列的解析验证，支持通过<code>命令行</code>传入参数，<code>覆盖</code>配置文件中配置的属性，最后返回<code>Properties</code>实例。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPropsFromArgs</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Properties</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> optionParser = <span class="keyword">new</span> <span class="type">OptionParser</span>(<span class="literal">false</span>)</span><br><span class="line">  <span class="keyword">val</span> overrideOpt = optionParser.accepts(<span class="string">"override"</span>, <span class="string">"Optional property that should override values set in server.properties file"</span>)</span><br><span class="line">    .withRequiredArg()</span><br><span class="line">    .ofType(classOf[<span class="type">String</span>])</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (args.length == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="type">CommandLineUtils</span>.printUsageAndDie(optionParser, <span class="string">"USAGE: java [options] %s server.properties [--override property=value]*"</span>.format(classOf[<span class="type">KafkaServer</span>].getSimpleName()))</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">val</span> props = <span class="type">Utils</span>.loadProps(args(<span class="number">0</span>)) <span class="comment">//加载server.properties</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (args.length &gt; <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">val</span> options = optionParser.parse(args.slice(<span class="number">1</span>, args.length): _*)</span><br><span class="line">      <span class="comment">//命令行参数个数校验</span></span><br><span class="line">    <span class="keyword">if</span> (options.nonOptionArguments().size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="type">CommandLineUtils</span>.printUsageAndDie(optionParser, <span class="string">"Found non argument parameters: "</span> + options.nonOptionArguments().toArray.mkString(<span class="string">","</span>))</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//将命令行配置的属性存入props</span></span><br><span class="line">    props ++= <span class="type">CommandLineUtils</span>.parseKeyValueArgs(options.valuesOf(overrideOpt).asScala)</span><br><span class="line">  &#125;</span><br><span class="line">  props</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>2. 创建KafkaServerStartable实例</strong><br>KafkaServerStartable主要的作用是启动Kafka的Metrics监控以及维护Kafka服务的生命周期。<br>包括：启动、关闭、闭锁阻塞等待关闭、设置Kafka服务状态。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">KafkaServerStartable</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">fromProps</span></span>(serverProps: <span class="type">Properties</span>) = &#123;</span><br><span class="line">  <span class="comment">//启动监控</span></span><br><span class="line">  <span class="keyword">val</span> reporters = <span class="type">KafkaMetricsReporter</span>.startReporters(<span class="keyword">new</span> <span class="type">VerifiableProperties</span>(serverProps))</span><br><span class="line">    <span class="keyword">new</span> <span class="type">KafkaServerStartable</span>(<span class="type">KafkaConfig</span>.fromProps(serverProps, <span class="literal">false</span>), reporters)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KafkaServerStartable</span>(<span class="params">val staticServerConfig: <span class="type">KafkaConfig</span>, reporters: <span class="type">Seq</span>[<span class="type">KafkaMetricsReporter</span>]</span>) <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  <span class="comment">//初始化真正的Kafka服务对象</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> server = <span class="keyword">new</span> <span class="type">KafkaServer</span>(staticServerConfig, kafkaMetricsReporters = reporters)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(serverConfig: <span class="type">KafkaConfig</span>) = <span class="keyword">this</span>(serverConfig, <span class="type">Seq</span>.empty) </span><br><span class="line">  <span class="comment">//启动</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>() &#123;</span><br><span class="line">    <span class="keyword">try</span> server.startup()</span><br><span class="line">    <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> _: <span class="type">Throwable</span> =&gt;</span><br><span class="line">        <span class="comment">// KafkaServer.startup() calls shutdown() in case of exceptions, so we invoke `exit` to set the status code</span></span><br><span class="line">        fatal(<span class="string">"Exiting Kafka."</span>)</span><br><span class="line">        <span class="type">Exit</span>.exit(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;  </span><br><span class="line">  <span class="comment">//关闭</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">shutdown</span></span>() &#123;</span><br><span class="line">    <span class="keyword">try</span> server.shutdown()</span><br><span class="line">    <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> _: <span class="type">Throwable</span> =&gt;</span><br><span class="line">        fatal(<span class="string">"Halting Kafka."</span>)</span><br><span class="line">        <span class="comment">// Calling exit() can lead to deadlock as exit() can be called multiple times. Force exit.</span></span><br><span class="line">        <span class="type">Exit</span>.halt(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;  </span><br><span class="line">  <span class="comment">//设置状态，包含：NotRunning、Starting、RecoveringFromUncleanShutdown、RunningAsBroker、PendingControlledShutdown、BrokerShuttingDown</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setServerState</span></span>(newState: <span class="type">Byte</span>) &#123;</span><br><span class="line">    server.brokerState.newState(newState)</span><br><span class="line">  &#125;  </span><br><span class="line">  <span class="comment">//阻塞进程避免退出，通过CountDownLatch实现</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">awaitShutdown</span></span>(): <span class="type">Unit</span> = server.awaitShutdown()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>3. 启动服务</strong><br>启动服务是通过间接调用<code>KafkaServer</code>的<code>startup()</code>方法来实现的。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>() &#123;</span><br><span class="line">   <span class="keyword">try</span> &#123;</span><br><span class="line">     info(<span class="string">"starting"</span>)</span><br><span class="line">     <span class="comment">//是否已关闭</span></span><br><span class="line">     <span class="keyword">if</span> (isShuttingDown.get)</span><br><span class="line">       <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"Kafka server is still shutting down, cannot re-start!"</span>)</span><br><span class="line">     <span class="comment">//是否已启动</span></span><br><span class="line">     <span class="keyword">if</span> (startupComplete.get)</span><br><span class="line">       <span class="keyword">return</span>       </span><br><span class="line">     <span class="comment">//是否可以启动</span></span><br><span class="line">     <span class="keyword">val</span> canStartup = isStartingUp.compareAndSet(<span class="literal">false</span>, <span class="literal">true</span>)</span><br><span class="line">     <span class="keyword">if</span> (canStartup) &#123;<span class="comment">//设置broker状态为Starting</span></span><br><span class="line">       brokerState.newState(<span class="type">Starting</span>)</span><br><span class="line">       <span class="comment">//连接ZK，并创建根节点</span></span><br><span class="line">       initZkClient(time)</span><br><span class="line">       <span class="comment">//从ZK获取或创建集群id，规则：UUID的mostSigBits、leastSigBits组合转base64</span></span><br><span class="line">       _clusterId = getOrGenerateClusterId(zkClient)</span><br><span class="line">       info(<span class="string">s"Cluster ID = <span class="subst">$clusterId</span>"</span>)</span><br><span class="line">       <span class="comment">//获取brokerId及log存储路径，brokerId通过zk生成或者server.properties配置broker.id</span></span><br><span class="line">       <span class="comment">//规则：/brokers/seqid的version值 + maxReservedBrokerId（默认1000），保证唯一性</span></span><br><span class="line">       <span class="keyword">val</span> (brokerId, initialOfflineDirs) = getBrokerIdAndOfflineDirs</span><br><span class="line">       config.brokerId = brokerId</span><br><span class="line">       logContext = <span class="keyword">new</span> <span class="type">LogContext</span>(<span class="string">s"[KafkaServer id=<span class="subst">$&#123;config.brokerId&#125;</span>] "</span>)</span><br><span class="line">       <span class="comment">//配置logger</span></span><br><span class="line">       <span class="keyword">this</span>.logIdent = logContext.logPrefix</span><br><span class="line">       <span class="comment">//初始化AdminZkClient，支持动态修改配置 </span></span><br><span class="line">       config.dynamicConfig.initialize(zkClient)</span><br><span class="line"><span class="comment">//初始化定时任务调度器</span></span><br><span class="line">       kafkaScheduler = <span class="keyword">new</span> <span class="type">KafkaScheduler</span>(config.backgroundThreads)</span><br><span class="line">       kafkaScheduler.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">//创建及配置监控，默认使用JMX及Yammer Metrics</span></span><br><span class="line">       <span class="keyword">val</span> reporters = <span class="keyword">new</span> util.<span class="type">ArrayList</span>[<span class="type">MetricsReporter</span>]</span><br><span class="line">       reporters.add(<span class="keyword">new</span> <span class="type">JmxReporter</span>(jmxPrefix))</span><br><span class="line">       <span class="keyword">val</span> metricConfig = <span class="type">KafkaServer</span>.metricConfig(config)</span><br><span class="line">       metrics = <span class="keyword">new</span> <span class="type">Metrics</span>(metricConfig, reporters, time, <span class="literal">true</span>)</span><br><span class="line">       _brokerTopicStats = <span class="keyword">new</span> <span class="type">BrokerTopicStats</span></span><br><span class="line">       <span class="comment">//初始化配额管理器</span></span><br><span class="line">       quotaManagers = <span class="type">QuotaFactory</span>.instantiate(config, metrics, time, threadNamePrefix.getOrElse(<span class="string">""</span>))</span><br><span class="line">       notifyClusterListeners(kafkaMetricsReporters ++ metrics.reporters.asScala)</span><br><span class="line">       <span class="comment">//用于保证kafka-log数据目录的存在</span></span><br><span class="line">       logDirFailureChannel = <span class="keyword">new</span> <span class="type">LogDirFailureChannel</span>(config.logDirs.size)</span><br><span class="line"></span><br><span class="line">       <span class="comment">//启动日志管理器，kafka的消息以日志形式存储</span></span><br><span class="line">       logManager = <span class="type">LogManager</span>(config, initialOfflineDirs, zkClient, brokerState, kafkaScheduler, time, brokerTopicStats, logDirFailureChannel)</span><br><span class="line">       <span class="comment">//启动日志清理、刷新、校验、恢复等的定时线程</span></span><br><span class="line">       logManager.startup()</span><br><span class="line"></span><br><span class="line">       metadataCache = <span class="keyword">new</span> <span class="type">MetadataCache</span>(config.brokerId)</span><br><span class="line">       <span class="comment">// SCRAM认证方式的token缓存</span></span><br><span class="line">       tokenCache = <span class="keyword">new</span> <span class="type">DelegationTokenCache</span>(<span class="type">ScramMechanism</span>.mechanismNames)</span><br><span class="line">       credentialProvider = <span class="keyword">new</span> <span class="type">CredentialProvider</span>(<span class="type">ScramMechanism</span>.mechanismNames, tokenCache)</span><br><span class="line"></span><br><span class="line">       <span class="comment">//启动socket，监听9092端口，等待接收客户端请求 </span></span><br><span class="line">       socketServer = <span class="keyword">new</span> <span class="type">SocketServer</span>(config, metrics, time, credentialProvider)</span><br><span class="line">       socketServer.startup(startupProcessors = <span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">       <span class="comment">//启动副本管理器，高可用相关</span></span><br><span class="line">       replicaManager = createReplicaManager(isShuttingDown)</span><br><span class="line">       replicaManager.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">//将broker信息注册到ZK上</span></span><br><span class="line">       <span class="keyword">val</span> brokerInfo = createBrokerInfo</span><br><span class="line">       zkClient.registerBrokerInZk(brokerInfo)</span><br><span class="line"></span><br><span class="line">       <span class="comment">//校验broker信息</span></span><br><span class="line">       checkpointBrokerId(config.brokerId)</span><br><span class="line"></span><br><span class="line">       <span class="comment">//启动token管理器</span></span><br><span class="line">       tokenManager = <span class="keyword">new</span> <span class="type">DelegationTokenManager</span>(config, tokenCache, time , zkClient)</span><br><span class="line">       tokenManager.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">//启动Kafka控制器，只有leader会与ZK建连</span></span><br><span class="line">       kafkaController = <span class="keyword">new</span> <span class="type">KafkaController</span>(config, zkClient, time, metrics, brokerInfo, tokenManager, threadNamePrefix)</span><br><span class="line">       kafkaController.startup()</span><br><span class="line">       </span><br><span class="line">       <span class="comment">//admin管理器</span></span><br><span class="line">       adminManager = <span class="keyword">new</span> <span class="type">AdminManager</span>(config, metrics, metadataCache, zkClient)</span><br><span class="line"></span><br><span class="line">       <span class="comment">//启动集群群组协调器</span></span><br><span class="line">       groupCoordinator = <span class="type">GroupCoordinator</span>(config, zkClient, replicaManager, <span class="type">Time</span>.<span class="type">SYSTEM</span>)</span><br><span class="line">       groupCoordinator.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">//启动事务协调器</span></span><br><span class="line">       transactionCoordinator = <span class="type">TransactionCoordinator</span>(config, replicaManager, <span class="keyword">new</span> <span class="type">KafkaScheduler</span>(threads = <span class="number">1</span>, threadNamePrefix = <span class="string">"transaction-log-manager-"</span>), zkClient, metrics, metadataCache, <span class="type">Time</span>.<span class="type">SYSTEM</span>)</span><br><span class="line">       transactionCoordinator.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">//ACL</span></span><br><span class="line">       authorizer = <span class="type">Option</span>(config.authorizerClassName).filter(_.nonEmpty).map &#123; authorizerClassName =&gt;</span><br><span class="line">         <span class="keyword">val</span> authZ = <span class="type">CoreUtils</span>.createObject[<span class="type">Authorizer</span>](authorizerClassName)</span><br><span class="line">         authZ.configure(config.originals())</span><br><span class="line">         authZ</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">//创建拉取管理器</span></span><br><span class="line">       <span class="keyword">val</span> fetchManager = <span class="keyword">new</span> <span class="type">FetchManager</span>(<span class="type">Time</span>.<span class="type">SYSTEM</span>,</span><br><span class="line">         <span class="keyword">new</span> <span class="type">FetchSessionCache</span>(config.maxIncrementalFetchSessionCacheSlots,</span><br><span class="line">           <span class="type">KafkaServer</span>.<span class="type">MIN_INCREMENTAL_FETCH_SESSION_EVICTION_MS</span>))</span><br><span class="line"></span><br><span class="line">       <span class="comment">//初始化KafkaApis，负责核心的请求逻辑处理</span></span><br><span class="line">       apis = <span class="keyword">new</span> <span class="type">KafkaApis</span>(socketServer.requestChannel, replicaManager, adminManager, groupCoordinator, transactionCoordinator,</span><br><span class="line">         kafkaController, zkClient, config.brokerId, config, metadataCache, metrics, authorizer, quotaManagers,</span><br><span class="line">         fetchManager, brokerTopicStats, clusterId, time, tokenManager)</span><br><span class="line">       <span class="comment">//请求处理池</span></span><br><span class="line">       requestHandlerPool = <span class="keyword">new</span> <span class="type">KafkaRequestHandlerPool</span>(config.brokerId, socketServer.requestChannel, apis, time,</span><br><span class="line">         config.numIoThreads)</span><br><span class="line"></span><br><span class="line">       <span class="type">Mx4jLoader</span>.maybeLoad()</span><br><span class="line"></span><br><span class="line">       config.dynamicConfig.addReconfigurables(<span class="keyword">this</span>)</span><br><span class="line"></span><br><span class="line">       <span class="comment">//启动动态配置处理器</span></span><br><span class="line">       dynamicConfigHandlers = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">ConfigHandler</span>](<span class="type">ConfigType</span>.<span class="type">Topic</span> -&gt; <span class="keyword">new</span> <span class="type">TopicConfigHandler</span>(logManager, config, quotaManagers),</span><br><span class="line">                                                          <span class="type">ConfigType</span>.<span class="type">Client</span> -&gt; <span class="keyword">new</span> <span class="type">ClientIdConfigHandler</span>(quotaManagers),</span><br><span class="line">                                                          <span class="type">ConfigType</span>.<span class="type">User</span> -&gt; <span class="keyword">new</span> <span class="type">UserConfigHandler</span>(quotaManagers, credentialProvider),</span><br><span class="line">                                                          <span class="type">ConfigType</span>.<span class="type">Broker</span> -&gt; <span class="keyword">new</span> <span class="type">BrokerConfigHandler</span>(config, quotaManagers))</span><br><span class="line"></span><br><span class="line">       dynamicConfigManager = <span class="keyword">new</span> <span class="type">DynamicConfigManager</span>(zkClient, dynamicConfigHandlers)</span><br><span class="line">       dynamicConfigManager.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">//启动请求处理线程</span></span><br><span class="line">       socketServer.startProcessors()</span><br><span class="line">       brokerState.newState(<span class="type">RunningAsBroker</span>)</span><br><span class="line">       shutdownLatch = <span class="keyword">new</span> <span class="type">CountDownLatch</span>(<span class="number">1</span>)</span><br><span class="line">       startupComplete.set(<span class="literal">true</span>)</span><br><span class="line">       isStartingUp.set(<span class="literal">false</span>)</span><br><span class="line">       <span class="type">AppInfoParser</span>.registerAppInfo(jmxPrefix, config.brokerId.toString, metrics)</span><br><span class="line">       info(<span class="string">"started"</span>)</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">catch</span> &#123;</span><br><span class="line">     <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</span><br><span class="line">       fatal(<span class="string">"Fatal error during KafkaServer startup. Prepare to shutdown"</span>, e)</span><br><span class="line">       isStartingUp.set(<span class="literal">false</span>)</span><br><span class="line">       shutdown()</span><br><span class="line">       <span class="keyword">throw</span> e</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka - 架构设计</title>
      <link href="/2020/01/09/Kafka-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
      <url>/2020/01/09/Kafka-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<pre><code>Kafka的背景</code></pre><p>kafka是一个<code>分布式</code>、<code>高性能</code>、<code>高可用</code>、<code>可水平拓展</code>的<code>发布-订阅</code>式消息队列，更是一个<code>流式</code>处理系统。<br>对于消息，提供了<code>O(1)</code>时间复杂度的持久化能力，具备<code>高吞吐率</code>，同时支持实时、离线数据处理。</p><pre><code>Kafka的架构</code></pre><p><img src="/images/kafka.png" alt="Kafka">Kafka包含了：</p><ul><li><code>Broker</code>: Kafka运行所在的服务器。</li><li><code>Topic</code>: Kafka生产、消费数据都是需要指定一个Topic的，相当于一个队列。</li><li><code>Partition</code>: 一个Topic可划分多个Partition，多机部署，可定义partition路由算法。</li><li><code>Segment</code>: 一个Partition被切分为多个Segment，每个Segment包含索引文件和数据文件。</li><li><code>Producer</code>: 生产者只需要指定Topic，往里头写数据即可。</li><li><code>Consumer</code>: 一个Consumer Group包含多个Consumer，一条消息只被同组中的一个消费。</li><li><code>Zookeeper</code>: Zookeeper用来管理Kafka集群。</li></ul><p>对于服务器来说，<code>Broker</code>只是一个进程。</p><p><code>Topic</code>则是服务器上的目录，存放在<code>log.dirs</code>指定的路径下，默认是<code>/tmp/kafka-logs</code>，支持<code>多</code>路径，逗号分隔，可将数据分散到多个磁盘中，使Kafka吞吐率线性提高。通过指定<code>--partitions</code>数值，可创建多个<code>Partition</code>，命名为<code>TopicName-K</code>，从<code>0</code>开始。</p><p>通过指定<code>--replication-factor</code>副本因子数值，可将这些<code>Partition</code>分散、备份在一个或多个可用的<code>Broker</code>中，前提是可用的<code>Broker</code>数要大于等于<code>replication-factor</code>的值，既可数据备份、又可实现高可用、分散负载，提高吞吐量。</p><p>每个Partiton目录下存储的是一段段的<code>Segment</code>，包含了索引文件和数据文件，以<code>offset</code>命名。</p><pre><code>Kafka采用推拉结合模型</code></pre><p>在<code>生产</code>消息方面，采用<code>主动推送</code>消息模式，在<code>客户端</code>会累积、压缩、批量发送到Broker。</p><p>在<code>消费</code>消息方面，采用<code>主动拉取</code>消息模式，由<code>客户端</code>轮询拉取消息，并按照策略提交<code>offset</code>。</p><p>另外，通过消费者拉消息的方式，可以由消费者自行控制消费的频率。</p><p><img src="/images/kafka-ps.png" alt="kafka-ps"></p><p>此种方式，有利于减轻<code>Broker</code>压力，不需要维护太多状态，可由客户端<code>自定义</code>从哪个<code>offset</code>开始拉取消息。</p><p><img src="/images/kafka-offset.png" alt="kafka-offset"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统 - 内存管理</title>
      <link href="/2019/12/24/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"/>
      <url>/2019/12/24/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<pre><code>内存是操作系统的核心，程序指令只有被加载到内存中才可以被CPU调度执行。</code></pre><p>内存，是由<code>字</code>或<code>字节队列</code>组成，每个字或字节队列都有它自己的<code>地址</code>。<br>CPU，根据<code>程序计数器</code>的值从内存中<code>取指令</code>，可能是从指定内存地址<code>读数据</code>或将数据<code>存入</code>指定内存地址。</p><p><img src="/images/computer-line.png" alt="系统总线"></p><p>CPU与内存之间的数据交互通过<code>系统总线</code>来传输。<br>通常来说，程序是以<code>二进制</code>的形式存储在<code>硬盘</code>上。只有将程序加载到<code>内存</code>中，并构造成<code>进程</code>的形式，才可以被真正的使用。在进程的<code>运行过程</code>中，CPU从内存中获取<code>指令和数据</code>，并服务于进程，而在进程<code>使用完毕</code>，终止之后，将会<code>释放</code>所占用的内存资源。</p><pre><code>CPU产生的地址称为：逻辑地址，内存单元的地址称为：物理地址。</code></pre><p><code>逻辑地址</code>，又称为：<code>虚拟地址</code>，程序所产生的所有<code>逻辑地址</code>形成了<code>逻辑地址空间</code>。<br><code>逻辑</code>地址空间所<code>对应</code>的<code>物理</code>地址形成了<code>物理地址空间</code>。<br>有一种物理硬件设备负责将<code>逻辑地址</code>和<code>物理地址</code>进行<code>映射</code>，这种设备称为：<code>内存管理单元</code>MMU。<br><img src="/images/mmu.png" alt="MMU">内存管理的核心：将逻辑地址空间<code>绑定</code>到物理地址空间。</p><pre><code>内存分配分为：连续内存分配、非连续内存分配。</code></pre><p><code>连续内存分配</code>，包含有：<code>多分区分配方法</code>、<code>固定分区机制</code>。</p><ul><li><p>多分区分配方法<br>当一个区被<code>释放</code>时，就从<code>输入队列</code>中取出一个<code>进程</code>，将其载入<code>空闲区</code>中，当该进程结束运行时，该区又可以被<code>其它</code>进程使用。不过这种方法早年前已经被<code>弃用</code>了。</p></li><li><p>固定分区机制<br>在操作系统内部保留一个<code>表</code>用来标识哪块内存<code>可用</code>，哪块内存<code>被占用</code>，当一个进程到达时，就在表中根据<code>首先适应</code>、<code>最佳适应</code>、<code>最差适应</code>等策略为其分配一个合适的分区。如果分区过大，那么将可以被多个进程使用，如果无法使用就浪费了。当进程终止，就释放内存分区交还给系统，继续为其它进程服务。如果分区过小，可以合并使用。</p></li></ul><p>以上2种方式，都存在着<code>碎片问题</code>，另外，维护内存分区及移动分区的<code>代价过高</code>。</p><p><code>非连续内存分配</code>，包含有：<code>分页机制</code>、<code>分段机制</code>。</p><ul><li><p>分页机制<br>分页机制是一种<code>非连续</code>的内存管理策略，相比<code>连续</code>的内存管理策略来说，不需要再为找不到一块完整的、连续的内存而苦恼。在<code>分页</code>机制中，不会产生外部碎片，因为允许不连续，每一块内存都会被利用，但会产生内部碎片。<br>将<code>物理内存</code>分成固定大小的块，称为：<code>帧</code>，将<code>逻辑内存</code>也分成固定大小的块，称为：<code>页</code>。程序执行的时候，页就从后备存储器装入到有效物理帧中。<br>CPU执行的时候，产生的地址包含：<code>页号</code>、<code>页偏移</code>。<br>逻辑内存是连续的，根据<code>页号</code>、<code>页偏移</code>计算得到物理内存具体位置。<br><img src="/images/mem1.png" alt="mem"><img src="/images/mem.png" alt="mem">在程序的内存视觉中，内存都是单调递增的。<br>通过<code>页号</code>可以索引到<code>页表</code>，<code>页表</code>包含了<code>物理内存</code>中<code>每个页</code>的<code>基地址</code>，也就是<code>帧号</code>。<br><code>基地址</code>乘以<code>页面大小</code>，再加上<code>页偏移</code>，就得到<code>物理内存</code>的具体地址。<br>每个物理帧都在<code>帧表</code>中存储着，包含：分配了哪些帧、哪些帧空闲、共有多少帧。<br>如果被分配了，那么会记录分配给了哪些<code>进程</code>。<br>由于通过<code>页表</code>这种方式计算出<code>物理内存地址</code>的方式需要访问<code>2次</code>内存，效率较<code>低</code>，也就产生了<code>TLB</code>，这是一种较小的<code>快速查找硬件高速缓冲</code>，只通过<code>页号</code>就可以迅速查找到<code>帧号</code>。如果<code>没有</code>查找到，那就通过<code>页表</code>去查找。<br><img src="/images/tlb.png" alt="TLB">由于现在的计算机支持的<code>逻辑空间</code>较大，在<code>2^32 ~ 2^64</code>之间，基于<code>页表</code>这种机制，这样会导致每一个进程需要创建<code>至少4MB</code>的<code>物理空间</code>给页表使用。<br>通过<code>两级分页算法</code>将<code>页表再次分页</code>，分为：<code>页号</code>、<code>页表页号</code>、<code>偏移量</code>。<br><img src="/images/page.png" alt="page">利用这种方式，可以有效减少物理内存的使用量，甚至还可以使用<code>三级分页</code>再次减少内存使用量。</p></li><li><p>分段机制<br>与<code>分页</code>机制不同，<code>分段</code>机制采用一段一段划分的，每一段的大小可以不一样，并且可以动态伸缩。在<code>段表</code>中记录的是<code>二维地址</code>，包含：<code>&lt; 段号 - 偏移量 &gt;</code>。<br>通过<code>二维地址</code>在<code>段表</code>中查找计算出具体的<code>物理地址</code>。<img src="/images/segment.png" alt="segment">虽然，分段机制<code>不是连续的</code>，但是每一段大小不一致，可能有些<code>段过大</code>，暂时难以找到合适的位置，需要等待且外部<code>碎片</code>会比较多。另外，通过<code>分段</code>，可以针对某些段设置为只读、共享，可以有效的<code>保护</code>内存段不被修改且<code>节约</code>内存。</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统 - CPU</title>
      <link href="/2019/12/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-CPU/"/>
      <url>/2019/12/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-CPU/</url>
      
        <content type="html"><![CDATA[<pre><code>CPU，中央处理器，是计算机系统的运算和控制中心，是信息处理、程序运行的最终执行单元。</code></pre><p><img src="/images/cpu.png" alt="CPU"></p><p>程序，最终都会变成<code>计算机指令</code>，然后被CPU<code>调度执行</code>。</p><p>CPU分为：运算器、控制器、高速缓冲存储器。</p><p><code>运算器</code>，包含：<code>算术运算器</code>、<code>逻辑运算器</code>，是用来实现加减乘除、与或非、移位、异或等的运算器。</p><p><code>控制器</code>，包含：<code>指令寄存器</code>、<code>程序计数器</code>、<code>操作控制器</code>，是用来指挥各个部件，按照计算机指令的要求协调工作的部件，是计算机的<code>神经中枢</code>和<code>指挥中心</code>。<br><code>指令寄存器</code>：用来保存当前执行或者即将要执行的指令的寄存器。<br><code>程序计数器</code>：用来指明程序下一次要执行的指令的地址。<br><code>操作控制器</code>：根据指令操作码和时序信号，产生各自操作信号，以便正确地创建数据链路，从而完成取指令和执行指令的控制。</p><p><code>高速缓冲存储器</code>，位于主存和CPU之间的一级缓存，容量小，但是速度比主存快。</p><p>有了CPU之后，那么就需要利用调度算法去让CPU调度程序了。</p><pre><code>CPU调度是多道程序操作系统的基础，通过在进程间转换CPU，操作系统可以提高计算机的生产力。</code></pre><p>为了<code>极尽CPU所能</code>，操作系统不会让CPU闲着，一旦<code>就绪队列</code>中有新的进程，将被CPU调度，然后<code>移交CPU使用权</code>执行，而CPU如何从<code>就绪队列</code>中获取要执行的进程任务，就依赖于<code>调度算法</code>。</p><p>CPU也不是随便就能调度的，需要等待<code>时机</code>。</p><ul><li>当进程从<code>运行</code>状态转换为<code>等待</code>状态。</li><li>当进程从<code>运行</code>状态转换为<code>就绪</code>状态。</li><li>当进程从<code>等待</code>状态转换为<code>就绪</code>状态。</li><li>当进程<code>终止</code>的时候。</li></ul><p>衡量CPU调度算法也是有<code>指标</code>的。</p><ul><li>CPU利用率</li><li>吞吐量</li><li>周转时间</li><li>等待时间</li><li>响应时间</li></ul><p>理想的情况是，CPU利用率、吞吐量<code>最大化</code>，周转时间、等待时间、响应时间<code>最小化</code>。</p><p><img src="/images/cpu-mark.png" alt="cpu-mark"></p><p>围绕以上指标，产生了一些<code>CPU调度算法</code>。</p><p>CPU调度，决定了哪个进程会被从就绪队列中拿出来，并被分配CPU资源。</p><p>CPU<code>就绪队列</code>作为一个队列，可以通过<code>FIFO</code>、<code>优先级</code>、<code>树</code>、<code>无序</code>来实现。</p><p>调度算法分为：</p><ul><li><strong>先来先服务算法</strong><br>按照进入队列的顺序，一个一个调度。</li><li><strong>短作业优先算法</strong><br>本质上也是优先调度算法，根据CPU Burst排序。</li><li><strong>优先调度算法</strong><br>为每一进程配置优先级，根据优先级排序。</li><li><strong>轮转调度算法</strong><br>分配时间片，循环调度队列中的进程。</li><li><strong>多级队列调度算法</strong><br>将反馈队列分为多个队列，采用不同调度算法。</li><li><strong>多级队列反馈调度算法</strong><br>根据CPU Burst调整进程应该所处带有不同优先级的队列。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统 - 进程与线程</title>
      <link href="/2019/12/06/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/"/>
      <url>/2019/12/06/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<pre><code>进程，是指运行中的程序，也称为作业。</code></pre><p>早期的计算机，只允许运行 <code>一个</code> 程序，这个程序被分配了计算机所能提供的所有资源。<br>现代的计算机，允许并行运行 <code>多个</code> 程序，系统资源也就被这些程序瓜分。<br>每一个程序也就成为了一个 <code>工作单元</code>，将这些 <code>工作单元</code> 称呼为：<code>进程</code>。<br>因此，<code>进程</code> 也是计算机系统<code>分配资源</code>的基本单位。</p><pre><code>程序，是静态的代码，而进程是动态的实体。</code></pre><p>程序，也就是 <code>代码</code>，在硬盘中存放着，经过 <code>主存储器（内存）</code> 的加载，被封装成 <code>PCB</code> 数据结构，在 <code>内核队列</code> 中排队，等待 <code>CPU调用</code> 执行。相同的一份代码，可以被多次加载，形成多个独立的进程，对于系统来说，不过是队列中多了一个成员，当然，资源也是需要被瓜分的。</p><pre><code>操作系统通过进程控制块PCB来表示进程。  </code></pre><p><img src="/images/pcb.png" alt="PCB"></p><p><code>进程控制块</code>，也就是PCB，是操作系统内部的一种用来表示<code>进程</code>的<code>数据结构</code>，记载着和进程相关的一些信息。<br>包括：内存指针、进程状态、进程号、程序计数器、寄存器、内存限制说明、I/O状态信息等。</p><p><code>内存指针</code>，进程内存数据相关的指针。<br><code>进程状态</code>，包含：新建、就绪、运行、阻塞、停止。<br><code>进程号</code>，用来标识唯一进程的标识符，也就是PID。<br><code>程序计数器</code>，用来标识程序要执行的下一条指令的地址。<br><code>寄存器</code>，用于发生CPU中断时临时存储信息。<br><code>内存限制说明</code>，包含了内存管理系统的一些信息，比如：页表、段表。<br><code>I/O状态信息</code>，包含了进程打开的文件列表及分配给进程的I/O设备。</p><p>进程的一生都在队列之间徘徊，一旦被CPU调用，那么就出队列，改变状态，读取PCB中记录的信息，恢复现场（也就是<code>CPU上下文切换</code>），相同状态的PCB会形成链表，从程序计数器记录的地址开始执行，直到时间片用完或者被中断，回到队列之中或者执行结束，释放资源。</p><p>如果，所有的进程都是<code>CPU繁忙型</code>，那么<code>等待队列</code>（CPU都在忙着）几乎都是空的。<br>如果，所有的进程都是<code>I/O繁忙型</code>，那么<code>就绪队列</code>（CPU都在闲着）几乎都是空的。</p><p>那么，就需要合理分配进程组合，避免内存需求过多或者设备过度空闲。</p><pre><code>一个进程，在运行期间可以创建多个子进程。</code></pre><p>创建进程的进程称为<code>父进程</code>，通过<code>fork</code>来实现，而<code>子进程</code>也可以再创建子进程，形成一个<code>进程树</code>。<br>创建进程是需要分配系统资源的，子进程所需要的资源可以<code>直接</code>从系统获取，也可以从父进程获取，父进程所拥有的数据也可以<code>传送</code>给子进程，父子进程也可以<code>共享</code>同样的资源。<br>子进程也不是无限制的创建的，需要<code>受限</code>于父进程，否则会负载过高。</p><pre><code>进程之间，可以通过多种方式相互通信。</code></pre><p>进程的通信可以分为：直接通信、间接通信。<br>具体的方式包含：管道、信号、消息队列、Socket、共享内存。</p><p><code>管道</code>，一种半双工的通信方式，数据只能在父子进程之间单向流动。<br><code>信号</code>，一种异步通信方式，通过监听、中断来实现，如：SIGINT。<br><code>消息队列</code>，是一种保存在内核中的消息的链表，进程之间通过读写消息队列通信。<br><code>Socket</code>，通过TCP、UDP协议进行通信。<br><code>共享内存</code>，多个进程读取同一块共享的内存。</p><p>最后，进程是系统分配资源的基本单位，是执行中的程序，被封装为PCB数据结构，由CPU来进行调度，每次调度将会加载进程数据，切换上下文，通过此方式切换进程，成本也是过高。</p><p>因此，诞生了<code>线程</code>。</p><pre><code>线程，本质上是轻量级进程，且共享了进程所拥有的数据和资源。</code></pre><p>线程，建立在进程的基础上，一个进程可以拥有<code>多个</code>线程，每一个线程<code>共享</code>进程的数据和资源，并且可以拥有自己<code>独享</code>的数据，是CPU执行的<code>基本单位</code>。通过线程这种方式，CPU无需进行复杂的进程<code>上下文切换</code>，只需要切换线程即可，内存数据在同一个进程内是共享的，相比切换进程来说，成本明显降低许多。</p><p><img src="/images/thread.png" alt="thread"></p><p>一个线程，包含：代码、数据、打开文件列表、寄存区、程序计数器、堆栈。<br>多个线程之间，处于并行状态。</p><p>举例，在我们打开浏览器的时候，一个线程负责拉取数据，一个线程负责加载页面，一个线程负责显示图像等，这几个线程之间互不影响，换做进程的话，需要来回切换。</p><p>在<code>RPC</code>的场景中，每来一个请求，就单独使用一个线程来处理，比起单线程来说，<code>并行</code>的方式显然提高了处理的效率。当然，线程也不是无限开辟的，可创建的线程数受限于所拥有的资源。虽然创建线程的成本比创建进程的成本低，但也不是没有成本的。为了降低这种成本，基于<code>线程池</code>，可以快速创建进程，充分利用资源。</p><pre><code>线程的实现方式有：一对一、多对一、多对多。</code></pre><p>线程分为<code>用户线程</code>、<code>内核线程</code>，用户线程由内核线程来实现。</p><p><code>一对一模型</code>情况下，一个用户线程由一个内核线程来实现。这种方式使得线程之间并行化，不会因为一个用户线程的阻塞导致其它用户线程的阻塞，但是资源消耗就比较大了。</p><p><code>多对一模型</code>情况下，将多个用户线程映射到一个内核线程。这种方式使得线程管理变得方便了，但一次只能执行一个线程，无法并行化，如果一个用户线程阻塞，将导致所有由此内核线程实现的用户线程阻塞。</p><p><code>多对多模型</code>情况下，多个用户线程映射到多个内核线程上，处于交叉状态，做到多路复用，一个内核线程阻塞的情况下，可以切换到其它的内核线程，避免了上面两种模型的缺点。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统 - 系统基础</title>
      <link href="/2019/09/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
      <url>/2019/09/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<pre><code>操作系统是被设计用来管理计算机硬件和应用程序的系统程序。</code></pre><p>试想，一台计算机本身是一堆零件拼凑而成，而这些零件本身也具备了可编程能力，每一个应用程序要运行，必然要去操作调用这些硬件的接口，而多个应用程序之间各自以各自的方式去调用这些硬件，要这些应用程序开发商按照规矩去操作这些硬件，那是很困难的。</p><p>为了解决这个问题，操作系统就诞生了，将操作这些硬件的方式封装在操作系统当中，并给这些应用程序开发商提供统一的接口去调用，并管理控制这些应用程序能够有条不紊、无冲突地分配和使用系统资源。</p><p><img src="/images/os-trans.png" alt="操作系统"></p><p>简单的说，操作系统相当于一个中介，帮助应用程序去调用硬件资源，同时也管理着应用程序。</p><p>操作系统是一个从始至终都运行在计算机中的程序，俗称<code>内核</code>。</p><pre><code>操作系统要正常运行，也需要底层硬件的支持，而硬件之间也要相互配合。</code></pre><p>计算机底层的硬件包含：CPU、内存、磁盘、磁带、打印机等。</p><p>这些硬件通过一条<code>公共总线</code>连接到一块，程序指令及任务由CPU来负责调度，由内存和磁盘来存储资源，所有的硬件共同<code>争抢总线</code>资源，为了保证有序使用内存资源，由<code>内存控制器</code>来统一分配。程序只有被加载到内存当中，才能够被CPU执行。</p><p>早期计算机一次只能执行一个任务，为了提高处理速度，相似的任务会被<code>分批执行</code>。由于CPU的运行速度远远大于I/O设备的处理速度，为了使得CPU总有任务可以运行，不至于过于空闲，产生了<code>作业系统</code>，也就是<code>多道程序设计</code>,将作业放入底层<code>作业队列</code>中，由CPU空闲时从队列中取出任务然后执行。再后来，为了提高系统吞吐量，一个CPU已经无法满足需求了，一台计算机被植入了多个CPU，大大提高了计算机的处理能力。</p><p><img src="/images/computer-line.png" alt="系统总线"></p><pre><code>计算机从开机到启动操作系统需要经过一个初始化过程。</code></pre><p>当点击<code>开机</code>按钮的时候，计算机通电，主板<code>BIOS</code>开始进行初始化固件操作，<code>CPU</code>开始运转。</p><p>计算机首先会进行一个<code>自检</code>操作，检查硬件是否正常，如果出现了异常，就发出声响或者关机、蓝屏、显示错误信息等。</p><p>自检通过以后，读取第一块磁盘的第一个扇区（主引导扇区），开始加载<code>主引导记录MBR</code>，计算机支持多系统的话，通常会有多个引导记录。引导记录是在<code>磁盘格式化</code>的时候写在磁盘上的。系统启动时，<code>自动</code>将它装入内存并用于加载操作系统的其它部分。</p><p>接着，启动<code>Boot Loader 引导加载器</code>，通常使用的是<code>GRUB</code>多操作系统启动程序。如果计算机安装了多个系统的话，可以在这个<code>选择</code>要进入的<code>操作系统</code>，同时会在这个阶段进行内存的初始化。</p><p>操作系统选择完毕之后，计算机的控制器就转移给了操作系统，操作系统的<code>内核</code>会被装载到系统内存之中，然后执行初始化操作。</p><p>初始化的时候，会调用系统底下的一个<code>init</code>方法，如：<code>/sbin/init</code>，执行后续的一些初始化及系统服务的启动，根据传入的参数，给用户展示的界面可以是命令行（通常是服务端），也可以是图形交互界面（通常是客户端）。</p><p>执行完以上操作，操作系统就启动了。</p><p><img src="/images/os-init.png" alt="系统启动"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计网 - 应用层</title>
      <link href="/2019/09/26/%E8%AE%A1%E7%BD%91-%E5%BA%94%E7%94%A8%E5%B1%82/"/>
      <url>/2019/09/26/%E8%AE%A1%E7%BD%91-%E5%BA%94%E7%94%A8%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<pre><code>应用层，建立在传输层的基础上，规定了应用程序的数据格式。</code></pre><p>我们所使用的软件都在应用层上工作，每一个应用具有自己的<code>数据格式</code>，也就是要有共同方言。</p><p>只有规定好了数据格式，应用程序才可以和服务端正常交互，用户也才能正常使用这些应用程序。</p><p>这些数据格式，也被约定俗成为一些通用协议，也可以自定义协议。</p><p>比如：Email、HTTP、FTP都属于应用层协议。</p><p>应用程序通过实现这些协议，将应用层数据封装成协议规定的格式，然后由<code>TCP</code>或者<code>UDP</code>来进行传输。</p><p><img src="/images/layer-data.png" alt="七层数据"></p><p>每一层对应的封装如下：</p><p><img src="/images/data-unwrap.png" alt="七层数据"></p><pre><code>常见的应用层协议有：DNS、HTTP。</code></pre><p><strong>DNS域名解析协议</strong></p><p>IP地址，即使采用<code>十进制点分法</code>来标识，要记住也是比较困难的，因此产生了<code>域名</code>。</p><p>域名，相比IP地址来说，会比较容易记住，如：<a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a>.</p><p>而<code>DNS协议</code>是用来<code>解析域名</code>，获取真实IP地址的一种协议。</p><p>通过<code>nslookup + 域名</code>，再使用<code>wireshark</code>抓包，可以看到DNS查询的时候，采用的是<code>UDP</code>协议，而DNS服务器之间进行数据推送的时候，会采用<code>TCP</code>协议。</p><p><img src="/images/dns.png" alt="dns"></p><p><strong>HTTP超文本传输协议</strong></p><p>HTTP协议，将数据以<code>明文</code>的方式传输，所有的<code>www文件</code>都采用这种方式。</p><p>以<code>浏览器</code>为客户端，以<code>TCP</code>为底层传输方式。</p><p>通过浏览器向服务端发送请求，服务端向客户端浏览器返回响应。</p><p><img src="/images/http.png" alt="http"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机通讯与网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计网 - 传输层</title>
      <link href="/2019/09/25/%E8%AE%A1%E7%BD%91-%E4%BC%A0%E8%BE%93%E5%B1%82/"/>
      <url>/2019/09/25/%E8%AE%A1%E7%BD%91-%E4%BC%A0%E8%BE%93%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<pre><code>简单的说，传输层就是将两个端口连接起来通信的介质。</code></pre><p>网络层IP协议为非同一网络上的主机之间的精准通信提供了高效的手段。</p><p>数据链路层为同一网络下的主机之间的通信提供了基于MAC地址的身份识别手段。</p><p>物理层为数据信号在信道上传输、信号转换等提供了方案。</p><p>然而，同一台计算机内部，同一网络中，甚至是全球网络中的两台计算机的两个应用程序之间要相互通信，光靠以上三层是无法实现的，也因此引入了<code>端口</code>、<code>TCP协议</code>、<code>UDP协议</code>。</p><p>传输层的主要任务是</p><ul><li>建立端口到端口的通信。</li><li>通过传输层协议进行数据的传输。</li></ul><pre><code>端口</code></pre><p>网络层通过IP协议，区分了子网。</p><p>以太网通过MAC地址，区分了主机。</p><p>传输层通过端口，区分了应用程序。</p><p>同一个IP下、同一个MAC地址下的同一台计算机，运行着许许多多的应用程序（进程），每一个应用程序通过端口来做唯一标识。</p><p>端口的范围为：0 - 65535，其中0 - 1023为系统占用端口，共16位， 2^16。</p><p>有了端口、IP、MAC地址之后，那么数据就可以找到传输的入口了。</p><pre><code>传输层的传输方式包含：TCP（可靠）、UDP（不可靠）。</code></pre><p>无论是TCP，还是UDP，目的都是为了发送IP数据包。</p><p>二者的区别主要是：有无连接、是否可靠、传输效率。</p><p><img src="/images/tcp-udp.png" alt="TCP-UDP"></p><pre><code>UDP，用户数据报协议。</code></pre><p><code>UDP</code>，不需要和目标主机建立连接，直接发送数据包即可。（无连接）</p><p>无论网络问题或者目标主机问题都不管，无法保证发送的分组一定到达，只能通过<code>ICMP</code>来回应异常报告，不会对分组进行超时重试、丢失重发、流量控制、乱序调整等。（不可靠）</p><p>正常情况，发出去的数据报是可以被成功接收的，并且省了建立及维护连接通道的成本。（高效）</p><p><img src="/images/udp.png" alt="UDP"></p><p>UDP抓包情况如下：</p><p><img src="/images/udp-wireshark.png" alt="UDP"></p><p>UDP包含了：<code>源IP地址</code>、<code>目的IP地址</code>、<code>协议号</code>、<code>源端口</code>、<code>目的端口</code> 五元组，当一台计算机的进程收到多个进程的数据报时候，以此五元组来做区分。</p><pre><code>TCP，传输层控制协议。</code></pre><p><code>TCP</code>，需要先和目标主机通过三次握手建立连接，然后才能进行通信。（有连接）</p><p>无论网络问题或者目标主机问题都要管，保证发送的分组可靠到达，但不是100%。当发送分组超时了，将会重试，丢失分组了，也会重发，为了防止网络崩溃，启用了滑动窗口机制来限制发送速率，通过ack机制及包编号实现了有序性。（可靠）</p><p>由于发送数据包之前需要先建立连接，用完了还要四次挥手断开连接，再用再建立连接，如此反复，成本较大。（低效）</p><p><img src="/images/tcp.png" alt="TCP"></p><p>TCP抓包情况如下：</p><p><img src="/images/tcp-wireshark.png" alt="TCP"></p><p><strong>序列号、确认号</strong></p><p>由于TCP是面向 <code>字节流</code> 的，每一个字节都会被标注一个序列号。</p><p>比如：一段数据100字节。</p><p>第1次发送50个字节，序列号 <code>seq</code> 为1-50，第2次序列号从51开始。</p><p>当目标主机收到数据包之后，会回复确认号<code>ack</code>。</p><p><strong>控制位</strong></p><p>TCP包含的控制位有：<code>URG</code>、<code>RST</code>、<code>PSH</code>、<code>ACK</code>、<code>SYN</code>、<code>FIN</code>。</p><p><img src="/images/tcp-flags.png" alt="TCP"></p><p><img src="/images/tcp-flags-1.png" alt="TCP"></p><p>URG，紧急指针，用于标识该数据包应该被优先接收。</p><p>RST，复位，当连接断了，再继续发送包会报这个错。</p><p>PSH，推送，表示数据包被成功推送。</p><p>SYN，同步，三次握手的时候会用到。</p><p>ACK，确认，三次握手和四次挥手的时候用到，确认。</p><p>FIN，终止，四次挥手的时候用到。</p><p><strong>窗口大小</strong></p><p>滑动窗口，Window Size Value 随着发送端和接收端的情况动态调整。</p><pre><code>TCP需要先经过三次握手，才能实现可靠连接。</code></pre><p><img src="/images/handshake-ws.png" alt="三次握手"></p><p><strong>三次握手的流程为</strong></p><ul><li><p>客户端主动打开连接，通过向服务端发送<code>SYN</code>包，并发送自己的序列号<code>seq = x</code>，服务端端口监听，接收到之后，会将<code>SYN</code>放到<code>Sync Queue</code>半连接队列中，处理完后向客户端发送 <code>SYN + ACK</code>及客户端的确认号+1,<code>ack = x + 1</code> ，表明已经收到了<code>SYN</code>连接请求，并发送自己的序列号 <code>seq = y</code>。</p></li><li><p>客户端收到服务端发送的 <code>SYN + ACK</code> 后，回复一个 <code>ACK</code>,并将对方的确认号+1，<code>ack = y + 1</code>。</p></li><li><p>如果客户端没有收到服务端发送的 <code>SYN + ACK</code>，那么服务端会再继续重发，直到超时或者成功。<code>DDos</code>中有一种 <code>SYN Flood</code>洪水攻击，通过伪造大量IP端口，并发送<code>SYN</code>，然后消失，导致服务端一直等不到<code>SYN + ACK</code>之后的<code>ACK</code>，导致稀缺的资源被占用，甚至宕机。</p></li><li><p>最终，双方相互确认之后，正式建立连接，连接会在 <code>Accept Queue</code> 连接队列中维护，用来控制服务端 <code>最大连接数</code>。</p></li></ul><p><strong>三次握手的原因</strong></p><p>可以防止已经失效的连接请求报文又被突然传到服务端，导致错误产生。</p><p>一个因为<code>网络延迟</code>到达的<code>SYN</code>连接请求报文被服务端接收了，没有<code>二次确认</code>的话，服务端将会和客户端直接建立连接，否则客户端会将服务端回应的报文直接<code>忽略</code>。</p><pre><code>类似地，TCP需要先经过四次挥手，才能实现可靠断连。</code></pre><p><img src="/images/wave-ws.png" alt="四次挥手"></p><p><strong>四次挥手的流程为</strong></p><ul><li><p>客户端发送 <code>FIN</code>主动关闭连接，并发送序列号<code>seq = x</code>，同时可能会发送<code>ACK</code>，用来确认之前接收的报文，然后进入<code>FIN_WAIT_1</code>状态，等待服务端回应，并且不会再发送数据了。</p></li><li><p>服务端接收到客户端的<code>FIN</code>控制指令，此时还有未发送完的数据，那么就先回复一个<code>ACK</code>以及确认号<code>ack = x + 1</code>，表示自己已经接收到了客户端的<code>FIN</code>。</p></li><li><p>服务端发送完剩下的数据后，向客户端发送<code>FIN</code>,同样也会附带一个<code>ACK</code>，用来确认之前的指令，随后服务端进入<code>CLOSE_WAIT</code>半关闭状态，等待客户端<code>ACK</code>。</p></li><li><p>客户端接收到<code>FIN</code>之后，双方确认数据已经传输完毕，并立即回复一个<code>ACK</code>，服务端收到后，立即进入<code>closed</code>状态。</p></li><li><p>但是，客户端需要进入<code>TIME_WAIT</code>状态，防止发出去的<code>ACK</code>没有被服务端接收。服务器端如果没有接收到<code>ACK</code>，将会重新发送<code>FIN</code>给客户端，直到超时或者成功。当然，也是因为这个特性，DDos攻击也会存在于这个阶段。</p></li><li><p>最后，客户端真正关闭连接。</p></li></ul><pre><code>TCP通过拥塞控制防止过多数据注入网络，造成过载。</code></pre><p>在<code>数据链路层</code>中存在着<code>流量控制</code>，当收发数据的时候，双方能知道对方的剩余可用<code>缓冲区</code>大小，然后<code>调整</code>发送频率及数据量。</p><p>在<code>TCP</code>当中，存在着比数据链路层更高级的<code>拥塞控制</code>,需要考虑双方的收发能力及链路的通畅程度。</p><p>TCP通过 <code>滑动窗口</code>及 <code>慢开始</code>、<code>快恢复</code> 算法来实现拥塞控制。</p><p>当存在数据包没有被<code>ACK</code>，那么就会被认定为<code>网络堵塞</code>，然后调小 <code>滑动窗口</code> 大小，且<code>门限阈值</code>降低为原来的 <code>一半</code>。</p><p><img src="/images/tcp-flow-control.png" alt="拥塞控制"></p><p><strong>拥塞避免</strong>，为了防止窗口增加速度过快，设置了一个慢开始门限，窗口每次增加1。</p><ul><li>当窗口大小小于门限的时候，采用慢开始算法。（指数增大）</li><li>当窗口大小大于门限的时候，采用拥塞避免算法。（加法增大）</li><li>当窗口大小大于门限的时候，两种算法都可以。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机通讯与网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计网 - 网络层</title>
      <link href="/2019/09/20/%E8%AE%A1%E7%BD%91-%E7%BD%91%E7%BB%9C%E5%B1%82/"/>
      <url>/2019/09/20/%E8%AE%A1%E7%BD%91-%E7%BD%91%E7%BB%9C%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<pre><code>对于不同的广播域，要通信靠全球广播是不可行的，因此引入了网络层。</code></pre><p>一个局域网称为一个广播域，在一个广播域中要进行通信，只需要向所有计算机发送请求，目标计算机在同一广播域中，收到请求后，响应即可。</p><p>不同的局域网就是不同的广播域，跨广播域通信，理论上可以向所有广播域发送请求，等待目标计算机响应即可，但是全球计算机数量过于庞大，一台计算机能接收到全世界计算机发送的包，纯靠广播容易产生网络风暴以及低效。</p><p>引入一套新的地址来区分不同的广播域、子网，这套地址称为：<code>网络地址</code>。</p><pre><code>网络层引入了IP、路由，跨广播域通信只能通过路由转发。</code></pre><p>给计算机提供IP地址，经过路由器的转发，寻找到目标广播域，由目标广播域内部再进行广播，找到目标计算机即可。</p><p><img src="/images/internet-bc.png" alt="跨广播域"></p><p>简单的说，<code>网络层</code> 就是在 <code>数据链路层</code> 的基础上进一步管理网络中的数据通信。</p><p>从<code>广播</code>的方式转为<code>跳跃</code>若干个中间节点的方式来完成数据通信。</p><p>跨广播域通信只能通过 <code>路由转发</code>。</p><p>网络层包含了：IP、ARP、RARP、ICMP、IGMP、路由选择、拥塞控制。</p><pre><code>IP协议，定义网络地址的协议。</code></pre><p>通过IP地址，为网络上的计算机提供一个逻辑地址及编号。</p><p>IP协议，分为：IPv4、IPv6。</p><p>IPv4，由32位的二进制数组成，用点分隔，因为可读性差，通常写成4个十进制数。</p><p>范围: <code>0.0.0.0</code> - <code>255.255.255.255</code></p><p>通常，家庭里拨号上网，ISP就会给分配一个IP，每次拨号获得的IP都可能是不一致的。</p><p>网络上的其它计算机要通信可以通过分配到的IP找到家庭里的计算机。</p><pre><code>IP地址 = 网络地址 + 主机地址</code></pre><p>通过 <code>子网掩码</code>，可以很方便的将IP地址划分为<code>网络部分</code>和<code>主机部分</code>。</p><p>比如：</p><ul><li>IP地址 172.16.10.1</li><li>子网掩码 255.255.255.0</li></ul><p>分别将二者转为<code>二进制</code>，再做一个<code>与运算</code>，得到 <code>172.16.10.0</code>，这部分就是网络部分，而主机部分则可以取值为 <code>0.0.0.1 - 0.0.0.254</code>，主机部分不能全为0，也不能全为1。</p><p>2个IP地址，通过与子网掩码做一个与运算，就可以计算出这两个IP是否在同一个子网中。<code>不同子网</code>中的2个IP地址是无法直接通信的，则需要通过 <code>网关</code>、<code>路由器</code>来间接通信。</p><p>通过 <code>tracert</code> 或者 <code>tracerouter</code> 命令可以查看到IP在路由过程中跳跃的路径。</p><p><img src="/images/tracert.png" alt="百度tracert"></p><pre><code>IP数据包作为数据链路层帧的数据部分。</code></pre><p>IP数据包分为：头部和数据部分。</p><p>头部：大小在20到60字节之间。</p><p>数据部分：最长为65515字节。</p><p>超过下层数据链路帧限制的 MTU 1500字节的话，将需要分片传输。</p><p><img src="/images/dll-frame.png" alt="数据包"></p><p>网络层IP数据包的结构如下：</p><p><img src="/images/ip-packet.png" alt="数据包"></p><p>IP数据包抓包如下：</p><p><img src="/images/ip-wireshark.png" alt="数据包"></p><pre><code>由于IP协议，无连接，不可靠，引入了ICMP。</code></pre><p>发送IP数据包的时候，即使是丢包了，那么对于IP协议来说也是未知的，因此，通过ICMP（Internet控制报文协议）可以得知网络通不通、路由是否可达、是否超时等信息。</p><p>ICMP是一种无连接的面向无连接的控制报文协议，用来传输出错控制报文信息。</p><p>常用的就是<code>ping</code>命令。</p><p>正常情况下的<code>ping</code>如下<br><img src="/images/ping-baidu.png" alt="ping"></p><p>异常的<code>ping</code>如下<br><img src="/images/ping-google.png" alt="ping"></p><p>wireshark抓包情况如下<br><img src="/images/ping-wireshark.png" alt="ping"></p><p>正常情况下，每一个<code>request</code>都会收到一个<code>reply</code>，否则会收到<code>no response found</code>之类的响应。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机通讯与网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计网 - 数据链路层</title>
      <link href="/2019/09/16/%E8%AE%A1%E7%BD%91-%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/"/>
      <url>/2019/09/16/%E8%AE%A1%E7%BD%91-%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<pre><code>简单的说，数据链路层定义了电信号的分组方式。</code></pre><p>数据链路层，连接了上层的 <code>网络层</code> 和下层的 <code>物理层</code>。</p><p>数据链路层是对物理层功能的增强，将物理层连接转为逻辑上无差错的链路。</p><p>为上层网络层提供透明传输和可靠的数据传输服务。</p><p><img src="/images/data-link-layer.png" alt="数据链路层"></p><p>单纯的电信号0和1是没有任何意义的，只有规定多少个为一组，每一组都是什么意思才有意义。<br>而这些分组要有意义，是由 <code>通信协议</code> 来控制的。</p><p>把实现这些 <code>通信协议</code> 的硬件和软件加到链路上，就形成了数据链路。<br>这样的硬件比如：网卡、交换机。</p><pre><code>数据链路层需要解决三个问题：封装成帧、透明传输、差错校验。</code></pre><p>主要关注的是：</p><ol><li>怎么封装成帧</li><li>怎么去传输帧</li><li>帧传输目的地</li><li>校验帧完整性</li></ol><pre><code>在一段数据的前后增加首部、尾部，这就形成了一个帧。</code></pre><p><img src="/images/dll-frame.png" alt="数据链路帧"></p><p>帧，包含：帧头、数据部分、帧尾。</p><p>不同的数据链路层通信协议会对应着不同的帧。</p><p><strong>帧头</strong></p><p>由8位二进制数组成，代表的是网络层数据包的开始。</p><p>从应用层开始往下，每一层都会接收上层数据，并加入自己的头。</p><p><strong>数据部分</strong></p><p>大小至少46字节，最大1500字节，也就是最大传输单元MTU。</p><p>如果数据过大，将会产生分片。</p><p><strong>帧尾</strong></p><p>由8位二进制数组成，代表的是网络层数据包的结束，也包含了一些控制信息。</p><p>通过帧的首部和尾部包含的控制信息，来给帧定义一个边界。</p><pre><code>帧，采用的是透明传输。</code></pre><p>不论上层传输过来的内容是什么，数据链路层只会将上层的数据部分的内容往下传输，起到一个通道的作用，并且保证传输质量，不参与任何业务。</p><p>为了表示一个帧结束了，在帧尾添加了 <code>特殊转义字符ESC</code>。当然，由于对上层数据采用透传的策略，可能因为数据中就包含了<code>ESC</code>，导致<code>帧提前结束</code>，因此遇到 <code>多个ESC</code> 的时候，将会删除其它，采用最后一个作为结束。</p><pre><code>由于数据帧传输过程中可能发生错误，则需要差错校验。</code></pre><p>因为在网络中传输的过程中，可能会有噪声等多方面因素，导致原本数据包中的bit产生比特差错，由1变成0，由0变成1，就需要进行差错校验。</p><p><img src="/images/bit-error.png" alt="差错校验"></p><p>数据链路层中采用的方式是：<code>CRC循环冗余校验法</code>。</p><p>CRC校验，通过在数据为K位的数据后添加n位的冗余码组成帧。</p><p><img src="/images/frame.png" alt="CRC校验"></p><p>发送端和接收端，共同协商出一个<code>多项式</code>，作为<code>除数</code>，将要发送的数据设定为固定大小的位数，作为<code>被除数</code>，通过反复的<code>异或取余</code>，最终得到一个<code>冗余码</code>，通过比较二者<code>冗余码 FCS</code>是否一致来确定<code>帧的完整性</code>。<br><img src="/images/crc-table.png" alt="多项式"></p><p>多项式由 <code>x^n</code> 是否存在，由高到低组成，存在为1，否则为0。</p><p><img src="/images/calculate-div.png" alt="冗余码"></p><p>异或：<code>1 ^ 1 = 0</code>、<code>1 ^ 0 = 1</code>、<code>0 ^ 0 = 0</code>。</p><pre><code>数据链路层提供了三种基本服务。</code></pre><p>根据链路的可靠性以及效率来划分。</p><ol><li>无确认无连接服务</li><li>有确认无连接服务</li><li>有确认有连接服务</li></ol><p>相比来说，无连接的比起有连接的效率更高，有确认的比无确认的可靠性更高。</p><p>通过<code>差错校验</code>之后，假设数据帧已经没有问题了，但如果由于网络问题，导致<code>丢包</code>了，那么这条链路也就算是<code>不可靠</code>的了。</p><p><code>无确认无连接服务</code>，只管往哪个目的地传送数据帧即可，哪怕丢失了也不做处理。</p><p><code>有确认无连接服务</code>，在无确认无连接服务的基础上，要求接收方在收到数据帧之后做<code>确认</code>处理，如果超时后没有收到则会重发。</p><p><code>有确认有连接服务</code>，在有确认无连接服务的基础上，将接收方和发送方之间建立一个<code>连接</code>，并且给每一个发送的帧加上<code>编号</code>，并且需要接收方接收到帧后做<code>确认</code>处理，比起有确认无连接服务，可以防止一个帧被多次重复发送，接收方多次重复接收。</p><pre><code>在不可靠的链路上，通过各种协议，来最终实现可靠传输。</code></pre><p>CRC只能保证传输的帧的数据是完整的，无法保证传输的帧一定被接收。</p><p>为了实现可靠传输，产生了 <code>停止等待协议</code>、<code>退回N步协议</code>、<code>选择重传协议</code>。</p><p><strong>停止等待协议</strong></p><p>发送方一次只能发送一帧，发送的同时启动计时器，然后等待接收方的确认信息。</p><p>如果时间超过了两倍来回时间，则重新发送当前帧，并重新启动计时器。</p><p>如果确认分组丢失了，或者接收到的帧的编号不是接收方期望接收到的编号或者超时了，则会要求发送方重新发送要求发送的帧。</p><p><strong>退回N步协议</strong></p><p>由于<code>停止等待协议</code>这种方式效率较低，为了改进以便提高信道的传输效率，接收方允许发送方<code>一次</code>发送<code>多个帧</code>，将帧存入<code>FIFO buffer</code>中，然后再逐步<code>ack</code>，从中删除正确的帧。但是，如果中间某一帧<code>丢失</code>了，那么就需要从<code>丢失的帧号</code>开始<code>全部重传</code>。</p><p><img src="/images/arq.png" alt="arq"></p><p>另外，由于发送方和接收方的处理能力不一样，需要基于 <code>滑动窗口</code> 来控制发送的速率和帧数。</p><p><strong>选择重传协议</strong></p><p>由于<code>退回N步协议</code>,每次都需要从<code>丢失的帧号</code>开始 <code>全部重传</code>，对于已经被<code>ack</code>的分组也会被<code>重传</code>，这种方式也是不利于提高信道的传输效率的，那么就通过<code>选择重传协议</code>，只将<code>发送错误的分组</code>重传即可。<br><img src="/images/arq+.png" alt="arq"></p><pre><code>数据链路层的信道分为：点对点信道、广播信道。</code></pre><p><img src="/images/dll-road.png" alt="dll-road"></p><p>点对点信道采用的主要是 <code>PPP协议</code>，一种点对点的协议。</p><p>家庭中的宽带拨号的时候，通常会是<code>PPPoE</code>。</p><p><img src="/images/ppp.png" alt="ppp"></p><p>PPP的链路包含6个步骤。</p><p>用户通过宽带PPPoE拨号，与ISP建立连接，由下层物理层来负责链路的建立，当链路建立成功后，双方发送LCP包来确认链路的一些信息（最大帧长、鉴权协议）以及是否可以在当前链路传输，之后再进行鉴权（身份识别、是否欠费）操作，成功的话，则开始进行网络层控制协议（NCP）配置的协商（分配IP、网络层协议），协商成功后则正式打开链路，进行数据的传输，数据传输完成后就进入了链路终止状态。</p><p><img src="/images/ppp-link.png" alt="ppp"></p><p>广播信道主要采用的是以太网通信标准，常用于局域网。</p><p>所谓的一台计算机发送的信号会被局域网内的所有计算机都收到。</p><p><img src="/images/broadcast.png" alt="broadcast"></p><pre><code>以太网协议，早期各企业自定分组方式，后形成的标准。</code></pre><p>上文提到了，数据链路层通过通信协议为电信号提供分组方式。</p><p><code>Ethernet</code> 规定，一组电信号组成一个数据包，称为<code>帧</code>。</p><p>每一个数据帧由头 <code>head</code> 和数据 <code>data</code> 组成。</p><ul><li><p><code>head</code> 固定18个字节，包含：<code>发送者/源地址</code>、<code>接收者/目标地址</code>、<code>数据类型</code>，各占6字节。</p></li><li><p><code>data</code> 最短46字节，最长1500字节，是数据包的具体内容，超过MTU的话则需要分片传输。</p></li></ul><p>以太网就是局域网，局域网不一定是以太网。</p><p>在以太网中，<code>发送者/源地址</code>、<code>接收者/目标地址</code>是由 <code>mac地址</code>来确定的，这个地址在网卡上标识着，全球唯一的。</p><p>因此，发送者、接收者的地址，说的就是 <code>网卡的地址</code>。</p><p><code>mac地址</code>由48位二进制组成，12位16进制组成，前6位是厂商编号，后6位是流水号。</p><p><img src="/images/mac.png" alt="mac地址"></p><p>找了个网址查了一下，<a href="https://mac.51240.com/" target="_blank" rel="noopener">点击查询</a></p><p><img src="/images/mac-addr.png" alt="mac地址"></p><p>有了mac地址之后，同一个网络中的计算机就可以通过mac地址找到对方，并进行通信了。</p><p>理论上，全世界的计算机之间都可以通过mac地址和对方相互通信。</p><p>只需要在数据帧的 <code>head</code> 部分写入自己的mac地址和对方的mac地址，然后给<code>同一网络</code>中的<code>所有</code>计算机发送信息，对比接收者是否自身，以此方式完成通信。这种方式，也称之为 <code>广播</code>。</p><p>通常，在通信的时候，只知道对方的IP地址，而不知道物理地址。</p><pre><code>ARP协议就被设计来通过IP地址查询对方MAC地址。</code></pre><p>一台计算机通过ARP协议可以获取另一台计算机的mac地址。</p><p>在TCP/IP模型中，ARP协议属于网络层协议。</p><p>在OSI模型中，ARP协议属于数据链路层协议。</p><p><img src="/images/mac-frame.png" alt="arp帧"></p><p>抓包信息如下：</p><p><img src="/images/arp-wireshark.png" alt="arp"></p><p>通过ARP协议，发送以太网帧，去询问同一网络上的所有计算机，IP是目标计算机的话，那就回复MAC地址，否则丢弃，默认请求数据下为 <code>00:00:00:00:00:00</code>。查询到目标IP对应的MAC地址之后就缓存到自己的内存中。</p><p>ARP分为两种类型：静态和动态。</p><p>通过 <code>arp -a</code> 命令可以查看到已缓存、配置的IP和MAC地址映射表，且可以知道动静类型。</p><p>ARP地址解析协议的工作流程如下：</p><p><img src="/images/arp-line.png" alt="arp"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机通讯与网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计网 - 物理层</title>
      <link href="/2019/09/16/%E8%AE%A1%E7%BD%91-%E7%89%A9%E7%90%86%E5%B1%82/"/>
      <url>/2019/09/16/%E8%AE%A1%E7%BD%91-%E7%89%A9%E7%90%86%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<pre><code>在网络上，两台计算机要通信，就需要一个通信媒介。</code></pre><p>物理层，通过这么一个介质，使得两台计算机之间得以完成信号的传输。</p><p>如果全世界的计算机都连接到彼此互通的介质中，那么彼此之间都可以相互进行信号的传输了。</p><p>通信的根本目的就是为了传输数据，而这个数据可以是任何形式的。</p><p>在生活中，常见的信号传输介质有：光缆、电缆、双绞线、无线电波等。</p><p><img src="/images/layer01.png" alt="物理层"></p><p>简单的说，物理层包含的就是<code>通信介质</code>和<code>信号传输</code>。</p><p>通俗的说，物理层规定了<code>通信数据</code>应该以何种方式、何种形态、在何处进行传输。</p><pre><code>物理层规定了通信介质的一些特性。</code></pre><ul><li>机械特性</li><li>电气特性</li><li>规程特性</li></ul><p>机械特性，规定了接口的大小、形状、颜色、排列方式，比如：RJ45水晶头。</p><p>电气特性，规定了在网线中传输的电压的范围，分为高（5V）低（-5V）电压。</p><p>规程特性，规定了建立连接时元器组件之间的工作方式及步骤。</p><pre><code>信号的形态分为：模拟信号、数字信号。</code></pre><p><img src="/images/signal.png" alt="信号的形态"></p><p>信号数据，可以表示图片、语音、文字、视频等任何信息。</p><p>模拟信号，指的是在某一段连续时间内，信号的幅度、频率、相位随着时间的变化而连续变化。</p><p>数字信号，指的是幅度的取值被限制为0和1的离散型信号，跳跃着变化的，由高低电压来体现。</p><p><code>调制解调器</code>，实现了<code>模拟信号</code>和<code>数字信号</code>的转换。</p><p>在家庭中，<code>调制解调器</code>又称为<code>猫</code>,既可以连接电信电路，又可以连接网线。</p><p>电话信号一般是低频率的，而高频率的则用来作为宽带信号。</p><p>调制：将<code>数字信号</code>转为<code>模拟信号</code>的过程。</p><p>解调：将<code>模拟信号</code>转为<code>数字信号</code>的过程。</p><p><img src="/images/tzjtq.png" alt="调制解调器"></p><pre><code>信号又分为：基带信号、带通信号。</code></pre><ul><li><p>基带信号（类比货物）</p><p>从信号源头产生的没有经过加工的信号。</p><p>在手机中，基带是手机的通信模块，调制解调器。</p><p>手机通话、上网质量差跟基带也是有莫大的关系的。</p></li><li><p>带通信号（类比货车）</p><p>基带信号经过载波调制后，被放大频率，以便在信道中传输。</p><p>载波是一个特定频率的无线电波，单位是Hz，是一种在频率、调幅、相位方面被调制成用来传输语音、文本等数据的电磁波。由振荡器产生的并在信道上传输的无线电波，频率会比基带信号高，属于高频信号。</p></li></ul><p><img src="/images/jddt.png" alt="基带信号"></p><p>信号的传输方式：</p><ul><li>串行、并行</li><li>单工、半双工、全双工</li><li>位同步、字符同步</li></ul><p>串行，将一个字符的二进制码1个个的从低位向高位在信道中依次传输。</p><p>并行，将一个字符的二进制码在8个并行信道中同时传输。</p><p><img src="/images/transtype.png" alt="transtype"></p><p>单工，信号只能单向传输。</p><p>半双工，信号支持双向传输，但是同一时刻只允许往一个方向。</p><p>全双工，信号支持双向传输，并且同一时刻允许往两个方向。</p><p><img src="/images/work.png" alt="work"></p><p>位同步，使接收端的每一位都跟发送端的保持同步状态，也是<code>数字信号码元</code>时间对齐的过程。<code>码元</code>指的是<code>数字信号</code>的<code>0、1</code>，1个<code>码元</code>可以携带多个<code>bit</code>的数据量。</p><p>位同步包含：外同步、内同步。</p><ul><li>外同步</li></ul><p>发送端发送数据时，同时发送<code>时钟信号</code>，接收方用<code>同步信号</code>来锁定自己的<code>时钟脉冲频率</code>。</p><p><code>时钟脉冲</code>指的是<code>脉冲信号</code>是一个按一定电压幅度，一定时间间隔连续发出的脉冲信号。<code>脉冲信号</code>之间的时间间隔称为<code>周期</code>。一个<code>周期</code>发送的<code>脉冲信号</code>的个数称为<code>频率</code>。<code>频率</code>的计量单位是<code>赫兹Hz</code>。</p><p>通俗的说，就是二者要在一个频道上。</p><p><img src="/images/hz.png" alt="电信频谱"></p><ul><li>内同步</li></ul><p>发送端通过特殊的编码方式进行编码，如：<code>曼彻斯特编码</code>,这些编码信号中包含了<code>同步信号</code>，接收端从这些信号中提取出<code>时钟脉冲频率</code>。</p><p><code>字符同步</code>，由于位同步只能以二进制码元的方式传输，为了识别出每一个字符的边界，还需要通过字符同步的方式来约束每一个字符应该到哪结束，如：ASCII编码，每一个字符都是8位，则应该以8位8位的方式作为一个字符的结束点来同步。</p><p><img src="/images/trans.png" alt="信号转换"></p><pre><code>信道，表示传输信息的媒体。</code></pre><p>信道分为：有线信道、无线信道。</p><ul><li><p>有线信道（导向传输媒体）</p><p>常见的有线信道，包含有：明线、对称电缆、同轴电缆、光纤。</p><p>明线，架在电线杆上的那种。</p><p>对称电缆，比如双绞线。</p><p>同轴电缆，那种同心圆柱体状的电缆。</p><p>光纤，利用光反射的原理使其在纤导中传播。</p></li></ul><ul><li><p>无线信道（非导向传输媒体）</p><p>信号基于电磁波传输，假想的一个无形的通道，比如无线电。</p><p>根据频段的不同来区分不同的信道。</p><p>在家庭路由器当中，通常会有13个信道，每个信道频率不同。</p></li></ul><pre><code>数据通信系统</code></pre><p><img src="/images/sjtxxt.png" alt="数据通信系统"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机通讯与网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计网 - 网络基础</title>
      <link href="/2019/09/15/%E8%AE%A1%E7%BD%91-%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/"/>
      <url>/2019/09/15/%E8%AE%A1%E7%BD%91-%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<pre><code>一台计算机，本质上就是一堆零件，只有安装上了软件，才能被正常使用。</code></pre><p>计算机由硬件和软件组成。</p><p>硬件包括：CPU、内存、磁盘、主板、网卡、声卡、显卡等。</p><p>软件包括：操作系统软件、应用程序软件。</p><p>如果没有软件，计算机就是一堆破铜烂铁，而如何来管理这些硬件，就需要操作系统软件来帮助完成这件事情了。</p><p><img src="/images/computer.png" alt="computer.png"></p><pre><code>操作系统</code></pre><p>操作系统是管理和控制计算机硬件和软件资源的计算机软件，是最基本的系统软件。</p><p>所有的应用程序软件都需要在操作系统的支持下才能使用。</p><p>操作系统为软件程序的运行提供了调度、分配硬件资源，协调多个程序之间的运行，也为用户提供了一个可视化的界面。</p><pre><code>网络通信</code></pre><p>一台计算机可以使用了之后，多台计算机之间如果不相互通信，那么计算机就比较孤独了，人与人之间需要通信，计算机之间也是需要通信的。</p><p>计算机之间通过互联网来完成彼此之间的通信，而计算机之间总得需要有一样的方言才能读懂对方计算机在说什么吧，而计算机之间的方言被称之为<code>互联网协议</code>。</p><p><code>互联网协议</code>定义了网络之间如何相互连接、如何进行通信的种种标准。</p><p><img src="/images/Internet.png" alt="Internet.png"></p><pre><code>互联网协议</code></pre><p>有个称为 <code>ISO 国际标准化组织</code>，定义了一个 <code>OSI模型</code>，定义了不同计算机之间的通信标准。这个模型将网络通信分为七层：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。</p><p><img src="/images/protocol.png" alt="protocol.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机通讯与网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IM - 消息可靠性的解决</title>
      <link href="/2019/09/14/IM-%E6%B6%88%E6%81%AF%E5%8F%AF%E9%9D%A0%E6%80%A7%E7%9A%84%E8%A7%A3%E5%86%B3/"/>
      <url>/2019/09/14/IM-%E6%B6%88%E6%81%AF%E5%8F%AF%E9%9D%A0%E6%80%A7%E7%9A%84%E8%A7%A3%E5%86%B3/</url>
      
        <content type="html"><![CDATA[<pre><code>当消息下推到客户端的时候，服务端对于推送状态是无感知的。</code></pre><p>在用户建立连接的时候，在<code>Channel</code>中缓存并初始化<code>tid</code>为<code>0</code>，每一条消息下推的时候，都会设置一个自增<code>tid</code>，并将<code>等待Ack</code>的消息存储在队列中，一旦某个<code>tid</code>被<code>Ack</code>了就将该消息移出队列。</p><p>也有一些情况，比如超过设置的期望时间，还没有<code>Ack</code>,则可以认为该消息丢失了，则启动重新下推的操作。</p><p><code>ACK</code>的数据结构可以定义为：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Ack</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> tid;</span><br><span class="line">    <span class="keyword">private</span> String msgId;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WaitAckMessage</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Message message;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> tid;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义一个<code>AckBuffer</code>来存储ack的信息</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AckBuffer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Set&lt;Long&gt; set = Sets.newHashSet();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">acknowledge</span><span class="params">(Ack ack)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//可以使用redis的zset来实现</span></span><br><span class="line">        set.remove(ack.getTid());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addAck</span><span class="params">(Ack ack)</span> </span>&#123;</span><br><span class="line">        set.add(ack.getTid());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> IM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IM - 离线消息乱序的解决</title>
      <link href="/2019/09/14/IM-%E7%A6%BB%E7%BA%BF%E6%B6%88%E6%81%AF%E4%B9%B1%E5%BA%8F%E7%9A%84%E8%A7%A3%E5%86%B3/"/>
      <url>/2019/09/14/IM-%E7%A6%BB%E7%BA%BF%E6%B6%88%E6%81%AF%E4%B9%B1%E5%BA%8F%E7%9A%84%E8%A7%A3%E5%86%B3/</url>
      
        <content type="html"><![CDATA[<pre><code>由于多线程及网络延迟的原因，离线消息sub出来可能会乱序。</code></pre><p>假设存在离线消息队列 <code>Redis</code>,以及 <code>10</code> 条消息，理想情况下消息按照顺序<code>1,2,3,4,5,6,7,8,9,10</code>完整<code>pub</code>入<code>Redis</code>中，但可能因为<code>网络延迟</code>导致顺序变成<code>1,3,2,6,5,4,7,8,9,10</code>，也可能顺序存入没问题，实打实的就是<code>1,2,3,4,5,6,7,8,9,10</code>，但是从<code>Redis</code>中<code>sub</code>出来的时候变成了<code>1,2,3,5,6,4,8,9,7,10</code>,也因此导致了离线消息乱序的产生。</p><p>为了解决这个问题，可以在每次触发拉取离线消息的时候，在服务端先取出所有消息，给每一条消息设置一个从0开始的自增<code>seqId</code>，为了防止突然上线突然下线反复拉取离线消息，需要给每一次的离线消息设置一个随机<code>packageId</code>，也是为了区分消息是否是新写入离线消息队列中的消息用的。</p><p>定义<code>Message</code>类表示要下推前未处理的消息</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Message</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String msgId;</span><br><span class="line">    <span class="keyword">private</span> String deviceId;</span><br><span class="line">    <span class="keyword">private</span> Long userId;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> packageId;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> seqId;</span><br><span class="line">    <span class="comment">//....more</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义<code>ChannelUtil</code>类表示<code>Channel</code>工具类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ChannelUtil</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> AttributeKey&lt;ConcurrentHashMap&lt;Integer, PackageQueue&gt;&gt; packageKey = AttributeKey.valueOf(<span class="string">"package_queue"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">setPackageQueue</span><span class="params">(Channel channel, ConcurrentHashMap&lt;Integer, PackageQueue&gt; packageQueueMap)</span> </span>&#123;</span><br><span class="line">        channel.attr(packageKey).set(packageQueueMap);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ConcurrentHashMap&lt;Integer, PackageQueue&gt; <span class="title">getPackageQueue</span><span class="params">(Channel channel)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> channel.attr(packageKey).get();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Channel <span class="title">getChannelByUserInfo</span><span class="params">(String deviceId, Long userId)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//ignore...</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义<code>SequenceMessage</code>类表示排序消息</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SequenceMessage</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> seqId;</span><br><span class="line">    <span class="keyword">private</span> String msgId;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义<code>PackageQueue</code>表示包队列</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 包队列</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PackageQueue</span> </span>&#123;</span><br><span class="line">    <span class="comment">//根据seqId排序</span></span><br><span class="line">    <span class="keyword">private</span> PriorityQueue&lt;SequenceMessage&gt; q =</span><br><span class="line">            <span class="keyword">new</span> PriorityQueue&lt;&gt;(Comparator.comparingInt(s -&gt; s.getSeqId()));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Channel channel;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> packageId;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">PackageQueue</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">PackageQueue</span><span class="params">(Channel channel, <span class="keyword">int</span> packageId)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.channel = channel;</span><br><span class="line">        <span class="keyword">this</span>.packageId = packageId;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addMsg</span><span class="params">(SequenceMessage msg)</span> </span>&#123;</span><br><span class="line">        q.add(msg);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">drainOut</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">//...</span></span><br><span class="line">        <span class="keyword">while</span> (!q.isEmpty()) &#123;</span><br><span class="line">            <span class="comment">//需将推送包封装为HeaderMap、BodyMap形式，该demo忽略</span></span><br><span class="line">            channel.writeAndFlush(q.poll());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义<code>PackageQueueManager</code>表示包队列管理器</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 包队列管理器</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PackageQueueManager</span> </span>&#123;</span><br><span class="line">    <span class="comment">//定时</span></span><br><span class="line">    <span class="keyword">private</span> ScheduledExecutorService executorService = <span class="keyword">new</span> ScheduledThreadPoolExecutor(<span class="number">10</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ConcurrentHashMap&lt;Integer, PackageQueue&gt; <span class="title">getPackageQueue</span><span class="params">(Channel channel)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ChannelUtil.getPackageQueue(channel);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//sub from redis and invoke this method</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addMsg</span><span class="params">(Message message)</span> </span>&#123;</span><br><span class="line">        Channel channel = ChannelUtil.getChannelByUserInfo(message.getDeviceId(), message.getUserId());</span><br><span class="line">        <span class="keyword">if</span> (channel != <span class="keyword">null</span> &amp;&amp; channel.isActive()) &#123;</span><br><span class="line">            ConcurrentHashMap&lt;Integer, PackageQueue&gt; packageQueueMap = getPackageQueue(channel);</span><br><span class="line">            packageQueueMap.computeIfAbsent(message.getPackageId(), pid -&gt; &#123;</span><br><span class="line">                PackageQueue packageQueue = <span class="keyword">new</span> PackageQueue(channel, pid);</span><br><span class="line">                <span class="comment">//2秒下发一次</span></span><br><span class="line">                executorService.schedule(packageQueue::drainOut, <span class="number">2</span>, TimeUnit.SECONDS);</span><br><span class="line">                <span class="keyword">return</span> packageQueue;</span><br><span class="line">            &#125;).addMsg(<span class="keyword">new</span> SequenceMessage(message.getSeqId(), message.getMsgId()));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义<code>Publisher</code>表示离线消息的发布者</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Publisher</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getOfflineMsgs</span><span class="params">(Long userId, String deviceId, Long syncVersion, String pubChannel)</span> </span>&#123;</span><br><span class="line">        List&lt;Message&gt; messageList = loadOfflineMsgs(syncVersion);</span><br><span class="line">        <span class="keyword">int</span> packageId = ThreadLocalRandom.current().nextInt(<span class="number">1</span>, Integer.MAX_VALUE);</span><br><span class="line">        <span class="keyword">int</span> seqId = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (Message message : messageList) &#123;</span><br><span class="line">            message.setDeviceId(deviceId);</span><br><span class="line">            message.setUserId(userId);</span><br><span class="line">            message.setSeqId(seqId++);</span><br><span class="line">            message.setPackageId(packageId);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//pub to redis, the channel is : pubChannel</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> List&lt;Message&gt; <span class="title">loadOfflineMsgs</span><span class="params">(<span class="keyword">long</span> startVersion)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//from redis</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> IM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IM - 队列机层</title>
      <link href="/2019/09/14/IM-%E9%98%9F%E5%88%97%E6%9C%BA%E5%B1%82/"/>
      <url>/2019/09/14/IM-%E9%98%9F%E5%88%97%E6%9C%BA%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<pre><code>队列机层起到了聚合多方消息，减轻网关层压力的中间枢纽作用。</code></pre><p>作为一个系统，可能是独享的，可能开放出一些能力提供给其它业务方使用，为了方便、安全、快捷，可通过队列机层来集中处理这些消息。</p><p>比如：发送私信，客户端可以直接通过上行接口直接调用，可以通过写入消息队列中，可以通过短信发送，而队列机无需关心消息到底怎么来，只需要关注消息可以这么来，而消息的来源渠道可以由各业务方来实现，以及消息如何处理，将要发送到什么地方，是否需要写入离线缓存队列中。</p><p>另外，哪怕多来几个不同APP，要接收下推消息，并且不想接入我方实现的网关层来进行消息下推，可以自行 <code>sub</code> 队列机层的 <code>Redis</code>，然后由自己来实现<code>网关层</code>。</p>]]></content>
      
      
      
        <tags>
            
            <tag> IM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IM - 服务层</title>
      <link href="/2019/09/14/IM-%E6%9C%8D%E5%8A%A1%E5%B1%82/"/>
      <url>/2019/09/14/IM-%E6%9C%8D%E5%8A%A1%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<pre><code>在整个链路中，API层相当于长连网关层的服务端，也相当于服务层的客户端。</code></pre><p>服务层包含有：私信、群聊、群发等。</p><p><code>API层</code>通过<code>HTTP</code>或者<code>RPC</code>的方式，去调用<code>服务层</code>的各种服务，然后返回处理 <code>成功</code> 或者 <code>失败</code>报文给 <code>API层</code>。</p><p><code>服务层</code> 处理成功之后，将消息存入<code>MySQL</code>、<code>HBase</code> 等存储中，每一条消息都会有个<code>版本号</code>，基于用户维度的，然后将消息写入 <code>Redis</code>、<code>MemcachedQ</code>、<code>Kafka</code> 等消息中间件中，由<code>队列机层</code> 来订阅这些消息中间件，再经过一系列的处理后，将最终消息<code>Pub</code>到 <code>Redis</code>中，<code>长连网关层</code> 的每一条服务器都可以<code>Sub</code>到这些消息，可以选择在网关层中对消息进行<code>GZIP</code>压缩，然后最终推送给客户端。</p>]]></content>
      
      
      
        <tags>
            
            <tag> IM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IM - API处理层</title>
      <link href="/2019/09/13/IM-API%E5%A4%84%E7%90%86%E5%B1%82/"/>
      <url>/2019/09/13/IM-API%E5%A4%84%E7%90%86%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<pre><code>长连网关通过调用RPC接口，将上行消息直接透传给API处理层。</code></pre><p>在API处理层，首先会根据 <code>Header</code> 中声明的接口信息，通过反射调用相应的<code>Controller</code>中的 <code>method</code>，长连网关层就类似 <code>SpringMVC</code> 的 <code>DispatcherServlet</code>，而API层的处理就类似 <code>@RequestMapping</code>所做的事情。</p><p>首先，定义注解，用来标识一个方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Retention</span>(RetentionPolicy.RUNTIME)</span><br><span class="line"><span class="meta">@Target</span>(ElementType.METHOD)</span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> DispatcherURL &#123;</span><br><span class="line">    <span class="comment">//URL地址</span></span><br><span class="line">    <span class="function">String <span class="title">value</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//接口标识</span></span><br><span class="line">    <span class="function">String <span class="title">tag</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再定义一个对象，用来表示一个<code>url - tag - bean - method</code>的关系。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DispatcherMapping</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String url;</span><br><span class="line">    <span class="keyword">private</span> String tag;</span><br><span class="line">    <span class="keyword">private</span> Object bean;</span><br><span class="line">    <span class="keyword">private</span> String method;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>基于<code>SpringBoot</code>来实现，容器初始化完成将会初始化映射关系。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.google.common.collect.Maps;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.ApplicationContext;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.ApplicationListener;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.event.ContextRefreshedEvent;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"><span class="keyword">import</span> org.springframework.util.ReflectionUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 用于初始化映射关系</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Initializer</span> <span class="keyword">implements</span> <span class="title">ApplicationListener</span>&lt;<span class="title">ContextRefreshedEvent</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Map&lt;String, DispatcherMapping&gt; urlDispatcherMappingMap = Maps.newHashMap();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onApplicationEvent</span><span class="params">(ContextRefreshedEvent event)</span> </span>&#123;</span><br><span class="line">        ApplicationContext context = event.getApplicationContext();</span><br><span class="line">        <span class="keyword">if</span> (context != <span class="keyword">null</span>) &#123;</span><br><span class="line">            String[] beanNames = context.getBeanDefinitionNames();</span><br><span class="line">            Arrays.stream(beanNames).forEach(beanName -&gt; &#123;</span><br><span class="line">                Object bean = context.getBean(beanName);</span><br><span class="line">                ReflectionUtils.doWithMethods(bean.getClass(), method -&gt; &#123;</span><br><span class="line">                    <span class="keyword">if</span> (method.isAnnotationPresent(DispatcherURL<span class="class">.<span class="keyword">class</span>)) </span>&#123;</span><br><span class="line">                        DispatcherMapping dispatcherMapping = <span class="keyword">new</span> DispatcherMapping();</span><br><span class="line">                        DispatcherURL dispatcherURL = method.getAnnotation(DispatcherURL<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">                        dispatcherMapping.setUrl(dispatcherURL.value());</span><br><span class="line">                        dispatcherMapping.setTag(dispatcherURL.tag());</span><br><span class="line">                        dispatcherMapping.setBean(bean);</span><br><span class="line">                        dispatcherMapping.setMethod(method.getName());</span><br><span class="line">                        urlDispatcherMappingMap.put(dispatcherMapping.getTag(), dispatcherMapping);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>声明一个方法大概如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestController</span> </span>&#123;</span><br><span class="line">    <span class="meta">@DispatcherURL</span>(value = <span class="string">"/say"</span>, tag = <span class="string">"(1,0)"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">say</span><span class="params">(Map&lt;Integer, Object&gt; header, Map&lt;Integer, Object&gt; body)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//handler header &amp; body</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">"Hello world"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>RPC服务端如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.Method;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * rpc服务端</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RpcService</span> </span>&#123;</span><br><span class="line">    <span class="comment">//长连网关调用</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">invoke</span><span class="params">(Map&lt;Integer, Object&gt; headerMap, Map&lt;Integer, Object&gt; bodyMap)</span> </span>&#123;</span><br><span class="line">        Object result = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            String tag = getTagFromHeader(headerMap);</span><br><span class="line">            DispatcherMapping dispatcherMapping = Initializer.urlDispatcherMappingMap.get(tag);</span><br><span class="line">            <span class="keyword">if</span> (dispatcherMapping == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="comment">//ignore...</span></span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            Class bean = dispatcherMapping.getBean().getClass();</span><br><span class="line">            Method method = bean.getDeclaredMethod(dispatcherMapping.getMethod(), <span class="keyword">new</span> Class[]&#123;Map<span class="class">.<span class="keyword">class</span>, <span class="title">Map</span>.<span class="title">class</span>&#125;)</span>;</span><br><span class="line">            result = method.invoke(bean, headerMap, bodyMap);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> String <span class="title">getTagFromHeader</span><span class="params">(Map&lt;Integer, Object&gt; headerMap)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//假设tag的key为1和2</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">"("</span> + headerMap.get(<span class="number">1</span>) + <span class="string">","</span> + headerMap.get(<span class="number">2</span>) + <span class="string">")"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最终，客户端只需要在<code>headerMap</code>中传入<code>tag</code>，在<code>bodyMap</code>中传入业务参数，通过简单的<code>RPC</code>透传调用，即可实现网关通用性，一旦有新的接口上线，只需要修改API处理层即可。</p>]]></content>
      
      
      
        <tags>
            
            <tag> IM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IM - 长连网关</title>
      <link href="/2019/09/12/IM-%E9%95%BF%E8%BF%9E%E7%BD%91%E5%85%B3/"/>
      <url>/2019/09/12/IM-%E9%95%BF%E8%BF%9E%E7%BD%91%E5%85%B3/</url>
      
        <content type="html"><![CDATA[<pre><code>长连网关作为与客户端的直接交互通道，其稳定性要求不言而喻。</code></pre><p>作为一个网关，如果频繁的上版本，那么可能在上线期间导致大批量的用户瞬间掉线，而需要转移到其它长连服务器上建连。正常来说，机器一台一台甚至一组一组上，一台机器上用户连接因上线原因被清退，转而跑到另外一台长连服务器建连，而此时这台新的长连服务器也刚好进入上线队列中，再次将这台长连服务器上的用户清退，依此循环，用户体验必然不好。</p><p>为了解决这个问题，那么长连网关必然要具备稳定性、通用性、轻量级，不能过于频繁的进行上线、重启。当然，如果在半夜这种时间上线，以上问题倒是没有那么明显。</p><p>长连网关包含有以下：</p><ul><li>编解码</li><li>通信协议</li><li>心跳保活</li><li>用户在线状态</li><li>上下行消息处理</li></ul><pre><code>1. 编解码</code></pre><p>对于<code>TCP</code>协议通信来说，一般由于<code>二进制包</code>过大或者过小，以及<code>MTU</code>、<code>sendBuffer</code>、<code>receiveBuffer</code>等参数可能产生<code>粘包、拆包问题</code>，从而破坏通信消息内容。</p><p>如果采用<code>Netty</code>开发的话，这个问题就比较容易解决了，可以采用<code>LengthFieldBasedFrameDecoder</code>、<code>LineBasedFrameDecoder</code>、<code>LengthFieldPrepender</code>，结合自定义协议的编解码方式一同组合使用。</p><pre><code>2. 通信协议</code></pre><p>为了让长连网关具备有通用性，协议也必须是轻量级的。</p><p>Google的<code>ProtoBuf</code>是一个不错的参考协议实现。</p><p>在这里将协议分为两个部分：<code>Header</code> 和 <code>Body</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> <span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProtocolRequest</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;Integer, Object&gt; header;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;Integer, Object&gt; body;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将请求<code>Header</code>和<code>Body</code>的 <code>Key-Value对</code> 根据 <code>Proto</code> 文件映射为 <code>KeyIndex-Value</code> 形式，对于 <code>Value</code> 也可以根据<code>Proto</code> 文件映射为 <code>KeyIndex-Value</code> 形式。</p><p>如：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="string">"fromUserId"</span>:<span class="number">123</span>,</span><br><span class="line"><span class="string">"toUserId"</span>:<span class="number">456</span>,</span><br><span class="line"><span class="string">"content"</span>:<span class="string">"hello"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>转化为：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="number">0</span>:<span class="number">123</span>,</span><br><span class="line"><span class="number">1</span>:<span class="number">456</span>,</span><br><span class="line"><span class="number">2</span>:<span class="string">"hello"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过这种方式，可以有效的减少数据包的大小。</p><p>在长连网关层不需要对协议的字段进行解析，只需要识别出请求的类型，然后直接透传给API层即可。</p><pre><code>3. 心跳保活</code></pre><p>对于长连接来说，如果长时间没有消息的读写，这个连接可能会被服务器给断开，导致不可用而使客户端长时间无法收发消息。</p><p>双方通过间歇性的发送特殊的读写请求包来判断对方是否存活，很好的保证了连接的可用性。</p><p>如果采样<code>Netty</code>开发的话，只需要将 <code>IdleStateHandler</code> 加入到<code>pipline</code>中即可，并自定义一个<code>Handler</code>用来处理<code>IdleStateEvent</code>事件。</p><p>如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> <span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">userEventTriggered</span><span class="params">(ChannelHandlerContext ctx, Object evt)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (evt <span class="keyword">instanceof</span> IdleStateEvent) &#123;</span><br><span class="line">        IdleStateEvent event = (IdleStateEvent) evt;</span><br><span class="line">        <span class="keyword">if</span> (event.state() == IdleState.READER_IDLE) &#123;</span><br><span class="line">            ctx.close();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (event.state() == IdleState.WRITER_IDLE) &#123;</span><br><span class="line">            ctx.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><pre><code>4. 用户在线状态</code></pre><p>在消息下推的时候，需要通过客户端与长连服务器建立的长连接通道下推下去，也因此要求了服务端需要维护着 <code>用户 - 连接</code> 的关系对。对于支持<code>多端在线</code>的场景，如果恰好同一个用户的多个设备与同一台长连服务器建连，则需要加入<code>用户 - 设备 - 连接</code>的关系对。</p><p>实际情况是：</p><ul><li>一个用户可以有多台设备</li><li>同一用户的多台设备可以与同一台长连服务器建连</li><li>同一用户的同一设备只能与同一台长连服务器建一个连接</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 标识在某一个设备上的用户</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ChannelIdentifier</span> </span>&#123;</span><br><span class="line">    <span class="comment">//用户id</span></span><br><span class="line">    <span class="keyword">private</span> Long userId;</span><br><span class="line">    <span class="comment">//设备信息</span></span><br><span class="line">    <span class="keyword">private</span> String device;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><pre><code class="java"><span class="comment">//用户id到多台设备的映射关系</span><span class="keyword">private</span> ConcurrentHashMap&lt;Long, Set&lt;ChannelIdentifier&gt;&gt; userToDevices = <span class="keyword">new</span> ConcurrentHashMap&lt;&gt;();<span class="comment">//在某一个设备上的用户与TCP连接的映射关系</span><span class="keyword">private</span> ConcurrentHashMap&lt;ChannelIdentifier, Channel&gt; deviceToChannel = <span class="keyword">new</span> ConcurrentHashMap&lt;&gt;();</code></pre><p>进行 <code>deviceToChannel</code> 的 <code>put</code> 操作的时候需要判断是否该设备已和同一台长连服务器建连，如果是的话，需要<code>close</code>之前的连接，才可以建连。</p><pre><code>5. 上下行消息处理</code></pre><p>对于上行消息，客户端将请求包根据协议定义的格式，封装为<code>HeaderMap</code>、<code>BodyMap</code>，在<code>HeaderMap</code>中声明了该消息的类型，客户端的信息、用户信息等。</p><p>对于下行消息，也是类似上行消息的格式。</p><p>当用户上线的时候，会触发 <code>拉取离线消息</code> 的操作，从 <code>Redis</code> 中<code>sub</code>出离线期间的消息的时候，采用异步多线程的方式来消费消息，虽然消费快了，但是可能会导致<code>消息乱序</code>，因此，不得不对消息进行<code>次序整形</code>，为了实现<code>次序整形</code>，需要在触发取离线消息操作的时候对每一条消息添加一个单调递增<code>seqId</code>，长连网关<code>sub</code>到消息之后，根据<code>seqId</code>对消息进行从小到大排序，也因此实现了消息有序。</p><p>当消息下推到客户端的时候，服务器其实也不确定消息到底推送成功没有以及消息推送到哪条了，甚至是中间某条消息没有推送成功。除了需要存储用户当前<code>已同步到的版本号</code>，对于每一个<code>连接</code>，在建立连接的时候，初始化一个<code>tid</code>，从<code>0</code>开始，消息收到之后，需要进行<code>ack</code>操作，类似<code>TCP三次握手</code>过程，如果有消息<code>丢失、超时</code>，那么将会触发<code>重推</code>操作，在直播互动这种场景中，可能消息下推QPS特别高，且不一定需要全部消息都关注下推成功，但为了统计一下服务推送到达能力，可以采用<code>采样ack</code>的方式，在消息的<code>HeaderMap</code>中添加一个<code>isSampled = true</code>，客户端及长连网关判断该消息需要<code>采样ack</code>，则执行<code>ack</code>操作，否则不执行。</p>]]></content>
      
      
      
        <tags>
            
            <tag> IM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IM - 服务器地址下发</title>
      <link href="/2019/09/12/IM-%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%9C%B0%E5%9D%80%E4%B8%8B%E5%8F%91/"/>
      <url>/2019/09/12/IM-%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%9C%B0%E5%9D%80%E4%B8%8B%E5%8F%91/</url>
      
        <content type="html"><![CDATA[<pre><code>用户上线的时候，需要和长连服务器建连，本文将涉及服务器地址下发设计。</code></pre><p><img src="/images/server-addr-dispatcher.png" alt="IM"></p><pre><code>由于无法得知SLB的可用度，需要计算求和每一台ECS的可用度，间接得出。</code></pre><p>在每一台<code>长连网关</code>程序上都启动了一个定时任务，每隔 <code>5s</code> 获取调度一次，计算<code>pps</code>及<code>bytes</code>，然后将二者分别除去设置的阈值，得到一个<code>已用度</code>，再用 <code>1 - 已用度</code> 得到 <code>可用度</code>的值，再在二者之中取最小值，作为当前<code>ECS服务器</code>的最终可用度，然后将这个值存到<code>Redis</code>中。（<a href="https://github.com/suzunshou/useful-tools/blob/master/java-tools/src/main/java/io/github/suzunshou/java/tools/statistics/LinuxUtils.java" target="_blank" rel="noopener">PPS及Bytes计算方法</a>）</p><p>在<code>下发IP服务</code>程序中，会去读取<code>Redis</code>中存储的每一个<code>SLB</code>对应的<code>ECS</code>服务器列表，每次统计可用度的时候，读出所有<code>ECS</code>服务器<code>当前的可用度</code>，将可用度求和，作为<code>当前SLB</code>的可用度。将计算得出的SLB可用度缓存到机器内存（调用Guava的LoadingCache实现）及Redis中。</p><p>为了让可用度比较接近的SLB被均衡连接，将可用度乘以一个随机数再去进行排序，让同一时刻内返回的SLB列表不会过于固定，造成某一个SLB过于饱和。</p>]]></content>
      
      
      
        <tags>
            
            <tag> IM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IM - 一种可参考的即时通讯设计</title>
      <link href="/2019/09/12/IM-%E4%B8%80%E7%A7%8D%E5%8F%AF%E5%8F%82%E8%80%83%E7%9A%84%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF%E8%AE%BE%E8%AE%A1/"/>
      <url>/2019/09/12/IM-%E4%B8%80%E7%A7%8D%E5%8F%AF%E5%8F%82%E8%80%83%E7%9A%84%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<pre><code>做了一段时间的即时通讯IM应用，有些心得，特来分享分享。</code></pre><p><img src="/images/IM.png" alt="IM"></p><pre><code>IM，又称为即时通讯。</code></pre><p>既然是即时，那就需要和客户端建立一个长连接。<br>对于长连接需要有连接保活心跳机制而长连服务器的IP地址又需要进行下发等。</p><p>总体划分如下:</p><ul><li>服务器地址下发</li><li>网关层</li><li>API层</li><li>服务层</li><li>队列机层</li></ul><p>用户客户端打开应用之后，将会向服务器发起一个HTTPS请求，服务端根据长连服务器负载情况将要下发的地址进行排序，客户端根据获取到的长连服务器地址顺序尝试连接，成功建立连接之后开始进行通信。</p><p>每一条上行及下行的消息都需要与网关层进行交互，在连接期间，需要与网关层进行心跳检测链路问题，消息经过encode处理之后发送到网关层，网关层直接调用API层的RPC透传到API层去处理。</p><p>API层收到来自网关层的RPC请求之后，先进行decode,然后解析出相应的header、body，根据header中定义的tag和type去调用相应的方法。这些方法除了业务逻辑外，另外就是通过RPC或者HTTP去调用各种所需的服务，如：用户服务、私信服务、群聊服务。</p><p>服务层收到API层的请求之后，生成消息版本号，将消息入库，并将消息异步写入队列之中，返回处理结果给API层。</p><p>队列机这一层负责接收、处理及转发多种服务写入的消息，然后将处理后的消息pub到Redis中，包括离线缓存队列，由长连服务器去sub，然后下推给客户端。</p><pre><code>需要解决的问题</code></pre><ul><li>消息乱序问题</li><li>消息可靠性问题</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> IM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>算法 - 归并排序</title>
      <link href="/2019/09/11/%E7%AE%97%E6%B3%95-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/"/>
      <url>/2019/09/11/%E7%AE%97%E6%B3%95-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/</url>
      
        <content type="html"><![CDATA[<p>给定一个<code>无序</code>数组，使用<code>归并排序法</code>对数组进行<code>从小到大</code>排序。</p><p><strong>原理：</strong> 将数组一分为二，二分为四，直到不可切分，然后排序、合并。（先分后治）</p><p><img src="/images/mergesort.png" alt="归并排序"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testMergeSort</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span>[] arr = &#123;<span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">6</span>, <span class="number">3</span>&#125;;</span><br><span class="line">    mergeSort(arr, <span class="number">0</span>, arr.length - <span class="number">1</span>);</span><br><span class="line">    <span class="comment">// -- output :  [1, 2, 3, 4, 5, 6, 7]</span></span><br><span class="line">    System.out.println(Arrays.toString(arr));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">mergeSort</span><span class="params">(<span class="keyword">int</span>[] arr, <span class="keyword">int</span> low, <span class="keyword">int</span> high)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (low &lt; high) &#123;</span><br><span class="line">        <span class="comment">//中心点</span></span><br><span class="line">        <span class="keyword">int</span> mid = low + (high - low) / <span class="number">2</span>;</span><br><span class="line">        <span class="comment">//左区间排序</span></span><br><span class="line">        mergeSort(arr, low, mid);</span><br><span class="line">        <span class="comment">//右区间排序</span></span><br><span class="line">        mergeSort(arr, mid + <span class="number">1</span>, high);</span><br><span class="line">        <span class="comment">//合并左右区间排序结果</span></span><br><span class="line">        merge(arr, low, mid, high);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">merge</span><span class="params">(<span class="keyword">int</span>[] arr, <span class="keyword">int</span> low, <span class="keyword">int</span> mid, <span class="keyword">int</span> high)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//左区间起点，终点为mid</span></span><br><span class="line">    <span class="keyword">int</span> i = low;</span><br><span class="line">    <span class="comment">//右区间起点，终点为high</span></span><br><span class="line">    <span class="keyword">int</span> j = mid + <span class="number">1</span>;</span><br><span class="line">    <span class="comment">//临时数组，用来存储排序结果,大小为: high - low + 1</span></span><br><span class="line">    <span class="keyword">int</span>[] temp = <span class="keyword">new</span> <span class="keyword">int</span>[high - low + <span class="number">1</span>];</span><br><span class="line">    <span class="keyword">int</span> t = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//归并</span></span><br><span class="line">    <span class="keyword">while</span> (i &lt;= mid || j &lt;= high) &#123;</span><br><span class="line">        <span class="comment">//当左右区间都未排完序</span></span><br><span class="line">        <span class="keyword">if</span> (i &lt;= mid &amp;&amp; j &lt;= high) &#123;</span><br><span class="line">            <span class="keyword">if</span> (arr[i] &lt;= arr[j]) &#123;</span><br><span class="line">                temp[t++] = arr[i++];</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                temp[t++] = arr[j++];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//当左区间还有未排序序的</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (i &lt;= mid) &#123;</span><br><span class="line">            temp[t++] = arr[i++];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//当右区间还有未排序序的</span></span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            temp[t++] = arr[j++];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将排序结果赋值给原数组</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> e : temp) &#123;</span><br><span class="line">        arr[low++] = e;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>算法 - 快速排序</title>
      <link href="/2019/09/11/%E7%AE%97%E6%B3%95-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"/>
      <url>/2019/09/11/%E7%AE%97%E6%B3%95-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/</url>
      
        <content type="html"><![CDATA[<p>给定一个<code>无序</code>数组，使用<code>快速排序法</code>对数组进行<code>从小到大</code>排序。</p><p><strong>原理：</strong> 定义一个<code>基准值</code>，同时遍历数组高、低位，并与之比较。</p><p>当高位比基准值大的时候，高位索引 <code>j</code> 往低位移动，也就是<code>j--</code>，当遇到一个比基准值小的数，就把该值赋给低位。</p><p>当低位比基准值小的时候，低位索引 <code>i</code> 往高位移动，也就是<code>i++</code>，当遇到一个比基准值大的数，就把该值赋给高位。</p><p>重复以上，直到<code>i &lt; j</code>，然后，将基准值赋给低位，递归去排序基准值左侧部分和基准值右侧部分，每次递归都需要找一个新的基准值。</p><p><img src="/images/quicksort.png" alt="快速排序"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"> <span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testQuickSort</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span>[] arr = &#123;<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">7</span>, <span class="number">0</span>, <span class="number">10</span>&#125;;</span><br><span class="line">    quickSort(arr, <span class="number">0</span>, arr.length - <span class="number">1</span>);</span><br><span class="line">    <span class="comment">// -- output :  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</span></span><br><span class="line">    System.out.println(Arrays.toString(arr));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">quickSort</span><span class="params">(<span class="keyword">int</span>[] arr, <span class="keyword">int</span> low, <span class="keyword">int</span> high)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (low &gt;= high) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//低位索引</span></span><br><span class="line">    <span class="keyword">int</span> i = low;</span><br><span class="line">    <span class="comment">//高位索引</span></span><br><span class="line">    <span class="keyword">int</span> j = high;</span><br><span class="line">    <span class="comment">//找一个基准值</span></span><br><span class="line">    <span class="keyword">int</span> temp = arr[low];</span><br><span class="line">    <span class="keyword">while</span> (i &lt; j) &#123;</span><br><span class="line">        <span class="comment">//将高位和基准值比较</span></span><br><span class="line">        <span class="keyword">while</span> (i &lt; j &amp;&amp; arr[j] &gt;= temp) &#123;</span><br><span class="line">            j--;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//将高位不符合条件的值赋给低位</span></span><br><span class="line">        <span class="keyword">if</span> (i &lt; j) &#123;</span><br><span class="line">            arr[i] = arr[j];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//将低位和基准值比较</span></span><br><span class="line">        <span class="keyword">while</span> (i &lt; j &amp;&amp; arr[i] &lt;= temp) &#123;</span><br><span class="line">            i++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//将低位不符合条件的值赋给低位</span></span><br><span class="line">        <span class="keyword">if</span> (i &lt; j) &#123;</span><br><span class="line">            arr[j] = arr[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//将基准值赋给i</span></span><br><span class="line">    arr[i] = temp;</span><br><span class="line">    <span class="comment">//排序low到i-1部分的</span></span><br><span class="line">    quickSort(arr, low, i - <span class="number">1</span>);</span><br><span class="line">    <span class="comment">//排序i+1到high部分的</span></span><br><span class="line">    quickSort(arr, i + <span class="number">1</span>, high);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>算法 - 二分查找</title>
      <link href="/2019/09/11/%E7%AE%97%E6%B3%95-%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"/>
      <url>/2019/09/11/%E7%AE%97%E6%B3%95-%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/</url>
      
        <content type="html"><![CDATA[<p>给定一个<code>有序</code>数组，查找数组中某个元素的索引。</p><p><strong>原理：</strong> 每次将搜索区间<code>一分为二</code>，比较目标值和中心值大小，再决定下一步要从左区间搜索还是右区间搜索。</p><p><img src="/images/binarySearch.png" alt="二分查找"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testBinarySearch</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span>[] arr = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>&#125;;</span><br><span class="line">    <span class="comment">// -- output :  1</span></span><br><span class="line">    System.out.println(binarySearch(arr, <span class="number">2</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">binarySearch</span><span class="params">(<span class="keyword">int</span>[] arr, <span class="keyword">int</span> key)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> low = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> high = arr.length - <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (low &lt;= high) &#123;</span><br><span class="line">        <span class="comment">//每次找到中心点，且要防止整数溢出。</span></span><br><span class="line">        <span class="keyword">int</span> mid = low + (high - low) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span> (arr[mid] == key) &#123;</span><br><span class="line">            <span class="keyword">return</span> mid;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (arr[mid] &lt; key) &#123;</span><br><span class="line">            <span class="comment">//如果目标值大于中心值，则从右侧开始找</span></span><br><span class="line">            low = mid + <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//如果目标值小于中心值，则从左侧开始找</span></span><br><span class="line">            high = mid - <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/09/10/hello-world/"/>
      <url>/2019/09/10/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>标签云</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>
