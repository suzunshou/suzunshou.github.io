<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 3.9.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.0"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.0"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.0"><link rel="mask-icon" href="/images/logo.svg?v=7.4.0" color="#222"><meta name="google-site-verification" content="true"><meta name="msvalidate.01" content="809ED7241B89AE83EC3158A325D2AEA7"><meta name="baidu-site-verification" content="true"><link rel="stylesheet" href="/css/main.css?v=7.4.0"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Pisces",version:"7.4.0",exturl:!1,sidebar:{position:"left",display:"hide",offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:"flat"},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,algolia:{appID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!0},path:"search.xml",motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},translation:{copy_button:"复制",copy_success:"复制成功",copy_failure:"复制失败"},sidebarPadding:40}</script><meta name="description" content="说出你的故事"><meta property="og:type" content="website"><meta property="og:title" content="Bug Free"><meta property="og:url" content="https://bug-free.cn/page/4/index.html"><meta property="og:site_name" content="Bug Free"><meta property="og:description" content="说出你的故事"><meta property="og:locale" content="zh-CN"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Bug Free"><meta name="twitter:description" content="说出你的故事"><link rel="canonical" href="https://bug-free.cn/page/4/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!0,isPost:!1,isPage:!1,isArchive:!1}</script><title>Bug Free - 疯狂，热情，追求。</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-147531716-1"></script><script>var host=window.location.hostname;if("localhost"!==host){function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-147531716-1")}</script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?f4fb0ae8dc548b7d25c4d35357cc6b32";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN"><div class="container use-motion"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-meta"><div><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">Bug Free</span> <span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">疯狂，热情，追求。</h1></div><div class="site-nav-toggle"><button aria-label="切换导航栏"><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul></nav><div class="site-search"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="搜索..." spellcheck="false" type="text" id="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"></div></div><div class="search-pop-overlay"></div></div></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article itemscope itemtype="http://schema.org/Article"><div class="post-block home"><link itemprop="mainEntityOfPage" href="https://bug-free.cn/2020/01/16/Kafka-消息到达保证机制/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="生命就是个Bug."><meta itemprop="description" content="说出你的故事"><meta itemprop="image" content="/images/avatar.jpg"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Bug Free"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/2020/01/16/Kafka-消息到达保证机制/" class="post-title-link" itemprop="url">Kafka - 消息到达保证机制</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-01-16 19:26:00" itemprop="dateCreated datePublished" datetime="2020-01-16T19:26:00+08:00">2020-01-16</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-06-13 16:42:53" itemprop="dateModified" datetime="2021-06-13T16:42:53+08:00">2021-06-13</time></span></div></header><div class="post-body" itemprop="articleBody"><pre><code>Kafka消费端采用pull模式，为消费端提供了更多的控制权。</code></pre><p>如果broker采用push模式，能更快的将消息推送给消费端，但无法适应消费端的消费能力，使消费端崩溃。</p><p>采用pull模式，可自主控制消费速率及消费的方式（批量、单条），并且可以表述不同的传输语义。</p><p>Kafka中包含了三种传输语义：</p><ul><li><code>At Most Once</code> 消息可能会丢，但不会重复。</li></ul><p><img src="/images/kafka-amo.png" alt="kafka-amo"></p><p>在这种模式下，先<code>Commit</code> Offset，再去<code>处理</code>消息。<br>如果Commit<code>成功</code>了，此时消费端<code>宕机</code>了，那么下次恢复的时候，消息不会再下发，也就<code>丢了</code>。</p><ul><li><code>At Least Once</code> 消息不会丢，但可能会重复（默认模式）。</li></ul><p><img src="/images/kafka-alo.png" alt="kafka-alo"></p><p>在这种模式下，先<code>处理</code>消息，再<code>Commit</code> Offset。<br>如果Commit<code>失败</code>了，那么这条消息还会继续下发，直到Offset <code>Commit成功</code>，也就<code>重了</code>。</p><ul><li><code>Exactly Once</code> 消息不会丢且不会重复。</li></ul><p><img src="/images/kafka-eo.png" alt="kafka-eo"></p><p>以<code>At Least Once</code> 为基础，让下游保证<code>幂等</code>，并且保存消息处理状态、Offset提交状态，间接实现<code>Exactly Once</code>。而要真正实现<code>Exactly Once</code>，需要引入<code>两阶段</code>事务处理，对于消息乱序、消息重复，采用类似TCP三次握手的<code>ACK</code>机制，对于单Session的，可以这么简单处理，对于多Session的，需要基于事务来实现类似分布式锁、分布式Session，记录所有事务状态、事务进度、判断是否合法，要么全部成功，要么全部失败。</p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article itemscope itemtype="http://schema.org/Article"><div class="post-block home"><link itemprop="mainEntityOfPage" href="https://bug-free.cn/2020/01/15/Kafka-日志、索引、分区、分段设计/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="生命就是个Bug."><meta itemprop="description" content="说出你的故事"><meta itemprop="image" content="/images/avatar.jpg"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Bug Free"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/2020/01/15/Kafka-日志、索引、分区、分段设计/" class="post-title-link" itemprop="url">Kafka - 日志、索引、分区、分段设计</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-01-15 19:09:00" itemprop="dateCreated datePublished" datetime="2020-01-15T19:09:00+08:00">2020-01-15</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-06-13 16:42:53" itemprop="dateModified" datetime="2021-06-13T16:42:53+08:00">2021-06-13</time></span></div></header><div class="post-body" itemprop="articleBody"><pre><code>Topic是Kafka的基本组织单位。</code></pre><p>Kafka的<code>消息</code>是以<code>Topic</code>作为<code>基本单位</code>来组织的，而多个Topic之间又是<code>相互独立</code>的。</p><p>形象的说，可以将Kafka当成一个<code>队列集合</code>，每一个Topic相当于一个<code>队列</code>。</p><p>每个Topic又分为多个Partition，也就是<code>分区</code>，分别存储了一部分的<code>消息</code>，也起到了<code>负载均衡</code>的作用。</p><p>创建Topic的时候，可以指定partition的个数，最终以文件形式存储在磁盘上。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kafka-topics.sh --create --partitions 3 --topic test_p_3 --zookeeper localhost:2181 --replication-factor 1</span><br></pre></td></tr></table></figure><p><img src="/images/kafka-tps.png" alt="kafka-tps.png"></p><p>每个partition以<code>Topic名称-Partition序号</code>来命名，底下又分为多个<code>Segment</code>，也就是<code>分段</code>。</p><p>生产消息的时候，需要指定Topic，而Topic根据Partition路由算法，路由到具体Partition。</p><p><img src="/images/kafka-p-j.png" alt="kafka-p-j"></p><p>同一个Topic，每一个partition各自处理各自的消息。</p><p><img src="/images/kafka-partition.png" alt="ukafka-partition.png"></p><p>每一个<code>segment</code>包含：日志（用来存储消息数据）和索引（用来记录offset相关映射信息）</p><p>通过<code>分段</code>，可以<code>减少</code>文件的大小以及通过<code>稀疏索引</code>进一步实现数据的<code>快速</code>查找。</p><p>可以通过配置<code>log.dirs</code>的值来修改数据存储的位置，默认是在<code>/tmp/kafka-logs</code>目录下。</p><p><img src="/images/kafka-logs.png" alt="kafka-logs"></p><pre><code>以相同基准offset命名的日志、索引文件，称为段。</code></pre><p>如果一个partition只有一个数据文件的话：</p><ul><li><p>对于写入<br>由于是顺序追加写入，时间复杂度为O(1)</p></li><li><p>对于查找<br>要查找某个offset，采用的是顺序查找，时间复杂度达到了O(n)</p></li></ul><p>通过对数据进行分段、加索引，解决了痛点。</p><p>在Kafka中，索引文件分为：</p><table><thead><tr><th align="center">name</th><th align="center">type</th><th align="center">suffix</th></tr></thead><tbody><tr><td align="center">偏移量索引</td><td align="center">OffsetIndex</td><td align="center">.index</td></tr><tr><td align="center">时间戳索引</td><td align="center">TimeIndex</td><td align="center">.timeindex</td></tr><tr><td align="center">事务索引</td><td align="center">TransactionIndex</td><td align="center">.txnindex</td></tr></tbody></table><p>日志文件分为：</p><table><thead><tr><th align="center">name</th><th align="center">suffix</th><th align="center">desc</th></tr></thead><tbody><tr><td align="center">数据文件</td><td align="center">.log</td><td align="center">用于存储消息</td></tr><tr><td align="center">交换文件</td><td align="center">.swap</td><td align="center">用于segment的恢复</td></tr><tr><td align="center">延迟待删文件</td><td align="center">.deleted</td><td align="center">用于标识要删除的文件</td></tr><tr><td align="center">快照文件</td><td align="center">.snapshot</td><td align="center">用于记录producer的事务信息</td></tr><tr><td align="center">清理临时文件</td><td align="center">.cleaned</td><td align="center">用于标识正在删除的文件</td></tr></tbody></table><p><strong>分段</strong></p><p>假设有100条消息，offset取值范围在：0 - 99，如果分为4个段，那么每一个段各存储25条消息，取值范围分别为：0 - 24、25 - 49、 50 - 74、75 - 99，而每一段的文件以<code>20位起始offset</code>来命名，不足20位，用0补齐，要查找某个offset只需要找到对应范围内的文件，然后再通过<code>二分查找</code>算法去文件查找即可。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 通过kafka.tools.DumpLogSegments可以查看log文件的内容</span><br><span class="line">./kafka-run-class.sh kafka.tools.DumpLogSegments --files /tmp/kafka-logs/test_p_3-0/00000000000000000000.log</span><br></pre></td></tr></table></figure><p><img src="/images/kafka-sg.png" alt="kafka-sg"></p><p><strong>索引</strong></p><p>通过分段可以减少数据文件大小，并且加快查询速度，但仍然存在顺序查找的最差情况。</p><p>为了进一步提高数据查找的速度，Kafka通过建立<code>稀疏索引</code>的方式，每隔一定间隔建立一条索引。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 通过kafka.tools.DumpLogSegments可以查看index文件的内容</span><br><span class="line">./kafka-run-class.sh kafka.tools.DumpLogSegments --files /tmp/kafka-logs/test_p_3-0/00000000000000000000.index</span><br></pre></td></tr></table></figure><p><img src="/images/kafka-index.png" alt="kafka-index"></p><p>偏移量索引，记录着 <code>&lt; offset , position &gt;</code> 偏移量 - 物理地址</p><p>时间戳索引，记录着 <code>&lt; timestamp , offset &gt;</code>时间戳 - 偏移量</p><p>事务索引，记录着 <code>&lt; offset , AbortedTxn &gt;</code> 偏移量 - 被中断事务</p><pre><code>消息查找：offset、timestamp</code></pre><p>在Kafka中，segment通过一个跳跃表来维护。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* the actual segments of the log */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> segments: <span class="type">ConcurrentNavigableMap</span>[java.lang.<span class="type">Long</span>, <span class="type">LogSegment</span>] = <span class="keyword">new</span> <span class="type">ConcurrentSkipListMap</span>[java.lang.<span class="type">Long</span>, <span class="type">LogSegment</span>]</span><br></pre></td></tr></table></figure><p>每一次，只有一个<code>activeSegment</code>可以进行写入消息，其它的<code>segment</code>是只读的。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The active segment that is currently taking appends</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">activeSegment</span> </span>= segments.lastEntry.getValue</span><br></pre></td></tr></table></figure><p><strong>基于偏移量查找</strong></p><p><code>OffsetIndex</code>的数据格式为：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">offset:</span> <span class="number">33</span> <span class="string">position</span> <span class="number">4158</span></span><br><span class="line"><span class="attr">offset:</span> <span class="number">66</span> <span class="string">position</span> <span class="number">8316</span></span><br><span class="line"><span class="attr">offset:</span> <span class="number">99</span> <span class="string">position</span> <span class="number">12474</span></span><br></pre></td></tr></table></figure><p>在Kafka的<code>IndexEntry.scala</code>中定义为：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The mapping between a logical log offset and the physical position</span></span><br><span class="line"><span class="comment"> * in some log file of the beginning of the message set entry with the</span></span><br><span class="line"><span class="comment"> * given offset.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">OffsetPosition</span>(<span class="params">offset: <span class="type">Long</span>, position: <span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">IndexEntry</span> </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">indexKey</span> </span>= offset</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">indexValue</span> </span>= position.toLong</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果要查找<code>offset=35</code>的消息，那么就先从<code>segments</code>跳跃表上找到对应应访问的<code>segment</code>文件。</p><p>然后通过<code>二分查找</code>在偏移量索引文件找到不大于35的offset，也就是<code>offset: 33 position 4158</code>。</p><p>解析offset对应的<code>position</code>，从position处顺序查找<code>log文件</code>，找到<code>offset=35</code>的位置。</p><p><strong>基于时间戳查找</strong></p><p><code>TimeIndex</code>的数据格式为：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">timestamp:</span> <span class="number">1579167998000</span> <span class="string">offset</span> <span class="number">33</span></span><br><span class="line"><span class="attr">timestamp:</span> <span class="number">1579168197621</span> <span class="string">offset</span> <span class="number">66</span></span><br><span class="line"><span class="attr">timestamp:</span> <span class="number">1579168397242</span> <span class="string">offset</span> <span class="number">99</span></span><br></pre></td></tr></table></figure><p>在Kafka的<code>IndexEntry.scala</code>中定义为：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The mapping between a timestamp to a message offset. The entry means that any message whose timestamp is greater</span></span><br><span class="line"><span class="comment"> * than that timestamp must be at or after that offset.</span></span><br><span class="line"><span class="comment"> * @param timestamp The max timestamp before the given offset.</span></span><br><span class="line"><span class="comment"> * @param offset The message offset.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">TimestampOffset</span>(<span class="params">timestamp: <span class="type">Long</span>, offset: <span class="type">Long</span></span>) <span class="keyword">extends</span> <span class="title">IndexEntry</span> </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">indexKey</span> </span>= timestamp</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">indexValue</span> </span>= offset</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果要查找<code>timestamp=15791679981234</code>的消息，那么就先比较每个<code>segment</code>文件的<code>largestTimestamp</code>，找到对应的<code>segment</code>文件。</p><p>然后通过<code>二分查找</code>在时间戳索引文件找到不大于<code>15791679981234</code>的<code>timestamp</code>，也就是<code>timestamp: 1579167998000 offset 33</code>。</p><p>找到offset直接去偏移量索引文件中查找position。</p><p>从position处顺序查找<code>log文件</code>，找到<code>timestamp=15791679981234</code>的位置。</p></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article><article itemscope itemtype="http://schema.org/Article"><div class="post-block home"><link itemprop="mainEntityOfPage" href="https://bug-free.cn/2020/01/09/Kafka-启动流程分析/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="生命就是个Bug."><meta itemprop="description" content="说出你的故事"><meta itemprop="image" content="/images/avatar.jpg"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Bug Free"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/2020/01/09/Kafka-启动流程分析/" class="post-title-link" itemprop="url">Kafka - 启动流程分析</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-01-09 23:42:00" itemprop="dateCreated datePublished" datetime="2020-01-09T23:42:00+08:00">2020-01-09</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-06-13 16:42:53" itemprop="dateModified" datetime="2021-06-13T16:42:53+08:00">2021-06-13</time></span></div></header><div class="post-body" itemprop="articleBody"><pre><code>通常，应用程序的启动都是基于main函数的，Kafka也不例外。</code></pre><p>启动<code>Kafka</code>的时候，通过执行<code>kafka-server-start.sh</code>文件，并且指定配置文件即可。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kafka-server-start.sh ../config/server.properties</span><br></pre></td></tr></table></figure><p>而<code>kafka-server-start.sh</code>中核心的内容在于启动<code>kafka.Kafka</code>类中的<code>main</code>函数。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">...省略</span></span><br><span class="line">exec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka "$@"</span><br></pre></td></tr></table></figure><p>主要流程：解析配置文件、创建<code>KafkaServerStartable</code>实例、启动服务。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">//解析配置文件 </span></span><br><span class="line">    <span class="keyword">val</span> serverProps = getPropsFromArgs(args)</span><br><span class="line">      <span class="comment">//从配置文件创建实例 </span></span><br><span class="line">    <span class="keyword">val</span> kafkaServerStartable = <span class="type">KafkaServerStartable</span>.fromProps(serverProps)</span><br><span class="line">    <span class="comment">//...	</span></span><br><span class="line">    <span class="comment">//优雅退出</span></span><br><span class="line">    <span class="type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="type">Thread</span>(<span class="string">"kafka-shutdown-hook"</span>) &#123;</span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = kafkaServerStartable.shutdown()</span><br><span class="line">    &#125;)</span><br><span class="line">    kafkaServerStartable.startup()<span class="comment">//启动应用	</span></span><br><span class="line">    kafkaServerStartable.awaitShutdown()<span class="comment">//阻塞等待关闭 </span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</span><br><span class="line">      fatal(<span class="string">"Exiting Kafka due to fatal exception"</span>, e)</span><br><span class="line">      <span class="type">Exit</span>.exit(<span class="number">1</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="type">Exit</span>.exit(<span class="number">0</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>1. 解析配置文件</strong><br>读取指定的<code>server.properties</code>文件，进行一系列的解析验证，支持通过<code>命令行</code>传入参数，<code>覆盖</code>配置文件中配置的属性，最后返回<code>Properties</code>实例。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPropsFromArgs</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Properties</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> optionParser = <span class="keyword">new</span> <span class="type">OptionParser</span>(<span class="literal">false</span>)</span><br><span class="line">  <span class="keyword">val</span> overrideOpt = optionParser.accepts(<span class="string">"override"</span>, <span class="string">"Optional property that should override values set in server.properties file"</span>)</span><br><span class="line">    .withRequiredArg()</span><br><span class="line">    .ofType(classOf[<span class="type">String</span>])</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (args.length == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="type">CommandLineUtils</span>.printUsageAndDie(optionParser, <span class="string">"USAGE: java [options] %s server.properties [--override property=value]*"</span>.format(classOf[<span class="type">KafkaServer</span>].getSimpleName()))</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">val</span> props = <span class="type">Utils</span>.loadProps(args(<span class="number">0</span>)) <span class="comment">//加载server.properties</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (args.length &gt; <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">val</span> options = optionParser.parse(args.slice(<span class="number">1</span>, args.length): _*)</span><br><span class="line">      <span class="comment">//命令行参数个数校验</span></span><br><span class="line">    <span class="keyword">if</span> (options.nonOptionArguments().size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    	<span class="type">CommandLineUtils</span>.printUsageAndDie(optionParser, <span class="string">"Found non argument parameters: "</span> + options.nonOptionArguments().toArray.mkString(<span class="string">","</span>))</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//将命令行配置的属性存入props</span></span><br><span class="line">    props ++= <span class="type">CommandLineUtils</span>.parseKeyValueArgs(options.valuesOf(overrideOpt).asScala)</span><br><span class="line">  &#125;</span><br><span class="line">  props</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>2. 创建KafkaServerStartable实例</strong><br>KafkaServerStartable主要的作用是启动Kafka的Metrics监控以及维护Kafka服务的生命周期。<br>包括：启动、关闭、闭锁阻塞等待关闭、设置Kafka服务状态。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">KafkaServerStartable</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">fromProps</span></span>(serverProps: <span class="type">Properties</span>) = &#123;</span><br><span class="line">  <span class="comment">//启动监控</span></span><br><span class="line">  <span class="keyword">val</span> reporters = <span class="type">KafkaMetricsReporter</span>.startReporters(<span class="keyword">new</span> <span class="type">VerifiableProperties</span>(serverProps))</span><br><span class="line">    <span class="keyword">new</span> <span class="type">KafkaServerStartable</span>(<span class="type">KafkaConfig</span>.fromProps(serverProps, <span class="literal">false</span>), reporters)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KafkaServerStartable</span>(<span class="params">val staticServerConfig: <span class="type">KafkaConfig</span>, reporters: <span class="type">Seq</span>[<span class="type">KafkaMetricsReporter</span>]</span>) <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  <span class="comment">//初始化真正的Kafka服务对象</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> server = <span class="keyword">new</span> <span class="type">KafkaServer</span>(staticServerConfig, kafkaMetricsReporters = reporters)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(serverConfig: <span class="type">KafkaConfig</span>) = <span class="keyword">this</span>(serverConfig, <span class="type">Seq</span>.empty) </span><br><span class="line">  <span class="comment">//启动</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>() &#123;</span><br><span class="line">    <span class="keyword">try</span> server.startup()</span><br><span class="line">    <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> _: <span class="type">Throwable</span> =&gt;</span><br><span class="line">        <span class="comment">// KafkaServer.startup() calls shutdown() in case of exceptions, so we invoke `exit` to set the status code</span></span><br><span class="line">        fatal(<span class="string">"Exiting Kafka."</span>)</span><br><span class="line">        <span class="type">Exit</span>.exit(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;  </span><br><span class="line">  <span class="comment">//关闭</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">shutdown</span></span>() &#123;</span><br><span class="line">    <span class="keyword">try</span> server.shutdown()</span><br><span class="line">    <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> _: <span class="type">Throwable</span> =&gt;</span><br><span class="line">        fatal(<span class="string">"Halting Kafka."</span>)</span><br><span class="line">        <span class="comment">// Calling exit() can lead to deadlock as exit() can be called multiple times. Force exit.</span></span><br><span class="line">        <span class="type">Exit</span>.halt(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;  </span><br><span class="line">  <span class="comment">//设置状态，包含：NotRunning、Starting、RecoveringFromUncleanShutdown、RunningAsBroker、PendingControlledShutdown、BrokerShuttingDown</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setServerState</span></span>(newState: <span class="type">Byte</span>) &#123;</span><br><span class="line">    server.brokerState.newState(newState)</span><br><span class="line">  &#125;  </span><br><span class="line">  <span class="comment">//阻塞进程避免退出，通过CountDownLatch实现</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">awaitShutdown</span></span>(): <span class="type">Unit</span> = server.awaitShutdown()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>3. 启动服务</strong><br>启动服务是通过间接调用<code>KafkaServer</code>的<code>startup()</code>方法来实现的。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>() &#123;</span><br><span class="line">   <span class="keyword">try</span> &#123;</span><br><span class="line">     info(<span class="string">"starting"</span>)</span><br><span class="line">     <span class="comment">//是否已关闭</span></span><br><span class="line">     <span class="keyword">if</span> (isShuttingDown.get)</span><br><span class="line">       <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"Kafka server is still shutting down, cannot re-start!"</span>)</span><br><span class="line">     <span class="comment">//是否已启动</span></span><br><span class="line">     <span class="keyword">if</span> (startupComplete.get)</span><br><span class="line">       <span class="keyword">return</span>       </span><br><span class="line">     <span class="comment">//是否可以启动</span></span><br><span class="line">     <span class="keyword">val</span> canStartup = isStartingUp.compareAndSet(<span class="literal">false</span>, <span class="literal">true</span>)</span><br><span class="line">     <span class="keyword">if</span> (canStartup) &#123;<span class="comment">//设置broker状态为Starting</span></span><br><span class="line">       brokerState.newState(<span class="type">Starting</span>)</span><br><span class="line">       <span class="comment">//连接ZK，并创建根节点</span></span><br><span class="line">       initZkClient(time)</span><br><span class="line">       <span class="comment">//从ZK获取或创建集群id，规则：UUID的mostSigBits、leastSigBits组合转base64</span></span><br><span class="line">       _clusterId = getOrGenerateClusterId(zkClient)</span><br><span class="line">       info(<span class="string">s"Cluster ID = <span class="subst">$clusterId</span>"</span>)</span><br><span class="line">       <span class="comment">//获取brokerId及log存储路径，brokerId通过zk生成或者server.properties配置broker.id</span></span><br><span class="line">       <span class="comment">//规则：/brokers/seqid的version值 + maxReservedBrokerId（默认1000），保证唯一性</span></span><br><span class="line">       <span class="keyword">val</span> (brokerId, initialOfflineDirs) = getBrokerIdAndOfflineDirs</span><br><span class="line">       config.brokerId = brokerId</span><br><span class="line">       logContext = <span class="keyword">new</span> <span class="type">LogContext</span>(<span class="string">s"[KafkaServer id=<span class="subst">$&#123;config.brokerId&#125;</span>] "</span>)</span><br><span class="line">       <span class="comment">//配置logger</span></span><br><span class="line">       <span class="keyword">this</span>.logIdent = logContext.logPrefix</span><br><span class="line">       <span class="comment">//初始化AdminZkClient，支持动态修改配置 </span></span><br><span class="line">       config.dynamicConfig.initialize(zkClient)</span><br><span class="line">	<span class="comment">//初始化定时任务调度器</span></span><br><span class="line">       kafkaScheduler = <span class="keyword">new</span> <span class="type">KafkaScheduler</span>(config.backgroundThreads)</span><br><span class="line">       kafkaScheduler.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">//创建及配置监控，默认使用JMX及Yammer Metrics</span></span><br><span class="line">       <span class="keyword">val</span> reporters = <span class="keyword">new</span> util.<span class="type">ArrayList</span>[<span class="type">MetricsReporter</span>]</span><br><span class="line">       reporters.add(<span class="keyword">new</span> <span class="type">JmxReporter</span>(jmxPrefix))</span><br><span class="line">       <span class="keyword">val</span> metricConfig = <span class="type">KafkaServer</span>.metricConfig(config)</span><br><span class="line">       metrics = <span class="keyword">new</span> <span class="type">Metrics</span>(metricConfig, reporters, time, <span class="literal">true</span>)</span><br><span class="line">       _brokerTopicStats = <span class="keyword">new</span> <span class="type">BrokerTopicStats</span></span><br><span class="line">       <span class="comment">//初始化配额管理器</span></span><br><span class="line">       quotaManagers = <span class="type">QuotaFactory</span>.instantiate(config, metrics, time, threadNamePrefix.getOrElse(<span class="string">""</span>))</span><br><span class="line">       notifyClusterListeners(kafkaMetricsReporters ++ metrics.reporters.asScala)</span><br><span class="line">       <span class="comment">//用于保证kafka-log数据目录的存在</span></span><br><span class="line">       logDirFailureChannel = <span class="keyword">new</span> <span class="type">LogDirFailureChannel</span>(config.logDirs.size)</span><br><span class="line"></span><br><span class="line">       <span class="comment">//启动日志管理器，kafka的消息以日志形式存储</span></span><br><span class="line">       logManager = <span class="type">LogManager</span>(config, initialOfflineDirs, zkClient, brokerState, kafkaScheduler, time, brokerTopicStats, logDirFailureChannel)</span><br><span class="line">       <span class="comment">//启动日志清理、刷新、校验、恢复等的定时线程</span></span><br><span class="line">       logManager.startup()</span><br><span class="line"></span><br><span class="line">       metadataCache = <span class="keyword">new</span> <span class="type">MetadataCache</span>(config.brokerId)</span><br><span class="line">       <span class="comment">// SCRAM认证方式的token缓存</span></span><br><span class="line">       tokenCache = <span class="keyword">new</span> <span class="type">DelegationTokenCache</span>(<span class="type">ScramMechanism</span>.mechanismNames)</span><br><span class="line">       credentialProvider = <span class="keyword">new</span> <span class="type">CredentialProvider</span>(<span class="type">ScramMechanism</span>.mechanismNames, tokenCache)</span><br><span class="line"></span><br><span class="line">       <span class="comment">//启动socket，监听9092端口，等待接收客户端请求 </span></span><br><span class="line">       socketServer = <span class="keyword">new</span> <span class="type">SocketServer</span>(config, metrics, time, credentialProvider)</span><br><span class="line">       socketServer.startup(startupProcessors = <span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">       <span class="comment">//启动副本管理器，高可用相关</span></span><br><span class="line">       replicaManager = createReplicaManager(isShuttingDown)</span><br><span class="line">       replicaManager.startup()</span><br><span class="line">	</span><br><span class="line">       <span class="comment">//将broker信息注册到ZK上</span></span><br><span class="line">       <span class="keyword">val</span> brokerInfo = createBrokerInfo</span><br><span class="line">       zkClient.registerBrokerInZk(brokerInfo)</span><br><span class="line"></span><br><span class="line">       <span class="comment">//校验broker信息</span></span><br><span class="line">       checkpointBrokerId(config.brokerId)</span><br><span class="line"></span><br><span class="line">       <span class="comment">//启动token管理器</span></span><br><span class="line">       tokenManager = <span class="keyword">new</span> <span class="type">DelegationTokenManager</span>(config, tokenCache, time , zkClient)</span><br><span class="line">       tokenManager.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">//启动Kafka控制器，只有leader会与ZK建连</span></span><br><span class="line">       kafkaController = <span class="keyword">new</span> <span class="type">KafkaController</span>(config, zkClient, time, metrics, brokerInfo, tokenManager, threadNamePrefix)</span><br><span class="line">       kafkaController.startup()</span><br><span class="line">       </span><br><span class="line">       <span class="comment">//admin管理器</span></span><br><span class="line">       adminManager = <span class="keyword">new</span> <span class="type">AdminManager</span>(config, metrics, metadataCache, zkClient)</span><br><span class="line"></span><br><span class="line">       <span class="comment">//启动集群群组协调器</span></span><br><span class="line">       groupCoordinator = <span class="type">GroupCoordinator</span>(config, zkClient, replicaManager, <span class="type">Time</span>.<span class="type">SYSTEM</span>)</span><br><span class="line">       groupCoordinator.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">//启动事务协调器</span></span><br><span class="line">       transactionCoordinator = <span class="type">TransactionCoordinator</span>(config, replicaManager, <span class="keyword">new</span> <span class="type">KafkaScheduler</span>(threads = <span class="number">1</span>, threadNamePrefix = <span class="string">"transaction-log-manager-"</span>), zkClient, metrics, metadataCache, <span class="type">Time</span>.<span class="type">SYSTEM</span>)</span><br><span class="line">       transactionCoordinator.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">//ACL</span></span><br><span class="line">       authorizer = <span class="type">Option</span>(config.authorizerClassName).filter(_.nonEmpty).map &#123; authorizerClassName =&gt;</span><br><span class="line">         <span class="keyword">val</span> authZ = <span class="type">CoreUtils</span>.createObject[<span class="type">Authorizer</span>](authorizerClassName)</span><br><span class="line">         authZ.configure(config.originals())</span><br><span class="line">         authZ</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">//创建拉取管理器</span></span><br><span class="line">       <span class="keyword">val</span> fetchManager = <span class="keyword">new</span> <span class="type">FetchManager</span>(<span class="type">Time</span>.<span class="type">SYSTEM</span>,</span><br><span class="line">         <span class="keyword">new</span> <span class="type">FetchSessionCache</span>(config.maxIncrementalFetchSessionCacheSlots,</span><br><span class="line">           <span class="type">KafkaServer</span>.<span class="type">MIN_INCREMENTAL_FETCH_SESSION_EVICTION_MS</span>))</span><br><span class="line"></span><br><span class="line">       <span class="comment">//初始化KafkaApis，负责核心的请求逻辑处理</span></span><br><span class="line">       apis = <span class="keyword">new</span> <span class="type">KafkaApis</span>(socketServer.requestChannel, replicaManager, adminManager, groupCoordinator, transactionCoordinator,</span><br><span class="line">         kafkaController, zkClient, config.brokerId, config, metadataCache, metrics, authorizer, quotaManagers,</span><br><span class="line">         fetchManager, brokerTopicStats, clusterId, time, tokenManager)</span><br><span class="line">       <span class="comment">//请求处理池</span></span><br><span class="line">       requestHandlerPool = <span class="keyword">new</span> <span class="type">KafkaRequestHandlerPool</span>(config.brokerId, socketServer.requestChannel, apis, time,</span><br><span class="line">         config.numIoThreads)</span><br><span class="line"></span><br><span class="line">       <span class="type">Mx4jLoader</span>.maybeLoad()</span><br><span class="line"></span><br><span class="line">       config.dynamicConfig.addReconfigurables(<span class="keyword">this</span>)</span><br><span class="line"></span><br><span class="line">       <span class="comment">//启动动态配置处理器</span></span><br><span class="line">       dynamicConfigHandlers = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">ConfigHandler</span>](<span class="type">ConfigType</span>.<span class="type">Topic</span> -&gt; <span class="keyword">new</span> <span class="type">TopicConfigHandler</span>(logManager, config, quotaManagers),</span><br><span class="line">                                                          <span class="type">ConfigType</span>.<span class="type">Client</span> -&gt; <span class="keyword">new</span> <span class="type">ClientIdConfigHandler</span>(quotaManagers),</span><br><span class="line">                                                          <span class="type">ConfigType</span>.<span class="type">User</span> -&gt; <span class="keyword">new</span> <span class="type">UserConfigHandler</span>(quotaManagers, credentialProvider),</span><br><span class="line">                                                          <span class="type">ConfigType</span>.<span class="type">Broker</span> -&gt; <span class="keyword">new</span> <span class="type">BrokerConfigHandler</span>(config, quotaManagers))</span><br><span class="line"></span><br><span class="line">       dynamicConfigManager = <span class="keyword">new</span> <span class="type">DynamicConfigManager</span>(zkClient, dynamicConfigHandlers)</span><br><span class="line">       dynamicConfigManager.startup()</span><br><span class="line">	</span><br><span class="line">       <span class="comment">//启动请求处理线程</span></span><br><span class="line">       socketServer.startProcessors()</span><br><span class="line">       brokerState.newState(<span class="type">RunningAsBroker</span>)</span><br><span class="line">       shutdownLatch = <span class="keyword">new</span> <span class="type">CountDownLatch</span>(<span class="number">1</span>)</span><br><span class="line">       startupComplete.set(<span class="literal">true</span>)</span><br><span class="line">       isStartingUp.set(<span class="literal">false</span>)</span><br><span class="line">       <span class="type">AppInfoParser</span>.registerAppInfo(jmxPrefix, config.brokerId.toString, metrics)</span><br><span class="line">       info(<span class="string">"started"</span>)</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">catch</span> &#123;</span><br><span class="line">     <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</span><br><span class="line">       fatal(<span class="string">"Fatal error during KafkaServer startup. Prepare to shutdown"</span>, e)</span><br><span class="line">       isStartingUp.set(<span class="literal">false</span>)</span><br><span class="line">       shutdown()</span><br><span class="line">       <span class="keyword">throw</span> e</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></div></article></div><nav class="pagination"><a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right" aria-label="下一页"></i></a></nav></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="生命就是个Bug."><p class="site-author-name" itemprop="name">生命就是个Bug.</p><div class="site-description" itemprop="description">说出你的故事</div></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">35</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">8</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/suzunshou" title="GitHub &rarr; https://github.com/suzunshou" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:suzunshou@qq.com" title="E-Mail &rarr; mailto:suzunshou@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a> </span><span class="links-of-author-item"><a href="https://weibo.com/suzunshou" title="Weibo &rarr; https://weibo.com/suzunshou" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i>Weibo</a> </span><span class="links-of-author-item"><a href="https://twitter.com/suzunshou" title="Twitter &rarr; https://twitter.com/suzunshou" rel="noopener" target="_blank"><i class="fa fa-fw fa-twitter"></i>Twitter</a></span></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright"><a href="http://www.beian.miit.gov.cn" rel="noopener" target="_blank">京ICP备20007595号 </a><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=" rel="noopener" target="_blank"></a>&copy; <span itemprop="copyrightYear">2021</span> <span class="with-love" id="animate"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">生命就是个Bug.</span></div><div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div><span class="post-meta-divider">|</span><div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.4.0</div></div></footer></div><script src="/lib/anime.min.js?v=3.1.0"></script><script src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script src="/js/utils.js?v=7.4.0"></script><script src="/js/motion.js?v=7.4.0"></script><script src="/js/schemes/pisces.js?v=7.4.0"></script><script src="/js/next-boot.js?v=7.4.0"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script src="/js/local-search.js?v=7.4.0"></script><script type="text/javascript">!function(){var t=document.createElement("script");t.type="text/javascript",t.async=!0,t.setAttribute("issue-term","title"),t.setAttribute("theme","github-light"),t.setAttribute("repo","suzunshou/suzunshou.github.io"),t.crossorigin="anonymous",t.src="https://utteranc.es/client.js",document.getElementById("utterance-container").appendChild(t)}()</script></body></html>